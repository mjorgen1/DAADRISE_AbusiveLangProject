{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/pyparsing.py:2725: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile( self.reString )\n",
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.stem.cistem import Cistem\n",
    "import string\n",
    "import re\n",
    "from textstat.textstat import *\n",
    "import seaborn\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "import autosklearn.classification\n",
    "import sklearn.metrics\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Raw data\n",
    "train_data = pd.read_csv(\"/home/mackenzie/Downloads/GermanTrainingData.txt\", sep='\\t', names=['tweet', 'coarse', 'labels'])\n",
    "test_data = pd.read_csv(\"/home/mackenzie/Downloads/GermanTestingData.txt\", sep='\\t', names=['tweet', 'coarse', 'labels'])\n",
    "df = pd.concat([train_data, test_data], ignore_index=True)\n",
    "del train_data\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tweets=df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"german\")\n",
    "\n",
    "other_exclusions = [\"lbr\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = Cistem()\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-ßA-ß]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def tokenize(tweet):\n",
    "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-ßA-ß]+\", tweet.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    \"\"\"Same as tokenize but without the stemming\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-ßA-ß.,!?]+\", tweet.lower())).strip()\n",
    "    return tweet.split()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    preprocessor=preprocess,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=stopwords,\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=3000,\n",
    "    min_df=5,\n",
    "    max_df=0.75\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['all', 'ber', 'dami', 'dasselb', 'demselb', 'denselb', 'derselb', 'dess', 'desselb', 'dieselb', 'dor', 'etwa', 'eur', 'f', 'geg', 'hatt', 'hrend', 'jed', 'jen', 'jetz', 'k', 'mach', 'manch', 'nich', 'nne', 'nnt', 'ohn', 'r', 'rde', 'selb', 'solch', 'son', 'sond', 'w', 'welch', 'werd', 'wes', 'woll', 'zwisch'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "#Construct tfidf matrix and get relevant scores\n",
    "tfidf = vectorizer.fit_transform(tweets).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Get POS tags for tweets and save as a string\n",
    "tweet_tags = []\n",
    "for t in tweets:\n",
    "    tokens = basic_tokenize(preprocess(t))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tag_list = [x[1] for x in tags]\n",
    "    tag_str = \" \".join(tag_list)\n",
    "    tweet_tags.append(tag_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#We can use the TFIDF vectorizer to get a token matrix for the POS tags\n",
    "pos_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=None,\n",
    "    lowercase=False,\n",
    "    preprocessor=None,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=None,\n",
    "    use_idf=False,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=2000,\n",
    "    min_df=5,\n",
    "    max_df=0.75,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Construct POS TF matrix and get vocab dict\n",
    "pos = pos_vectorizer.fit_transform(pd.Series(tweet_tags)).toarray()\n",
    "pos_vocab = {v:i for i, v in enumerate(pos_vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Now get other features\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-ßA-ß]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    sentiment = TextBlob(\"tweet\").sentiment\n",
    "    \n",
    "    words = preprocess(tweet) #Get text only\n",
    "    \n",
    "    syllables = textstat.syllable_count(words, lang='de_DE')\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment[0],twitter_objs[2], twitter_objs[1], twitter_objs[0]]\n",
    "    #features = pandas.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"sentiment\", \"num_hashtags\", \"num_mentions\", \"num_urls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "feats = get_feature_array(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "M = np.concatenate([tfidf,pos,feats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8407, 3918)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Finally get a list of variable names\n",
    "variables = ['']*len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    variables[v] = k\n",
    "\n",
    "pos_variables = ['']*len(pos_vocab)\n",
    "for k,v in pos_vocab.items():\n",
    "    pos_variables[v] = k\n",
    "\n",
    "feature_names = variables+pos_variables+other_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make sure string to numeric is working\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Changing string labels to numeric labels\n",
    "def string_to_numeric(x):\n",
    "    if x == 'OTHER' or x == 'PROFANITY':\n",
    "        return 0\n",
    "    if x == 'INSULT':\n",
    "        return 1\n",
    "    if x == 'ABUSE':\n",
    "        return 2\n",
    "    \n",
    "X = pd.DataFrame(M, columns=feature_names)\n",
    "\n",
    "# double check that labels are ints\n",
    "y = df['labels'].apply(string_to_numeric)\n",
    "print('make sure string to numeric is working...')\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other rows extracted...done \n",
      "insult rows extracted...done: \n",
      "abuse rows extracted...done \n"
     ]
    }
   ],
   "source": [
    "# Resampling Technique setup\n",
    "\n",
    "# convert the labels series to a dataframe\n",
    "a = y.to_frame()\n",
    "a.columns=['labels']\n",
    "\n",
    "df = pd.concat([X, a], axis=1)\n",
    "\n",
    "# split up the df data by labels\n",
    "print('other rows extracted...done ')\n",
    "other = df.loc[df['labels']==0]\n",
    "\n",
    "print('insult rows extracted...done: ')\n",
    "insult = df.loc[df['labels']==1]\n",
    "\n",
    "print('abuse rows extracted...done ')\n",
    "abuse = df.loc[df['labels']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insult upsampled...done\n",
      "abuse upsampled...done\n"
     ]
    }
   ],
   "source": [
    "# Upsample minority class insult\n",
    "df_insult_upsampled = resample(insult, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=4722,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "print('insult upsampled...done')\n",
    "\n",
    "# Upsample minority class abuse\n",
    "df_abuse_upsampled = resample(abuse, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=3926,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "print('abuse upsampled...done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: \n",
      "17055\n",
      "shape of y: \n",
      "17055\n"
     ]
    }
   ],
   "source": [
    "# For Upsampling, update X and y with new values\n",
    "# resampling doesn't impact the og dataframes, so we make new X and y with updated values\n",
    "X = pd.DataFrame() # might not need this, double check\n",
    "X = pd.concat([other, insult, df_insult_upsampled, abuse, df_abuse_upsampled])\n",
    "X = X.drop(columns=\"labels\")\n",
    "y = pd.concat([other['labels'], insult['labels'], df_insult_upsampled['labels'], abuse['labels'], df_abuse_upsampled['labels']])\n",
    "print('shape of X: ')\n",
    "print(X.shape)\n",
    "print('shape of y: ')\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Feature Selection RFE -- TODO: issue with nan\\nfrom sklearn.feature_selection import RFE\\nfrom sklearn.svm import SVR\\nestimator = SVR(kernel=\"linear\")\\nselector = RFE(estimator, step=1) # half of the features are selected\\nselector = selector.fit(X, y)\\nselector.support_ \\nselector.ranking_\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' In process of testing this...\n",
    "# Feature Selection RFE -- TODO: issue with nan\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator, step=1) # half of the features are selected\n",
    "selector = selector.fit(X, y)\n",
    "selector.support_ \n",
    "selector.ranking_\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame(name='labels')\n",
    "y_test = y_test.to_frame(name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/autosklearn/automl.py:887: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Will change shape via np.ravel().\n",
      "  y = self._check_y(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start automl!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2019-07-26 11:57:37,019:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:37,029:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:39,034:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:41,038:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:43,045:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:45,084:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:47,095:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:49,102:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:51,114:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:53,119:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:55,125:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:57,130:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:57:59,135:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:01,142:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:03,147:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:05,150:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:07,155:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:09,159:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:11,183:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:13,194:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:15,198:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:17,203:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:19,207:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:21,211:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:23,226:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:25,230:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:27,237:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:29,242:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-07-26 11:58:31,247:EnsembleBuilder(1):english_data] No models better than random - using Dummy Score!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2019-07-26 12:34:00,394:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2019-07-26 12:34:00,394:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['/tmp/autosklearn_tmp_23934_2581/.auto-sklearn/ensembles/1.0000000000.ensemble', '/tmp/autosklearn_tmp_23934_2581/.auto-sklearn/ensembles/1.0000000001.ensemble', '/tmp/autosklearn_tmp_23934_2581/.auto-sklearn/ensembles/1.0000000002.ensemble', '/tmp/autosklearn_tmp_23934_2581/.auto-sklearn/ensembles/1.0000000003.ensemble', '/tmp/autosklearn_tmp_23934_2581/.auto-sklearn/ensembles/1.0000000004.ensemble', '/tmp/autosklearn_tmp_23934_2581/.auto-sklearn/ensembles/1.0000000005.ensemble', '/tmp/autosklearn_tmp_23934_2581/.auto-sklearn/ensembles/1.0000000006.ensemble', '/tmp/autosklearn_tmp_23934_2581/.auto-sklearn/ensembles/1.0000000007.ensemble']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(delete_output_folder_after_terminate=True,\n",
       "                      delete_tmp_folder_after_terminate=True,\n",
       "                      disable_evaluator_output=False,\n",
       "                      ensemble_memory_limit=1024, ensemble_nbest=50,\n",
       "                      ensemble_size=50, exclude_estimators=None,\n",
       "                      exclude_preprocessors=None, get_smac_object_callback=None,\n",
       "                      include_estimators=None, include_preprocessors=None,\n",
       "                      initial_configurations_via_metalearning=25,\n",
       "                      logging_config=None, metadata_directory=None,\n",
       "                      ml_memory_limit=100000, n_jobs=None, output_folder=None,\n",
       "                      per_run_time_limit=360, resampling_strategy='holdout',\n",
       "                      resampling_strategy_arguments=None, seed=1,\n",
       "                      shared_mode=False, smac_scenario_args=None,\n",
       "                      time_left_for_this_task=3600, tmp_folder=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"start automl!\")\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(ml_memory_limit=100000, time_left_for_this_task=3600, per_run_time_limit=360)\n",
    "automl.fit(X_train, y_train, dataset_name='german_data') # feat_type=classification is another param we might use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_hat = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9255568581477139\n",
      "F1 score: \n",
      "0.925256167643352\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score:\", sklearn.metrics.accuracy_score(y_test, y_hat))\n",
    "print(\"F1 score: \")\n",
    "print(sklearn.metrics.f1_score(y_test, y_hat, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auto-sklearn results:\\n  Dataset name: english_data\\n  Metric: accuracy\\n  Best validation score: 0.924990\\n  Number of target algorithm runs: 17\\n  Number of successful target algorithm runs: 7\\n  Number of crashed target algorithm runs: 4\\n  Number of target algorithms that exceeded the time limit: 5\\n  Number of target algorithms that exceeded the memory limit: 1\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.sprint_statistics() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[500  18  51]\n",
      " [ 10 583   2]\n",
      " [ 40   6 496]]\n",
      "Recall: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAFHCAYAAAAySY5rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8FdX9//HXJwQ0C1tVxLqwyCaiUcEFcQGrbO67VgXrVq17pV/XWkUFF9D+WmurdWFREFzqLu6KFhUQ1IqC7CIKgoYgSQwkfH5/zCTeJJNwkWTuDbyfj8d95N6Zc2c+M/feT86cM3PG3B0REaksI9UBiIikIyVHEZEISo4iIhGUHEVEIig5iohEUHIUEYmg5CgiEkHJUUQkgpKjiEiEzFQH8EvsuOOOuqwnBgsWLEh1CFuMgoKCVIewxWjVqpUlU041RxGRCEqOIiIRlBxFRCIoOYqIRFByFBGJoOQoIhJByVFEJIKSo4hIBCVHEZEISo4iIhGUHEVEIig5iohEUHIUEYmg5CgiEkHJUUQkgpKjiEgEJUcRkQhKjiIiEZQcRUQiKDmKiERQchQRiaDkKCISQclRRCSCkqOISAQlRxGRCEqOIiIRlBxFRCIoOYqIRFByFBGJoOQoIhJByVFEJIKSo4hIBCVHEZEISo4iIhGUHEVEIig5iohEUHIUEYmg5CgiEkHJUUQkgpKjiEgEJcdN0KJFCx588EHmzp3Lhx9+yHHHHRdZrkmTJtx+++18/PHHfPbZZ4waNYrWrVtXzN9pp50YM2YMs2bNYubMmdx66600atQors1oEAoKCrjiiivYb7/96NevHy+++GJkOXfnnnvu4eCDD+bggw/m7rvvxt0ByM/PZ9CgQRx88MH06tWLM888k5kzZ8a5GWlv9erVXHfddRxxxBGcdNJJvPbaa5Hl3J1//vOfHHnkkRx55JHcd999FfsZ4L///S+DBg2ib9++XHTRRSxcuDCuTagzsSZHC7Q3s83il3/bbbexbt068vLyuOSSSxg+fDidOnWqVu7cc8+le/fuHH744XTv3p3Vq1dzyy23VMwfNmwY33//Pfvssw99+/blgAMOYPDgwXFuStq77bbbaNy4MW+//TbDhw/ntttuY968edXKPfnkk7z55ps88cQTPPnkk0yePJknnngCgOzsbG6++Wbeeecd3nvvPc455xwuvfRSSktL496ctHX33XfTuHFjnn32WW688UZGjhwZmdiee+453n33XR555BFGjRrFlClTePbZZwFYsmQJQ4cOZciQIbz00ksceOCBXHvttQ1uP8eaHD341/I/wDdUNt1lZWUxcOBA7rrrLoqKipg2bRqvvfYaJ554YrWyu+yyC2+//TYrV66kpKSEZ599ls6dO1ea//zzz1NSUsKKFSt4++23K83f0hUVFfH6669z8cUXk52dzT777EPv3r154YUXqpV97rnnGDx4MK1bt2b77bdn0KBBFT/arbbainbt2pGRkYG7k5GRwerVqykoKIh7k9JScXEx77zzDueeey7Z2dnsueee9OrVi1deeaVa2UmTJnHaaafRqlUrtttuO0477TRefvllAKZOncqee+7JnnvuSWZmJmeccQYrVqzg448/jnuTNkkqDqtnAtWrVw1M+/btKSsrY8GCBRXTZs2aFZnUxo8fz7777sv222/P1ltvzfHHH89bb71VMf+hhx7i2GOPZeutt6Z169b06dOn0vwt3eLFi2nUqBFt27atmNapU6fImuP8+fMr1d47d+7M/PnzK5U58cQT6dGjB5dddhknnHAC22yzTb3F3pAsWbKEjIwMdtlll4ppHTp0iKw5Lly4kF133TWyXOLhdeLrhnZonZmCdb4NTDKzUcASEmqR7v5wTW8yswuACwCaN29OTk5O/Ua5ATk5Ofz444+Vpv3444+RcS1YsIClS5cyY8YMSktLmT17NjfccEPF/Pfff5/f/va3zJkzh8zMTCZOnMikSZPqfRsaiqKiInJzcytNy83NpaioKLJs06ZNq5Vzd8wMgKeeeoqSkhLeeOMN1q1bV7/BNyDFxcXV9nNOTk7kfq5aNicnh+LiYtydfffdl/vvv5+ZM2fSrVs3HnvsMdatW8dPP/1U79tQl1JRc+wFLAQOBc4EzgofZ9b2Jnd/wN17uHuPVCdGgMLCwko/QoCmTZtSWFhYrezw4cPZaqut2H333enYsSMvv/wyY8eOBcDMGDduHC+//DIdO3akW7duNG/enOuvvz6W7WgIsrOzq+3XwsJCsrOzI8uuWbOmWrnyxFhuq622YuDAgTz88MPMmTOnfgJvYLKysqrt56Kiosj9XLVsUVERWVlZmBlt2rThuuuu45577uG4446joKCAtm3bst1229X7NtSl2JOju/ep4XFY3LFsigULFtCoUSPatWtXMa1r166RP7SuXbsyceJEVq1axdq1a3n44YfZZ599aNmyJS1atGDHHXfkkUceYe3ateTn5zNhwgQOO6xB7Y561aZNG0pLS1m8eHHFtDlz5tChQ4dqZXfddddKn8GcOXMqHf5VVVpaytdff123ATdQO++8M2VlZSxZsqRi2rx58yp9x8u1a9euUrNG1XJ9+vRhzJgxvPjii5xzzjksW7aM3XbbrX43oI6l5FQeM9vGzM4ysz+Fr39tZjulIpZfqri4mJdffpkhQ4aQlZVFjx496Nu3L0899VS1sp988gknnXQSTZs2JTMzk8GDB/Ptt9+Sn59Pfn4+ixcvZtCgQTRq1IhmzZpx8skn8/nnn6dgq9JTdnY2hx9+OP/4xz8oKipi5syZvP322xx11FHVyh599NGMHTuW5cuX89133zFmzBiOPfZYIPgcZsyYUXGI9/DDD/P999+zxx57xL1JaSkrK4tDDjmEhx56iOLiYj799FPee+89+vXrV61sv379mDhxIitWrGDlypU8/vjjDBgwoGL+nDlzKCsrIz8/nxEjRtCrVy/atGkT5+ZsMqvaeFrvKzQ7FHgKmA70cvem4bQh7n50MsvYcccd06K3u0WLFowcOZJDDjmE/Px8hg0bxjPPPMN+++3Ho48+WtEx0LJlS4YOHcohhxxC48aNmTNnDjfffHNF793uu+/OTTfdRNeuXVm/fj1Tpkzhuuuu4/vvv0/l5lXqbEq1goICbrzxRt5//31atGjB5ZdfzpFHHslHH33EH/7wBz788EPg5/Mcn376aQBOOOEErrzySsyM6dOnc/vtt/P111+TmZlJx44dufjii+nRo0cqNw0gbXrMV69ezfDhw5k+fTrNmjXjwgsv5IgjjuCTTz7hT3/6E6+++irw83mO5WcMHHXUUVx00UUVzRd/+MMfmDdvHpmZmfTp04dLLrmErKyslG1XolatWtmGS6UmOc4kSIRvmFm+u7c0s62Bxe6+fTLLSJfkuLlLp+S4uUuX5LglSDY5puKwuq27vxE+L09ya0lNz7mISKRUJMfPzaxqI8bhBCeHi4ikhVTU1q4CXjCzF4EsM7sfOBo4NgWxiIhESsWpPB8AecAs4GGCcx73c/dpccciIlKTlLTzuftS4M5UrFtEJBmxJ0cz+xUwBNgLqHStkrsfEnc8IiJRUlFzHAdsBUwEql+0KSKSBlKRHA8EtnP3khSsW0QkKak4ledToEFdKigiW55Yao5mdk7CyzcJhix7BFiWWK62IctEROIU12H1WVVefw0cUWWaE5zaIyKScrEkR3fvE8d6RETqSuxtjuHAE1HTp8cdi4hITVLRIVNthFILxjlqn4JYREQixXYqj5mNCZ82SXheri3B5YQiImkhzvMcE28BNw8oH1PNgf8CT8QYi4hIrWJLju5+s5k1Br4DDgK2BVYCbwBj3V23gRORtBFbm6OZNQfeA/4CrANmhH+HA1PC+SIiaSHOw+rhBDXFw9y94p6OZpZDcJ31cOAPMcYjIlKjOHurjwMuSkyMAOHri4HjY4xFRKRWcSbH5sDSGuZ9DTSLMRYRkVrFmRznAzXdqf43gG51JyJpI87keDcwxsxONLMMADPLMLOTgFHhfBGRtBDnqTyjzGwbgkQ43sxWEpzOUwIMdfdH4opFRGRDYh3s1t1HmtkDBAPelp/n+L67r44zDhGRDYl9JHB3/xF4Je71iohsjFQMPCEikvaUHEVEIig5iohEUHIUEYmg5CgiEkHJUUQkwi9KjmbWxMwOMrMd6jogEZF0kFRyNLMHzOz34fNMYAowGVhgZlVvsSoi0uAlW3M8Eii/O+AxwPYE930ZDgyt+7BERFIr2eS4DbA8fN4feNLdvwLGALvXR2AiIqmUbHJcDnQJR9PpR3DfF4AcoKw+AhMRSaVkr60eA0wgGJS2EfBaOH1fYE49xCUiklJJJUd3/7OZzQZ2AR5395KE94+or+BERFLF3D3VMWy0srKyhhd0A5SZGfugTVushvg7bMAsmUJJn+doZoeZ2ZNmNsPMdgqnnW1mh/7SCEVE0lWy5zmeDDwPrAB2A5qEs7KBa+onNBGR1Em25ng9cKG7XwSUJkyfAuxd51GJiKRYssmxE8EVMVWtBlrUXTgiIukh2eS4DOgQMb0XuqWqiGyGkk2ODwF/NbPugAPbm9mpwF3AA/UVnIhIqiR7rsYw4FcEbYyNgfcIroz5f+7+13qKTUQkZTbqPEczaw7sQVDj/J+759dXYLXReY7x0HmO8dF5jrFK6jxHnQQuNVJyjE9D/B02YEklxxq//WY2ETjP3VeHz2vk7qdsZHAiImmttqpBGUHnC8D6hOciIpu9pA6rzSzD3dfHEE9SdFgdDx1Wx0eH1bGqm2urw9sirDWzbpsckohIA7HB5OjupcBXBOM4iohsEZI9CXw4cGt4Ko+IyGYv2TbHaUAXgtrjQqAwcb6771cv0dVAbY7xUJtjfNTmGKtNO5WnitfDh4jIFkEngUuNVHOMT0P8HTZgdVpzDJZodiDQleCcx1nu/sEvCExEJO0llRzNbHvgSYIhyr4PJ29jZu8BJ7n7d/UUn4hISiTbW/13IAvo6u7buft2wO7htL/VV3AiIqmSbG91AXC4u0+rMn0/4FV3j3U0cLU5xkNtjvFRm2Os6vTugxnA2ojp6zZiGSIiDUayie0tgpHAW5dPCJ+PDOeJiGxWkj2sbgu8SHAfmUUEvdXtgLnAke6+uN4ijKDD6njosDo+OqyOVd0OdmtmGcCRBFfKGPA58FIqRutRcoyHkmN8lBxjpZHAZdMoOcanIf4OG7C6OwnczP6vhlkO/ATMA15393XJxSYikt6SbXOcC7QGcoCV4eRtCQagKAB2IBjW7FB3/6p+Qv2Zao7xUM0xPqo5xqpOT+X5C/AR0MHdW7l7K4LOmanAEGAnYAlwzy8IVEQk7SRbc5wPnOjuH1eZvjfwlLu3D6+7ftrdW0cupA6p5hgP1Rzjo5pjrOq05rgD0SOBNyI43Ab4BshNcnkiImkt2eT4NvBPM9ujfEL4/D5+Pgm8G8E5kCIiDV6yyfE8gs6XT8ys2MyKgI/DaeeFZUqAa+o+RBGR+G3UeY5mlgd0Jjhm/8LdP62vwGqjNsd4qM0xPmpzjFX9nAQe3mRrtafw01RyjIeSY3yUHGNVdx0yZpZpZkPN7HuCwW7bhdNvM7Pzf3mMIiLpKdk2x+uB04E/ELQtlvsYOLeugxIRSbVkk+NZwO/dfQKQONDE/wjaIEVENivJJscdgfk1vL9J3YUjIpIekk2OXwAHRUw/EZhZd+E0LKtWreLSSy+le/fu/OY3v+GFF16ILOfujBw5kp49e9KzZ09GjBhR0QC/aNEiLr74Ynr16sUBBxzA+eefz8KFC+PcjAahZcuWPP3006xZs4ZFixZx+umnR5Zr3rw5o0aNYvny5Sxfvpy//OUvlebn5eUxefJkVq1axZIlS/jzn/8cR/gNxqpVq7j44ovZa6+96NOnD88//3xkOXfnrrvuYv/992f//ffnzjvvrNSp9MUXX3DCCSeQl5fHCSecwBdffBHXJtQdd9/gAzgB+AG4iuDcxiuAfxK0P/ZPZhl1+SgtLfV0eFxxxRV+2WWXeUFBgX/44Ye+zz77+BdffFGt3GOPPeZ9+/b1r7/+2pcuXer9+/f3Rx991EtLS33GjBk+YcIEX7lypRcXF/vdd9/t/fr1S/m2lZaWOsGoS2nxGDdunD/++OOek5PjvXr18lWrVnnXrl2rlXv44Yd94sSJnpWV5W3atPF58+b52WefXTF/1qxZfuutt3pGRoa3b9/ev/nmGz/66KNTvn3p4sorr/TLL7/c16xZ49OmTfN99tnHv/zyy2rlxo8f73379vVvv/3Wly1b5gMGDPBx48a5u3tJSYn37t3bH3nkES8pKfHRo0d77969vaSkJO7NqUlyeS/pgnAM8CHBvWRKgenA0cm+vy4fqU4apaWlvnr1au/atavPmzevYtpVV13ld955Z7Wyp5xyio8bN67i9YQJE/ykk06KXO7KlSu9U6dOvnLlypRvY6oTRvkjOzvbS0pKvGPHjhXTxowZ48OHD69WdsWKFd6jR4+K19dee61Pnjy54nVhYaHvtttuFa8nTpzo11xzTcq3MR0UFhb67rvv7gsWLKiYNmTIEL/rrruqlT311FP98ccfr3g9ceJEP/nkk93d/d133/WDDjrI169fXzH/0EMP9Xfeeaceo98oSeWZpG+O5e7Pufv+7t4EaOzuPdw9us69BVi0aBGNGjWibdu2FdM6d+7MvHnzqpWdN28enTt33mA5gOnTp7PtttvSokWsN3RMa506daKsrIy5c+dWTPvkk0/YfffdI8ubWaXn3bp1q3j917/+lUGDBpGZmUmnTp3o2bMnr7/+ev0F34AsWrSIjIwM2rVrVzGtS5cukd/VuXPn0qVLl0rlyj+f8u974udQ23c+XSV7nuPnZvar8tfuQVXSzJqb2ecbs0Iz+6GG6d9tzHJSraioiNzcyuNsNG3alMLCwsiyTZs2rXidm5tLUVFRtRN/ly1bxq233srVV19dP0E3ULm5uRQUFFSaVlBQUGmflps0aRLXXHMNubm57LrrrpxzzjlkZ2dXzH/hhRc46aSTKC4uZs6cOTz00ENMnz693rehIaj6PYXav9OJ3/+mTZtWfKcLCwurLSc3NzdyOeks2ZpjF6JHDd8a2HUj19m46gQza0z0qD+JZS4ws+lmNv3f//73Rq6y7mVnZ1f7sNesWUNOTk5k2TVr1lS8LiwsJDs7u9J/1h9++IHzzjuP0047jSOPPLL+Am+A1qxZQ7NmzSpNa9asGT/++GO1spdddhnFxcXMnTuXZ599lvHjx/P1118DQafOpEmTGDp0KFtvvTU77bQT/fr146KLLoplO9Jd1e8p1P6dTvz+r1mzpuI7nZOTU205hYWFkctJZ7UmRzMbaGYDw5e/KX8dPo4GriMYAXyDzOxdM5sMbG1mkxMfwBxgSm3vd/cHwkP5Huefn/qLctq2bUtpaSmLFi2qmDZnzhw6dOhQrWyHDh2YM2dOxevZs2dXKldQUMB5553HYYcdxoUXXlivcTdEX375JZmZmZX2WV5eHrNmzapWNj8/nzPPPJMddtiBbt26kZGRwdSpUwFo3749ZWVljB07lrKyMpYuXcrjjz/OwIEDqy1nS9S2bVvKysoqfaerflfLdezYkdmzZ1cq17FjR+Dn73vikVFNv420VluDJMEJ3+uBsoTnidMWA8cn07gJDAbOBorD5+WPQUA/gnbMBtMhU1pa6pdffrlfccUVvnr1ap86dWqNvdWPPvqo9+/f35cuXerffPONDxgwoKK3etWqVX7iiSf6TTfdlPLtSdcOGcDHjx/v48aN8+zsbD/wwANr7K1u3769/+pXv/KMjAzv37+/r1ixoqJc06ZNPT8/308//XQ3M99+++19ypQpfuutt6Z8+9LFFVdc4VdeeaUXFhb69OnTa+ytHjdunPfv39+XLVvmy5Yt84EDB1brrR41apSXlJT42LFjN7/eamArgkPnbwluhbBVwqNRsiupsswuv+R9iY9UJ43yx8qVK/3CCy/0vLw8P+SQQ/yZZ57x0tJS/+CDDzwvL6+i3Lp16/z222/3Hj16eI8ePfz222/3devWeWlpqT/55JPeqVMnz8vLq/T46quvUr59qU4YiY+WLVv6f/7zH1+zZo0vXrzYTz/9dAf8oIMO8h9//LGi3Mknn+xLly71wsJCnzlzpvft27fScvr06eNTp071VatW+bfffusPPPCAZ2VlpXz70kV+fr5fdNFFnpeX54ceeqg/99xz7u4+bdo032uvvSrKrV+/3u+44w7fd999fd999/U77rijUu/0rFmz/Pjjj/c99tjDjzvuOJ81a1bs21KLpPJMLLdmNbNzkinn7g8nU06j8sRDo/LEJ47foVSo2yHLzKwpcASwC1UuGXT3Ozfw3reSWIW7+2HJxKLkGA8lx/goOcaq7pKjmfUAXiLoUW4OrABaAUXAt+7e6ZfHufGUHOOh5BgfJcdY1ekNtkYCTwHbEXSo9ALaEFxXff1GRWWWUdNjY5YjIlKfkq05rgL2d/c54fOe7v6Fme0PjHH3pIctM7P1BI3Q1bh7rec6llPNMR6qOcZHNcdYJVVzTPbbX8rP4zh+R9Du+AWwCth5IwNrV+X1DgQ35tpiL0UUkfSTbHKcCXQH5gKTgZvMrAXBOYqfbcwK3X1xlUmLzWwwMA14aGOWJSJSX5Jt57uR4N4xADcAPwFjCNodf18HcTQjaM8UEUkLsZznWGmFZmOp3OaYDRwCTHD3S5NZhtoc46E2x/iozTFWddfmaGadgEx3/7zK9K7AOnefG/3OSFXHLSoE/uXuGjdKRNJGsr3V7wIPuPvYKtN/S3DjrUPrKb5IqjnGQzXH+KjmGKs6Pc8xD3g/YvrUcF7SzOx0M9stfN7JzN4xszfNrMuG3isiEpdkk6MD1UcWDTpSkjo3McGtBPejgeDk8mkEPeD3beRyRETqTbKH1S8QtA2e7u7rw2kZwONAU3cfkPQKzVa7ezMzKx/tpzWwDljp7r+q/d0BHVbHQ4fV8dFhdazq9CTwawhqd7PN7J1w2iEE11cfspGBrTCzDsAewDR3LzGz7GQDFhGJQ1LJ0d0/M7O9gMuBvQgS2fPA3yNO6t6QW4CPCAbLPTWc9hvgk41cjohIvYn9PEeAsKaIuxeFr1sBGe6+LJn367A6Hjqsjo8Oq2NVp4fVdcrdi8yslZm1TsX6RUQ2JPbkaGb9Ca6h3qHKLGfje75FROpFKsZQ/AdBu2OOu2ckPJQYRSRtpOLa6h+AbXwTVqw2x3iozTE+anOMVZ1eIRMs0SzXzPLMrPEviwkIDql/twnvFxGpd8meBJ4D/BM4k2DQ207uvsDM7iW4h8xtSa8wuE57f2ARUKl32t2TOmdSNcd4qOYYH9UcY1WnvdXDgS7AgUDi6DmvAkOBpJMj8GD4EBFJW8kmx2OBU9z9QzNL/Bf3OdA+mQWYWfltV5dsRHwiIimRbHLcjuDeMVXlbMS6NnQLBCfJRCsiUt+STY4fAQMJTsOBn0fyPofoocyqcfeqN9YSEUlbySbH64GXwjEXM4GLzWx3oDcQ60C3IiJxSOpUHnefTJAEWwFLgRMIhjDr5e5T6y88EZHUSMnAE5tKp/LEQ6fyxKch/g4bsDq9wVZ2bfPLR9cREdlcJFs1WEPl26lWpeuiRWSzkmxyrHobhMbA3sB5wJ/rNCIRkTSwSW2OZnYqcKa7H113IW2Y2hzjoTbH+KjNMVZ1P/BEhOnAYRssJSLSwPzi5GhmTYCLCU7tERHZrCTbW72Cyh0yBrQA1gKD6iEuEZGUSrZR6YYqr9cDK4Ap7h51zbWISIO2weRoZpnAOuClZO8OKCLS0CU72G0RsNsvuEd1vVBvdTzUWx0f9VbHqk57q6cCeb88FhGRhiXZqsG9wEgz+zXB8GWFiTPd/fO6Dqw2BQUFca5ui1VWVpbqELYYLVu2THUIW4z8/PykyiWbHCeGf+8L/5YfAxi637SIbIaSTY671WsUIiJpptbkaGYPA5e7+5yY4hERSQsb6pAZDGTFEYiISDrZUHJMqstbRGRzk8ypPDoBS0S2OMl0yCwzq70C6e7qrRaRzUoyyfECYFV9ByIikk6SSY7Pa3AJEdnSbKjNUe2NIrJFUm+1iEiEWg+r3X1Tb6MgItIgKfmJiERQchQRiaDkKCISQclRRCSCkqOISAQlRxGRCEqOIiIRlBxFRCIoOYqIRFByFBGJoOQoIhJByVFEJIKSo4hIBCVHEZEISo4iIhGUHEVEIig5iohEUHIUEYmg5CgiEkHJUUQkgpKjiEgEJUcRkQhKjiIiEZQcRUQiKDmKiERQchQRiaDkKCISQclRRCSCkuMmKCgo4Oqrr6ZPnz4cf/zxvPLKK5Hl3J1//OMf9OvXj379+nHvvffi7gB8/PHHHHbYYZUePXv25K233opzU9LeqlWruOSSS9hnn3047LDDeOGFFyLLuTsjRozggAMO4IADDuCuu+6q2NcAN954IwMGDKBr16785z//iSv8BqNFixaMHTuWr7/+mk8//ZSTTjopslyzZs247777+PLLL/nyyy+5+uqrK+Ztu+22PPjgg3z++ecsXryYSZMm0b1797g2oc5kpjqAhmzkyJE0btyYF198kblz53LVVVfRsWNH2rdvX6ncM888w+TJkxk7diwAl19+Ob/+9a854YQT2GuvvXjzzTcrys6YMYM//elPHHDAAbFuS7q75ZZbaNy4Me+++y6zZ8/mwgsvpHPnznTs2LFSuYkTJ/LGG2/wzDPPYGace+657Lzzzpx22mkAdO7cmQEDBjBy5MhUbEbaGzFiBGvXrqVz587sscceTJgwgc8++4zZs2dXKjds2DCysrLIy8tj22235dlnn2XJkiWMGzeOnJwcZsyYwfXXX8+KFSs466yzmDBhAnl5eRQWFqZoyzZe7DVHM9vNzP5sZv8IX3cxsz3jjmNTFRcX89Zbb3HBBReQnZ1NXl4eBx98MJMmTapW9qWXXuL000+nVatWtGrVitNPP52XXnopcrkvvfQSffr0ISsrq743ocEoKiritdde47LLLiMnJ4fu3bvTp08fnnvuuWpiFkD4AAATjUlEQVRln3nmGX73u9/RunVrtt9+e84+++xKNcQzzjiDnj17stVWW8W5CQ1CdnY2Rx99NMOGDaOwsJAPPviAl19+mVNPPbVa2f79+/O3v/2N4uJilixZwqOPPsqZZ54JwOLFi7nvvvtYvnw569evZ/To0TRu3JgOHTrEvUmbJNbkaGYnA+8AOwJnhZNzgbvjjKMufPXVV2RkZLDLLrtUTOvQoQMLFiyoVnbhwoWVajgdO3Zk4cKF1cr99NNPvPXWWwwcOLB+gm6gFi1aREZGBu3atauY1qVLF+bNm1et7Lx58+jcufMGy0l1u+66K2VlZcyfP79i2meffUaXLl0iy5tZpee77bZbZLlu3brRpEmTyO98Oou75jgU6OvuFwJl4bRPgLyY49hkxcXF5ObmVpqWm5tLUVFRZNmcnJxq5RLbwgDeeustmjdvzt57710/QTdQRUVFNG3atNK03NzcyEO0qmVr2tdSXW5uLqtXr640bfXq1dW+5wBvvPEGV1xxBbm5ubRr144zzjgj8minadOm3H///dx5553Vlp3u4k6OrQiSIYAn/N3gN9fMLjCz6WY2ffTo0fUVX9KysrKq/TgLCwvJzs7eYNnycon/eSE4pB4wYEC16Vu67Oxs1qxZU2laYWFhpX84NZWtaV9LdWvWrKn2T6hp06bV9j3A1VdfzU8//cT06dN57LHHeOqpp/jmm28qldl6660ZP34806ZN45577qnX2OtD3MnxI34+nC53GjB1Q2909wfcvYe79xg8eHC9BLcxdtllF8rKyliyZEnFtLlz51brjAFo165dpUO7uXPnVjpEBFi+fDkzZ85kwIAB9Rd0A9W2bVvKyspYtGhRxbTZs2dHtmF16NChUudBTeWkuvnz55OZmVnpO9ytW7dqnTEQnD1wwQUX0KVLFw488EAyMjKYMWNGxfwmTZrw6KOP8u2333LllVfGEn9dizs5XgbcambvADlm9gpwC9Dg9l5WVha9e/fm3//+N8XFxXzyySe8++679O/fv1rZAQMGMH78eL777jtWrFjB+PHjq7Urvvzyy+yxxx7stNNOcW1Cg5Gdnc3hhx/O3//+d4qKipgxYwZvvvkmxxxzTLWyxx57LKNHj2b58uV89913PPLIIxx//PEV89euXUtJSQnuzrp16ygpKWH9+vVxbk7aKioq4oUXXuC6664jOzub/fffn4EDBzJhwoRqZdu2bUvLli3JyMjg8MMPZ/DgwYwYMQKAzMxMRo8ezU8//cSFF17YYJs0LO7AzSwbOApoAywBXnD36vX2Wvzwww9psbcLCgoYNmwYU6dOpXnz5lx00UX069ePjz/+mD/+8Y8Vp+iUn+dY3rt6zDHHcPHFF1c61Dv11FM544wzIn/wqdKiRYtUh1Bh1apV3HDDDUyZMoUWLVrwxz/+kaOOOorp06fz+9//no8++gj4+TzHp556CoATTzyRIUOGVOzrQYMGMW3atErLHj16NPvtt1+8G1TFNttsk9L1l2vRogX33nsvvXv3Jj8/n5tvvpknn3ySnj17MnHiRHbeeWcAjjvuOIYNG0bz5s2ZP38+N910U8X3/cADD+TFF1+kqKio0j+eU045hffffz8l25UoPz8/qTaW2JNjpZWbtQfK3H3xxrwvXZLj5i6dkuPmLl2S45Yg2eQY96k8483swPD574BZwOdmdm6ccYiIbEjcbY6/AaaHz/8IHA7sB1wTcxwiIrWK+/LBJu6+1sx2BH7l7v8FMLPtY45DRKRWcSfHj83sWoLOmBcBwkTZsM4OFZHNXtyH1ecCewBZwA3htJ7AYzHHISJSq5T2Vv9S6q2Oh3qr46Pe6vgk21sd62G1mZ1T0zx3fzjOWEREahN3m2PVSwdbA7sC/wWUHEUkbcSaHN29T9VpYW0yeqwjEZEUSYfbJIwi6KgREUkbcbc5Vk3G2cCZwKo44xAR2ZC42xxLqT5241Lg/JjjEBGpVdzJsV2V14XuvjLmGERENijWNkd3XxyOwFNKMCp4kzjXLyKSrLhH5dnFzN4FFhNcPviVmb1nZm3ijENEZEPi7q0eTXCrhObu3gpoAUwLp4uIpI242xy7E9x9cB2Au68xs6uB72OOQ0SkVnHXHD8gGL8xUQ8g9WOni4gkqPeao5kNTXg5H3jJzF4kuH/MzsBAYFx9xyEisjHiOKzeucrrp8O/rYAS4D9A9buGi4ikUL0nR3f/XU3zzGxPYBDw2/qOQ0RkY8R+bbWZbWdml5vZDGAmQZvj5XHHISJSm1h6q82sMXAMcDbQD5gHjAfaAqe4+3dxxCEikqy4ao7LgfuBOcAB7t7V3W8haHMUEUk7cSXHTwlO+N4f2NfMWsa0XhGRXySW5OjuvQlG/H4VGAIsM7PngRygcRwxiIhsjNg6ZMJBJ25x947Ab4BvgfXAJ2Z2Z1xxiIgkIyUjgbv7e+5+AcE9ZC4luF2riEjaSOltEtz9J3cf7+4DUhmHiEhV6XAPGRGRtKPkKCISQclRRCSCkqOISAQlRxGRCEqOIiIRlBxFRCIoOYqIRFByFBGJoOQoIhJByVFEJIK5e6pj2GKY2QXu/kCq49jcaT/HZ3Pe16o5xuuCVAewhdB+js9mu6+VHEVEIig5iohEUHKM12bZNpOGtJ/js9nua3XIiIhEUM1RRCSCkqOISAQlx3pmZm+b2XmpjkMq0+dSMzMbZWa3pjqOVFNy3EhmdraZ/c/MisxsmZn908xahPNuMrNHUx3j5sDMFpnZ4TGt62wzey+OdaWb8J9EvpltlepY0o2S40Yws6uAO4A/Ac2BA4A2wGtm1qSe121mps9L6oyZtQUOBhw4JqXBpCH92JJkZs2Am4FL3X2Su69z90XAKQQJ8jzgOuBUM1tjZp8kvL2Nmf3XzH40s1fNbNuE5R5gZlPMbJWZfWJmvRPmvW1mt5nZf4EioH39b2l6Ka/VmdmIsIaz0MwGVJm/INy3C83sjHB6pVq8mbU1MzezzCrL3w34F9Az/NxWxbVtaWAQ8AEwChhcZd62ZvZauF/fMbM2EL0fE5sozKxDWL7AzFaa2YSEcl3CZf5gZnPM7JR638JNoOSYvAOBrYGnEye6+xrgZYL/wMOACe6e6+55CcV+C/wOaAU0AYYAmNmOwIvArcCvwulPmdl2Ce89i+ASrabA4rrfrAZhf2AOsC1wJ/BQWJPOAf4GDHD3pgSf0ccbs2B3/wK4EHg//Nxa1G3oaW0Q8Fj46Gdm2yfMOwO4hWCffxyWScYtwKtAS2An4O8A4Wf1GjCO4HdwOnCfme2+6ZtRP5Qck7ctsNLdSyPmfRvOr8kj7v6luxcDE4G9wulnAi+5+0vuvt7dXwOmAwMT3jvK3We5e6m7r6uD7WiIFrv7v929DBgN7ACU/5DXA93MLMvdv3X3WSmLsgExs4MIjngmuvtHwHyCf+LlXnT3ye5eAlxPULPeOYlFrwuX+2t3/8ndy9tyjwIWufsj4Xd5BvAUcFJdbVNdU3JM3kqCQ43MiHk7hPNrsizheRGQGz5vA5wcHlKvCg/pDgqXV27JJsS8uajYf+5eFD7NdfdC4FSCmt+3ZvaimXVJRYAN0GDgVXcv/96Oo/KhdcX3Ljw6+gH4dRLL/T/AgKlmNsvMzgmntwH2r/JdPwNovYnbUW+ifugS7X2gBDiBoPYHVBwuDCBob9xxI5e5BBjr7ufXUkaXMNXC3V8BXjGzLILmiX8TNHEUAtkJRWv7EW5R+zjcV6cAjcys/B/PVkALMytvDto5oXwuQbPPN8BP4eRsYHX4vGLfuvsy4PzwfQcBr5vZZILv+jvufkS9bFQ9UM0xSe5eQNAh83cz629mjcPevieAr4GxwHKg7Ub0Kj8KHG1m/cyskZltbWa9zWynetiEzY6ZbW9mx4T/oEqANUBZOPtj4BAz28XMmgPX1rKo5cBO9X3GQRo5jmA/dSVo4tkL2A14l6AdEmCgmR0U7pNbgA/dfYm7rwCWAmeG39lzgF3LF2xmJyd8f/MJ/vGUAS8AnczsrPC309jM9g07xNKSkuNGcPc7CWqIIwj+a35I8B/xN2HbzBNh0e/NbEYSy1sCHBsuc0W4rD+hzyVZGcBVBDWaH4BDgT8AhO23E4BPgY8Ifpw1eROYBSwzs9qaRzYXgwnawb9y92XlD+BegkPdTILD7L8Q7Nfu4fRy5xN8T78HdgemJMzbF/jQzNYAzwGXu/tCd/8R6AucRvB5LSM4LS5tz6/UwBMiIhFUQxERiaDkKCISQclRRCSCkqOISAQlRxGRCEqOkhQz+8zMbkp4vcjMhqQgjh7hwAdt4153KoXnv3rioCVSv5QcGygLBiT18LEuHJlmRHhCdBz2Be5LpmA4cs6aeo6nzoT7trbzIlNhCsFlpd+nOpAthS4fbNheJxi1pzHBJXMPAjnARVGFzaxxXQ1eEV4pITEIP7e1VL5GX+qZao4NW0l4dcMSdx9HMKzUcVDpMGygmU01s7VAv3De0Wb2kZn9FI6BeFvipXNm1srMnjWzYjNbnDB4AAllKh1Wm1kzC0ZF/zZc7hdmdqoF41M+AuQk1HRvCt/TxMzuMLOvzazQzKaZWb8q6+lvZrPDZb4LdNrQTgmXOyyMvSSsVV8WzmtkZg+F211sZnPN7P/KL/kMYxsMHJkQb+9w3o5m9rgF40rmhwNddKyy7mvNbLkFY0OOMbO/mNmihPkZZvZnM1sSxvY/Mzs2YX75eImnm9mbZlYM/D7qsNrMDrRg7MQiM1sa7v9mCfMPMbMPwlgKzOxDM+u2of0nIXfXowE+CAYofaHKtL8RDKsG0Jvgutb/EVy21R7YjiBBriYYX3JXoA/BWIkjEpbzEsHldL2AvYG3Ca5bvimhzCJgSPjcgP8CnwP9w3UNAI4nGL/ycoKBIFqHj9zwfY8RDLZ6SPieS4C1QF44f2eCgQ7+DnQhGCzh63C72tayb8aH5U4Ml9sHGBTOawwMJWgWaBsucxVwbjg/l+Cyw9cS4m1CMNDCl+F+3zOM50GCMTazw/eeFsZ7HkESvxYoIBiqqzy2K8P9/9uwzFCCa4/3Cue3DbdvEcFwXu0IxkUs/zy3DcvtEX4mVwEdCca8fB94MpyfSXBt84jwc+4SrnO3VH93G8oj5QHo8Qs/uCrJEdiPYNi0CeHr8h/TiVXeNxn4c5Vpx4U/NAt/sA70SpjfJvwB35QwbRE/J8cjCMZVjPzhAWcDa6pM2zV8zy5Vpj8D3Bc+HxYmJEuYfwO1JMcwUTjQfyP25e3A6zXt23DaOcDcKrE0ImgDPCV8/T7wryrve7VKclwK3FilzNvAo+Hz8uR4VZUyVZPjGOChKmX2Csu0IhhFx4FDU/1dbagPtTk2bP3Djo5MghrRs8ClVcpMr/K6O7CfmV2dMC0DyCKoJe1GkLSmls9098Vm9k0tcewNfOvBqNrJ2ocgGX9uZonTtyIYCIIwlg88/OWH3t/AcvcmiP+tmgqY2YUEtbs2BNvdmA2Pst6doBb3Y5V4s/l5VJouBEOmJfqQsCkgPOT9NUEtO9F7VB7gGKp/blHxdDCzUxOmlQe2q7u/b2ajCIZzewN4A3jCg8FOJAlKjg3bZIJbKKwDvvHozpbCKq8zCIZeeyKi7Ap+/oFtjF/yngyCms2+BPEnKt6E5db6njCZ/JXglhRTCA5xLyZoAqhNBsEwaKdFzPsh4XkyI7lElak6rernFhXPg8A9EfOWArj778zsrwRNHccAt5nZcR6MgSkboOTYsBW5+7yNfM8MoEtN7zOzLwh+ePsSDkVlZrtQ+yjQM4AdzGy3GmqPawkOQRPNJEhkrd29plre58CJZmYJtccDaomjPJYMgnbGSRHzDyIYm/De8glmtmuVMlHxziC478lKd6/pJlyzCZo3HkmYtl/5E3dfHdbAD+Ln2nF5TJ/XtEE1mAHsvqHP390/AT4B7jCzlwk6m5Qck6De6i3PUOC3ZjbUzLpZcEe4k8zsTgB3n0OQVO43s55mthdBG1xxzYvkDYLDx6csGLi3nZkdYWbHhfMXAVuH07Y1s2x3/5KgQ2ZUuP72FpzgPcTMTgjf9y+CNri/mllnMzuJ4JYINXL3uQQjtT9oZieGsRxsZmeFRb4E9jGzAWbW0cz+TDAOZKJFBPel6RzG2ziMdTnwrJkdGi73EDMbmdBj/f+As83snHDZ/0fQUZJYK7wLGBL2Rncys6EEp2GNrG27ItxB0DzyLzPb24K7/h1lZvcDhPHdHvZotzGzPgQdSRubhLdcqW701OOXPYjoNKgyvzcJDfhV5vUlGPW5iOCwcjpwScL87QkGKi0mGID3POAzauiQCV+3IGhvW0HQY/s5YUdFOP+fBB1GXr4cgra+m4AFBLW1ZeF6uye870iC3vSfCNrqzmDDvdVbEdylcCnBCOHzy7ePoOf5IYKe3FXh8xup3GmyHUFHyo/hunon7JdHgO/C5S4EHk7cxwQDF39H0ME1hqCz54uE+RnAn8P9upbgbILjEua3DdfZY0OfJ9CD4B/ZaoLD8P8BQxNifTphH3wV7pPGqf7uNpSHBrsVqUdm9h8g092PTnUssnHU5ihSR8wsm+DqpElAKcF5lseGf6WBUc1RpI5YcFe/5wlOJ8oiOC/yTnd/LKWByS+i5CgiEkG91SIiEZQcRUQiKDmKiERQchQRiaDkKCISQclRRCTC/wdisaGrH09U+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Confusion Matrix: \")\n",
    "print(sklearn.metrics.confusion_matrix(y_test, y_hat))\n",
    "\n",
    "print(\"Recall: \")\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_test,y_hat)\n",
    "matrix_proportions = np.zeros((3,3))\n",
    "for i in range(0,3):\n",
    "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
    "names=['Other','Insult','Abuse']\n",
    "confusion_df = pd.DataFrame(matrix_proportions, index=names,columns=names)\n",
    "plt.figure(figsize=(5,5))\n",
    "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
    "plt.ylabel(r'True categories',fontsize=14)\n",
    "plt.xlabel(r'Predicted categories',fontsize=14)\n",
    "plt.tick_params(labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for this run will be stored in /home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/TestResults/Test_594\n"
     ]
    }
   ],
   "source": [
    "# Create a new folder to hold statistics for a run\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "# create a random folder number to reference the directory\n",
    "rand = random.randint(0, 1000)*random.randint(0,10)\n",
    "directory = '/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/TestResults/Test_' + str(rand)\n",
    "print('The results for this run will be stored in ' + directory)\n",
    "createFolder(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results partially shown below\n",
      "   mean_test_score  mean_fit_time  \\\n",
      "0         0.924990      28.918569   \n",
      "1         0.000000       5.174078   \n",
      "2         0.615673       7.057591   \n",
      "3         0.399526     163.661626   \n",
      "4         0.000000     360.091432   \n",
      "\n",
      "                                              params  rank_test_scores  \\\n",
      "0  {'balancing:strategy': 'none', 'categorical_en...                 1   \n",
      "1  {'balancing:strategy': 'weighting', 'categoric...                 8   \n",
      "2  {'balancing:strategy': 'none', 'categorical_en...                 6   \n",
      "3  {'balancing:strategy': 'weighting', 'categoric...                 7   \n",
      "4  {'balancing:strategy': 'none', 'categorical_en...                 8   \n",
      "\n",
      "    status param_balancing:strategy param_categorical_encoding:__choice__  \\\n",
      "0  Success                     none                      one_hot_encoding   \n",
      "1   Memout                weighting                      one_hot_encoding   \n",
      "2  Success                     none                           no_encoding   \n",
      "3  Success                weighting                      one_hot_encoding   \n",
      "4    Crash                     none                      one_hot_encoding   \n",
      "\n",
      "  param_classifier:__choice__ param_imputation:strategy  \\\n",
      "0               random_forest                      mean   \n",
      "1                 extra_trees                      mean   \n",
      "2         k_nearest_neighbors                      mean   \n",
      "3                  libsvm_svc                      mean   \n",
      "4                 extra_trees                      mean   \n",
      "\n",
      "  param_preprocessor:__choice__  ...  \\\n",
      "0              no_preprocessing  ...   \n",
      "1                    polynomial  ...   \n",
      "2                  select_rates  ...   \n",
      "3         feature_agglomeration  ...   \n",
      "4                    polynomial  ...   \n",
      "\n",
      "  param_classifier:xgradient_boosting:normalize_type  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "  param_classifier:xgradient_boosting:rate_drop  \\\n",
      "0                                           NaN   \n",
      "1                                           NaN   \n",
      "2                                           NaN   \n",
      "3                                           NaN   \n",
      "4                                           NaN   \n",
      "\n",
      "   param_classifier:xgradient_boosting:sample_type  \\\n",
      "0                                              NaN   \n",
      "1                                              NaN   \n",
      "2                                              NaN   \n",
      "3                                              NaN   \n",
      "4                                              NaN   \n",
      "\n",
      "   param_preprocessor:fast_ica:n_components  \\\n",
      "0                                       NaN   \n",
      "1                                       NaN   \n",
      "2                                       NaN   \n",
      "3                                       NaN   \n",
      "4                                       NaN   \n",
      "\n",
      "   param_preprocessor:kernel_pca:coef0  param_preprocessor:kernel_pca:degree  \\\n",
      "0                                  NaN                                   NaN   \n",
      "1                                  NaN                                   NaN   \n",
      "2                                  NaN                                   NaN   \n",
      "3                                  NaN                                   NaN   \n",
      "4                                  NaN                                   NaN   \n",
      "\n",
      "   param_preprocessor:kernel_pca:gamma  \\\n",
      "0                                  NaN   \n",
      "1                                  NaN   \n",
      "2                                  NaN   \n",
      "3                                  NaN   \n",
      "4                                  NaN   \n",
      "\n",
      "   param_preprocessor:nystroem_sampler:coef0  \\\n",
      "0                                        NaN   \n",
      "1                                        NaN   \n",
      "2                                        NaN   \n",
      "3                                        NaN   \n",
      "4                                        NaN   \n",
      "\n",
      "   param_preprocessor:nystroem_sampler:degree  \\\n",
      "0                                         NaN   \n",
      "1                                         NaN   \n",
      "2                                         NaN   \n",
      "3                                         NaN   \n",
      "4                                         NaN   \n",
      "\n",
      "   param_preprocessor:nystroem_sampler:gamma  \n",
      "0                                        NaN  \n",
      "1                                        NaN  \n",
      "2                                        NaN  \n",
      "3                                        NaN  \n",
      "4                                        NaN  \n",
      "\n",
      "[5 rows x 177 columns]\n"
     ]
    }
   ],
   "source": [
    "# Saves the cv results to a csv in the folder specified\n",
    "results = automl.cv_results_ #A dict with keys as column headers and values as columns, \n",
    "                             #that can be imported into a pandas DataFrame\n",
    "\n",
    "# dict --> pandas dataframe\n",
    "cv_results = pd.DataFrame.from_dict(results)\n",
    "print('CV Results partially shown below')\n",
    "print(cv_results.head())\n",
    "cv_results.to_csv(directory+'/cv_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results partially shown below\n",
      "[(0.62, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01},\n",
      "dataset_properties={\n",
      "  'task': 2,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': True,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})), (0.12, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'normalize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5240592829918601, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 10, 'classifier:random_forest:min_samples_split': 16, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00012586572428922356},\n",
      "dataset_properties={\n",
      "  'task': 2,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': True,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})), (0.1, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'k_nearest_neighbors', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'normalize', 'classifier:k_nearest_neighbors:n_neighbors': 4, 'classifier:k_nearest_neighbors:p': 2, 'classifier:k_nearest_neighbors:weights': 'uniform', 'preprocessor:select_rates:alpha': 0.1, 'preprocessor:select_rates:mode': 'fpr', 'preprocessor:select_rates:score_func': 'chi2'},\n",
      "dataset_properties={\n",
      "  'task': 2,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': True,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})), (0.08, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'gradient_boosting', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'quantile_transformer', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False', 'classifier:gradient_boosting:criterion': 'mse', 'classifier:gradient_boosting:learning_rate': 0.3795924768593385, 'classifier:gradient_boosting:loss': 'deviance', 'classifier:gradient_boosting:max_depth': 2, 'classifier:gradient_boosting:max_features': 0.33708497069988536, 'classifier:gradient_boosting:max_leaf_nodes': 'None', 'classifier:gradient_boosting:min_impurity_decrease': 0.0, 'classifier:gradient_boosting:min_samples_leaf': 15, 'classifier:gradient_boosting:min_samples_split': 13, 'classifier:gradient_boosting:min_weight_fraction_leaf': 0.0, 'classifier:gradient_boosting:n_estimators': 451, 'classifier:gradient_boosting:subsample': 0.7716323242090217, 'preprocessor:select_rates:alpha': 0.2573946506994812, 'preprocessor:select_rates:mode': 'fwe', 'preprocessor:select_rates:score_func': 'f_classif', 'rescaling:quantile_transformer:n_quantiles': 1000, 'rescaling:quantile_transformer:output_distribution': 'uniform'},\n",
      "dataset_properties={\n",
      "  'task': 2,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': True,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})), (0.04, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'gradient_boosting', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'robust_scaler', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:gradient_boosting:criterion': 'mse', 'classifier:gradient_boosting:learning_rate': 0.053517066400173056, 'classifier:gradient_boosting:loss': 'deviance', 'classifier:gradient_boosting:max_depth': 10, 'classifier:gradient_boosting:max_features': 0.542144980834302, 'classifier:gradient_boosting:max_leaf_nodes': 'None', 'classifier:gradient_boosting:min_impurity_decrease': 0.0, 'classifier:gradient_boosting:min_samples_leaf': 20, 'classifier:gradient_boosting:min_samples_split': 13, 'classifier:gradient_boosting:min_weight_fraction_leaf': 0.0, 'classifier:gradient_boosting:n_estimators': 233, 'classifier:gradient_boosting:subsample': 0.7398539900055563, 'preprocessor:select_rates:alpha': 0.0614425536709615, 'preprocessor:select_rates:mode': 'fwe', 'preprocessor:select_rates:score_func': 'f_classif', 'rescaling:robust_scaler:q_max': 0.9523118062307263, 'rescaling:robust_scaler:q_min': 0.13434811490315818, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.02345017287074443},\n",
      "dataset_properties={\n",
      "  'task': 2,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': True,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})), (0.04, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'gaussian_nb', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'robust_scaler', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'rescaling:robust_scaler:q_max': 0.8245132980938538, 'rescaling:robust_scaler:q_min': 0.08947420373097192, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00034835629696198427},\n",
      "dataset_properties={\n",
      "  'task': 2,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': True,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False}))]\n"
     ]
    }
   ],
   "source": [
    "# Saves the model info to the directory specified\n",
    "models = automl.get_models_with_weights() # Return a list of the final ensemble found by auto-sklearn.\n",
    "# depending on how many models were made might need to change the below line\n",
    "model_info = pd.DataFrame.from_dict([models[0], models[1], models[2], models[3], models[4], models[5]])\n",
    "                            #models[6], models[7], models[8], models[9], models[10], models[11]])\n",
    "\n",
    "model_info.to_csv(directory+'/model_info.csv')\n",
    "print('Model Results partially shown below')\n",
    "print(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
