{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/featureExtraction\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.chdir('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/featureExtraction/')\n",
    "%cd ../featureExtraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from featurE_eng.ipynb\n",
      "Completing ngram generation for train\n",
      "Completing ngram generation for test\n",
      "Completing char-ngram generation for train\n",
      "Completing char-ngram generation for test\n",
      "Completing tfidf+ngram generation for train\n",
      "Completing tfidf+ngram generation for test\n",
      "Completing char-tfidf+ngram generation for train\n",
      "Completing char-tfidf+ngram generation for test\n",
      "Completing the sentiment analysis for train\n",
      "Completing the sentiment analysis for test\n",
      "Completing the liguistic feature extraction for train\n",
      "Completing the liguistic feature extraction for test\n",
      "Completing the readability scores extraction for train\n",
      "Completing the readability scores extraction for test\n",
      "Concatenating in process\n",
      "Did it!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import import_ipynb\n",
    "from featurE_eng import getTrainData, getTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19808, 4032)\n"
     ]
    }
   ],
   "source": [
    "# retrieve the features from the featureExtraction file\n",
    "data = getTrainData()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the features and target variable\n",
    "X = data.iloc[:,0:4030]  #independent columns, change column number depending on what we have for shape\n",
    "y = data.iloc[:,-2]    #target column i.e labels\n",
    "y_string = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate Selection features found, use getUnivariateData() to get the features\n",
      "          Specs        Score\n",
      "75     bitch_nw  1880.111408\n",
      "1342    bitc_nc  1878.096858\n",
      "1343   bitch_nc  1878.096858\n",
      "1022    bitc_nc  1877.593354\n",
      "1602   itch _nc  1864.593042\n",
      "1021     bit_nc  1846.728725\n",
      "1341     bit_nc  1840.749266\n",
      "1601    itch_nc  1837.998935\n",
      "1600     itc_nc  1834.324330\n",
      "1889    tch _nc  1709.313722\n",
      "1888     tch_nc  1675.051534\n",
      "1887      tc_nc  1657.428884\n",
      "3342    bitc_tc  1530.192525\n",
      "3343   bitch_tc  1530.192525\n",
      "3022    bitc_tc  1529.876762\n",
      "3602   itch _tc  1529.871140\n",
      "3601    itch_tc  1518.734150\n",
      "3600     itc_tc  1517.178436\n",
      "3021     bit_tc  1511.387977\n",
      "3341     bit_tc  1509.217853\n",
      "1361     ch _nc  1483.234231\n",
      "3889    tch _tc  1480.486044\n",
      "3888     tch_tc  1470.295649\n",
      "3887      tc_tc  1463.245805\n",
      "4000  sentiment  1374.994295\n",
      "3361     ch _tc  1363.456086\n",
      "3598      it_tc  1193.740148\n",
      "1018      bi_nc  1140.308383\n",
      "3018      bi_tc  1085.071235\n",
      "1598      it_nc  1058.805136\n",
      "...         ...          ...\n",
      "1934      uc_nc   161.767759\n",
      "1645   llow _nc   160.985916\n",
      "3603     ite_tc   160.893722\n",
      "3535      ho_tc   160.610619\n",
      "3643     llo_tc   159.131590\n",
      "3862      ss_tc   157.392233\n",
      "3167      pu_tc   156.784519\n",
      "3559      ig_tc   156.362995\n",
      "1644    llow_nc   154.621510\n",
      "603    nigga_nw   154.195081\n",
      "1488     gga_nc   154.195081\n",
      "1489    gga _nc   154.195081\n",
      "1563    igga_nc   154.195081\n",
      "1564   igga _nc   154.195081\n",
      "1704   nigga_nc   154.195081\n",
      "3934      uc_tc   153.939563\n",
      "3440     er _tc   153.324597\n",
      "1643     llo_nc   152.988501\n",
      "2603   nigga_tw   151.473046\n",
      "1604    ite _nc   146.994181\n",
      "1559      ig_nc   146.312041\n",
      "1546      ia_nc   145.128361\n",
      "1167      pu_nc   144.993749\n",
      "3061       f_tc   142.366003\n",
      "1481     ga _nc   141.815616\n",
      "1440     er _nc   141.313396\n",
      "2144  browni_tw   139.988841\n",
      "3481     ga _tc   139.892569\n",
      "3794      pu_tc   139.226080\n",
      "3604    ite _tc   139.057874\n",
      "\n",
      "[300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Univariate Selection -- apply SelectKBest class to extract top n best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=300)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print('Univariate Selection features found, use getUnivariateData() to get the features')\n",
    "# Extract the top n features\n",
    "uni_selected_feat = featureScores.nlargest(300,'Score')\n",
    "print(uni_selected_feat) # print out the top n features selected\n",
    "\n",
    "# Saving the top n features to a data frame\n",
    "#print(a.iloc[0].name) # how to get the column # for the ith feature\n",
    "#print(a.iloc[0][0]) # how to get the header column\n",
    "top_univariate_features = pd.DataFrame()\n",
    "for i in range(0, 300):\n",
    "    curr_column_vals = X.iloc[:, uni_selected_feat.iloc[i].name]\n",
    "    curr_column_name = uni_selected_feat.iloc[i][0]\n",
    "    top_univariate_features[curr_column_name] = curr_column_vals\n",
    "#top_univariate_features.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\UnivariateFeatures.csv', index=None, header=True, encoding='utf-8')\n",
    "#y.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TrainLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_string.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TrainStringLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "top_univariate_features.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/UnivariateFeatures_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/TrainLabels.csv', index=None, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance results saved, use getFeatureImpt() to get the features\n",
      "bitch_tc     0.007459\n",
      "hoe _tc      0.006684\n",
      "itc_tc       0.006245\n",
      " bit_nc      0.006111\n",
      "oe_tc        0.005920\n",
      " bitc_nc     0.005770\n",
      "hoe_nw       0.005488\n",
      "bitc_tc      0.005457\n",
      "sentiment    0.005431\n",
      " hoe_tc      0.005326\n",
      "bit_tc       0.005263\n",
      "bi_nc        0.005070\n",
      " hoe _tc     0.005030\n",
      " bitc_tc     0.005003\n",
      "tch _tc      0.004941\n",
      "oe _tc       0.004896\n",
      "tc_nc        0.004832\n",
      "itch_nc      0.004796\n",
      "oe _nc       0.004770\n",
      "itch _tc     0.004691\n",
      "hoe_tc       0.004682\n",
      "hoe_tw       0.004562\n",
      " bit_tc      0.004480\n",
      "itch_tc      0.004474\n",
      " hoe_nc      0.004436\n",
      "hoe_nc       0.004436\n",
      " hoe _nc     0.004416\n",
      "hoe _nc      0.004411\n",
      "bitc_nc      0.004373\n",
      "itc_nc       0.004367\n",
      "               ...   \n",
      "rd_tc        0.000774\n",
      "rd _tc       0.000773\n",
      "llow _nc     0.000768\n",
      " ch_nc       0.000761\n",
      " tr_tc       0.000760\n",
      "nica_nw      0.000757\n",
      "eta_nc       0.000756\n",
      " tr_nc       0.000756\n",
      "shit_tw      0.000752\n",
      "i _nc        0.000749\n",
      " fa_nc       0.000746\n",
      "retard_tw    0.000745\n",
      "uc_tc        0.000744\n",
      "ga_tc        0.000744\n",
      "si_tc        0.000742\n",
      "cu_tc        0.000737\n",
      "nica_tw      0.000732\n",
      " shi_nc      0.000731\n",
      "er _tc       0.000728\n",
      "t _tc        0.000724\n",
      "faggot_nw    0.000721\n",
      "nigah_tw     0.000714\n",
      "ger_tc       0.000712\n",
      "us_nc        0.000710\n",
      "shi_nc       0.000705\n",
      "ag_nc        0.000699\n",
      "ank_tc       0.000699\n",
      "ar_nc        0.000695\n",
      "aggo_tc      0.000694\n",
      " fu_nc       0.000691\n",
      "Length: 300, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance \n",
    "model = ExtraTreesClassifier(n_estimators=300)\n",
    "model.fit(X,y)\n",
    "print('Feature Importance results saved, use getFeatureImpt() to get the features')\n",
    "#print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "top_feat_impt = feat_importances.nlargest(300) \n",
    "print(top_feat_impt) # prints out the n best features\n",
    "\n",
    "# The top n most important features in bar graph\n",
    "#top_feat_impt.plot(figsize=(75, 25),fontsize=40,kind='bar')\n",
    "#plt.show()\n",
    "\n",
    "# Saving the top n features to a dataframe\n",
    "list_names = top_feat_impt.axes \n",
    "best_impt_features = pd.DataFrame()\n",
    "#print(X.columns.get_loc(list[0][0])) # how to get the index of the column/name from the feature selected names\n",
    "for i in range(0, 300):\n",
    "    curr_column_name = list_names[0][i]\n",
    "    curr_column_index = X.columns.get_loc(curr_column_name)\n",
    "    curr_column_vals = X.iloc[:, curr_column_index]\n",
    "    best_impt_features[curr_column_name] = curr_column_vals\n",
    "#best_impt_features.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\ImportanceFeatures.csv', index=None, header=True, encoding='utf-8')\n",
    "#y.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TrainLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_string.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TrainStringLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "best_impt_features.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/ImportanceFeatures_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/TrainLabels.csv', index=None, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "' fagg_tc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2655\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2656\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2657\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ' fagg_tc'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0d2c0e60d7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcurr_column_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcurr_column_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_column_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mcurr_column_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_column_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mbest_impt_features_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_column_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_column_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ' fagg_tc'"
     ]
    }
   ],
   "source": [
    "# Feature extraction for test data\n",
    "data_test = getTestData()\n",
    "X_test = data_test.iloc[:,0:4030]\n",
    "y_test = data_test.iloc[:,-2]\n",
    "y_string_test = data_test.iloc[:,-1]\n",
    "\n",
    "# univariate\n",
    "top_univariate_features_test = pd.DataFrame()\n",
    "for i in range(0, 300):\n",
    "    curr_column_vals = X_test.iloc[:, uni_selected_feat.iloc[i].name]\n",
    "    curr_column_name = uni_selected_feat.iloc[i][0]\n",
    "    top_univariate_features_test[curr_column_name] = curr_column_vals\n",
    "    \n",
    "#top_univariate_features_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\UnivariateFeaturesTest.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TestLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_string_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TestStringLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "top_univariate_features_test.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/UnivariateFeaturesTest_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_test.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/TestLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "\n",
    "# Saving the top n features to a dataframe\n",
    "list_names = top_feat_impt.axes \n",
    "best_impt_features_test = pd.DataFrame()\n",
    "#print(X.columns.get_loc(list[0][0])) # how to get the index of the column/name from the feature selected names\n",
    "for i in range(0, 300):\n",
    "    curr_column_name = list_names[0][i]\n",
    "    curr_column_index = X_test.columns.get_loc(curr_column_name)\n",
    "    curr_column_vals = X_test.iloc[:, curr_column_index]\n",
    "    best_impt_features_test[curr_column_name] = curr_column_vals\n",
    "\n",
    "#best_impt_features_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\ImportanceFeaturesTest.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TestLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_string_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TestStringLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "best_impt_features_test.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/ImportanceFeaturesTest_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_test.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/TestLabels.csv', index=None, header=True, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for returning top features of different feature selection algorithms\n",
    "def getUnivariateData():\n",
    "    return top_univariate_features\n",
    "\n",
    "def getFeatureImpt():\n",
    "    return best_impt_features\n",
    "\n",
    "def getLabels():\n",
    "    return y\n",
    "\n",
    "# Test data\n",
    "def getUnivariateTestData():\n",
    "    return top_univariate_features_test\n",
    "\n",
    "def getFeatureImptTest():\n",
    "    return best_impt_features_test\n",
    "\n",
    "def getTestLabels():\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the univariate and featureImpt selected features\n",
    "titles_univariate = getUnivariateData().columns\n",
    "titles_impt = getFeatureImpt().columns\n",
    "count = 0\n",
    "for i in range(0, len(titles_univariate)):\n",
    "    if titles_univariate[i] in titles_impt:\n",
    "        #print(titles_univariate[i]+' in both!')\n",
    "        count+=1\n",
    "print('The number of same features selected is: ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix with Heatmap -- get correlations of each features in dataset\n",
    "#corrmat = data.corr()\n",
    "#top_corr_features = corrmat.index\n",
    "#plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "#g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
