{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\mikec\\\\Codes\\\\DAADRISE_AbusiveLangProject\\\\featureExtraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import import_ipynb\n",
    "from featurE_eng import getData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19808, 4019)\n"
     ]
    }
   ],
   "source": [
    "# retrieve the features from the featureExtraction file\n",
    "data = getData()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the features and target variable\n",
    "X = data.iloc[:,0:4018]  #independent columns, change column number depending on what we have for shape\n",
    "y = data.iloc[:,-1]    #target column i.e labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if nan values check\n",
    "#print(np.where(np.isnan(X)))\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate Selection results:\n",
      "          Specs        Score\n",
      "75        bitch  1880.111408\n",
      "1342       bitc  1878.096858\n",
      "1343      bitch  1878.096858\n",
      "1022       bitc  1877.593354\n",
      "1602      itch   1864.593042\n",
      "1021        bit  1846.728725\n",
      "1341        bit  1840.749266\n",
      "1601       itch  1837.998935\n",
      "1600        itc  1834.324330\n",
      "1889       tch   1709.313722\n",
      "1888        tch  1675.051534\n",
      "1887         tc  1657.428884\n",
      "3342       bitc  1530.192525\n",
      "3343      bitch  1530.192525\n",
      "3022       bitc  1529.876762\n",
      "3602      itch   1529.871140\n",
      "3601       itch  1518.734150\n",
      "3600        itc  1517.178436\n",
      "3021        bit  1511.387977\n",
      "3341        bit  1509.217853\n",
      "1361        ch   1483.234231\n",
      "3889       tch   1480.486044\n",
      "3888        tch  1470.295649\n",
      "3887         tc  1463.245805\n",
      "4000  sentiment  1374.994295\n",
      "3361        ch   1363.456086\n",
      "3598         it  1193.740148\n",
      "1018         bi  1140.308383\n",
      "3018         bi  1085.071235\n",
      "1598         it  1058.805136\n",
      "...         ...          ...\n",
      "3265      aggot   640.282633\n",
      "3490        ggo   640.282633\n",
      "3491       ggot   640.282633\n",
      "3492      ggot    640.282633\n",
      "1487         gg   634.548911\n",
      "1222        tra   633.329473\n",
      "3222        tra   632.225707\n",
      "3263        agg   630.281415\n",
      "1311       ash    625.644394\n",
      "3310        ash   607.061764\n",
      "73         bird   600.002107\n",
      "1340      bird    599.956588\n",
      "1339       bird   594.072442\n",
      "1020       bird   594.043133\n",
      "2293     faggot   586.275346\n",
      "3340      bird    585.368957\n",
      "3339       bird   583.193751\n",
      "3020       bird   582.356401\n",
      "1310        ash   581.084876\n",
      "1593       ird    565.110878\n",
      "2073       bird   562.066917\n",
      "3593       ird    558.033491\n",
      "3011          b   556.639192\n",
      "1592        ird   555.959648\n",
      "3922        tra   552.550895\n",
      "3592        ird   550.479944\n",
      "1922        tra   535.857188\n",
      "3261         ag   534.038330\n",
      "1800         ra   528.413911\n",
      "1514         h    522.048688\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Univariate Selection -- apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=100)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print('Univariate Selection results:')\n",
    "print(featureScores.nlargest(100,'Score'))  #print 100 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance results:\n",
      "[1.08898437e-05 6.61052476e-05 4.84340418e-05 ... 2.13817808e-03\n",
      " 1.34440640e-03 1.58261849e-03]\n",
      " bitc                   0.011740\n",
      " hoe                    0.009305\n",
      "bitch                   0.008314\n",
      "bit                     0.007690\n",
      "hoe                     0.007427\n",
      "sentiment               0.006896\n",
      "bit                     0.006288\n",
      "itch                    0.006183\n",
      "bitc                    0.005932\n",
      "tch                     0.005692\n",
      "itch                    0.005653\n",
      "oe                      0.005638\n",
      "itch                    0.005629\n",
      " hoe                    0.005530\n",
      " bit                    0.005481\n",
      "hoe                     0.005356\n",
      "hoe                     0.005256\n",
      " bitc                   0.005237\n",
      "ch                      0.005058\n",
      " hoe                    0.005034\n",
      " bit                    0.004821\n",
      "oe                      0.004793\n",
      " hoe                    0.004677\n",
      "tc                      0.004450\n",
      "oe                      0.004340\n",
      "bitch                   0.004318\n",
      "itc                     0.004295\n",
      "bitch                   0.004237\n",
      "oe                      0.004196\n",
      "ussi                    0.003989\n",
      "                          ...   \n",
      "trash                   0.002265\n",
      "si                      0.002263\n",
      "ssi                     0.002246\n",
      "fag                     0.002232\n",
      " fag                    0.002214\n",
      "charli                  0.002196\n",
      "ch                      0.002176\n",
      " puss                   0.002173\n",
      "coleman liau index      0.002138\n",
      "bi                      0.002094\n",
      "puss                    0.002068\n",
      " ni                     0.002066\n",
      "arl                     0.002055\n",
      "ird                     0.001971\n",
      "number of words         0.001932\n",
      "pussi                   0.001924\n",
      "nig                     0.001879\n",
      " bi                     0.001870\n",
      "bird                    0.001863\n",
      "shit                    0.001861\n",
      "flesch reading ease     0.001861\n",
      "pussi                   0.001831\n",
      "number of links         0.001807\n",
      " puss                   0.001785\n",
      " nig                    0.001758\n",
      "flesch kincaid grade    0.001740\n",
      "bird                    0.001713\n",
      "us                      0.001685\n",
      " b                      0.001666\n",
      " fuck                   0.001637\n",
      "Length: 100, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19808, 828)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance \n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,y)\n",
    "print('Feature Importance results:')\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "print(feat_importances.nlargest(100))\n",
    "clf = SelectFromModel(model, prefit=True)\n",
    "X_new = clf.transform(X)\n",
    "X_new.shape  \n",
    "\n",
    "#feat_importances.nlargest(100).plot(kind='barh')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix with Heatmap -- get correlations of each features in dataset\n",
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
