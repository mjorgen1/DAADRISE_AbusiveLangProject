{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "C:\\Users\\mikec\\Codes\\DAADRISE_AbusiveLangProject\\featureExtraction\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#import os\n",
    "#os.chdir('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/featureExtraction/')\n",
    "%cd ../featureExtraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from featurE_eng.ipynb\n",
      "Completing ngram generation for train",
      "\n",
      "Completing ngram generation for test",
      "\n",
      "Completing char-ngram generation for train",
      "\n",
      "Completing char-ngram generation for test",
      "\n",
      "Completing tfidf+ngram generation for train",
      "\n",
      "Completing tfidf+ngram generation for test",
      "\n",
      "Completing char-tfidf+ngram generation for train",
      "\n",
      "Completing char-tfidf+ngram generation for test",
      "\n",
      "Completing the sentiment analysis for train",
      "\n",
      "Completing the sentiment analysis for test",
      "\n",
      "Completing the liguistic feature extraction for train",
      "\n",
      "Completing the liguistic feature extraction for test",
      "\n",
      "Completing the readability scores extraction for train",
      "\n",
      "Completing the readability scores extraction for test",
      "\n",
      "Concatenating in process",
      "\n",
      "Did it!",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import import_ipynb\n",
    "from featurE_eng import getTrainData, getTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the features from the featureExtraction file\n",
    "data = getTrainData()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the features and target variable\n",
    "X = data.iloc[:,0:4030]  #independent columns, change column number depending on what we have for shape\n",
    "y = data.iloc[:,-1]    #target column i.e labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Selection -- apply SelectKBest class to extract top 100 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=100)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print('Univariate Selection features found, use getUnivariateData() to get the features')\n",
    "# Extract the top 100 features\n",
    "uni_selected_feat = featureScores.nlargest(100,'Score')\n",
    "print(uni_selected_feat) # print out the top 100 features selected\n",
    "\n",
    "# Saving the top 100 features to a data frame\n",
    "#print(a.iloc[0].name) # how to get the column # for the ith feature\n",
    "#print(a.iloc[0][0]) # how to get the header column\n",
    "top_univariate_features = pd.DataFrame()\n",
    "for i in range(0, 100):\n",
    "    curr_column_vals = X.iloc[:, uni_selected_feat.iloc[i].name]\n",
    "    curr_column_name = uni_selected_feat.iloc[i][0]\n",
    "    top_univariate_features[curr_column_name] = curr_column_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance \n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,y)\n",
    "print('Feature Importance results saved, use getFeatureImpt() to get the features')\n",
    "#print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "top_feat_impt = feat_importances.nlargest(100) \n",
    "print(top_feat_impt) # prints out the 100 best features\n",
    "\n",
    "# The top 100 most important features in bar graph\n",
    "top_feat_impt.plot(figsize=(75, 25),fontsize=40,kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# Saving the top 100 features to a dataframe\n",
    "list_names = top_feat_impt.axes \n",
    "best_impt_features = pd.DataFrame()\n",
    "#print(X.columns.get_loc(list[0][0])) # how to get the index of the column/name from the feature selected names\n",
    "for i in range(0, 100):\n",
    "    curr_column_name = list_names[0][i]\n",
    "    curr_column_index = X.columns.get_loc(curr_column_name)\n",
    "    curr_column_vals = X.iloc[:, curr_column_index]\n",
    "    best_impt_features[curr_column_name] = curr_column_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature extraction for test data\n",
    "data_test = getTestData()\n",
    "X_test = data_test.iloc[:,0:4030]\n",
    "y_test = data_test.iloc[:,-1]\n",
    "\n",
    "# univariate\n",
    "top_univariate_features_test = pd.DataFrame()\n",
    "for i in range(0, 100):\n",
    "    curr_column_vals = X_test.iloc[:, uni_selected_feat.iloc[i].name]\n",
    "    curr_column_name = uni_selected_feat.iloc[i][0]\n",
    "    top_univariate_features_test[curr_column_name] = curr_column_vals\n",
    "\n",
    "# Saving the top 100 features to a dataframe\n",
    "list_names = top_feat_impt.axes \n",
    "best_impt_features_test = pd.DataFrame()\n",
    "#print(X.columns.get_loc(list[0][0])) # how to get the index of the column/name from the feature selected names\n",
    "for i in range(0, 100):\n",
    "    curr_column_name = list_names[0][i]\n",
    "    curr_column_index = X_test.columns.get_loc(curr_column_name)\n",
    "    curr_column_vals = X_test.iloc[:, curr_column_index]\n",
    "    best_impt_features_test[curr_column_name] = curr_column_vals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for returning top features of different feature selection algorithms\n",
    "def getUnivariateData():\n",
    "    return top_univariate_features\n",
    "\n",
    "def getFeatureImpt():\n",
    "    return best_impt_features\n",
    "\n",
    "def getLabels():\n",
    "    return y\n",
    "\n",
    "# Test data\n",
    "def getUnivariateTestData():\n",
    "    return top_univariate_features_test\n",
    "\n",
    "def getFeatureImptTest():\n",
    "    return best_impt_features_test\n",
    "\n",
    "def getTestLabels():\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the univariate and featureImpt selected features\n",
    "titles_univariate = getUnivariateData().columns\n",
    "titles_impt = getFeatureImpt().columns\n",
    "count = 0\n",
    "for i in range(0, len(titles_univariate)):\n",
    "    if titles_univariate[i] in titles_impt:\n",
    "        #print(titles_univariate[i]+' in both!')\n",
    "        count+=1\n",
    "print('The number of same features selected is: ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix with Heatmap -- get correlations of each features in dataset\n",
    "#corrmat = data.corr()\n",
    "#top_corr_features = corrmat.index\n",
    "#plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "#g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}