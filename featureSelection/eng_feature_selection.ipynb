{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/featureExtraction/')\n",
    "%cd ../featureExtraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from featurE_eng.ipynb\n",
      "Completing ngram generation for data\n",
      "Completing char-ngram generation for data\n",
      "Completing tfidf+ngram generation for data\n",
      "Completing char-tfidf+ngram generation for data\n",
      "Completing the sentiment analysis for data\n",
      "Completing the liguistic feature extraction for data\n",
      "Completing the readability scores extraction for data\n",
      "Concatenating in process\n",
      "Finished it!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import import_ipynb\n",
    "from featurE_eng import getTrainData, getTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19808, 4031)\n"
     ]
    }
   ],
   "source": [
    "# retrieve the features from the featureExtraction file\n",
    "data = getTrainData()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the features and target variable\n",
    "X = data.iloc[:,0:4030]  #independent columns, change column number depending on what we have for shape\n",
    "y = data.iloc[:,-1]    #target column i.e labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate Selection features found, use getUnivariateData() to get the features\n",
      "          Specs        Score\n",
      "73     bitch_nw  1880.111408\n",
      "1344    bitc_nc  1878.096858\n",
      "1345   bitch_nc  1878.096858\n",
      "1022    bitc_nc  1877.593354\n",
      "1604   itch _nc  1864.593042\n",
      "1021     bit_nc  1846.728725\n",
      "1343     bit_nc  1840.749266\n",
      "1603    itch_nc  1837.998935\n",
      "1602     itc_nc  1834.324330\n",
      "1888    tch _nc  1709.313722\n",
      "1887     tch_nc  1675.051534\n",
      "1886      tc_nc  1657.428884\n",
      "3344    bitc_tc  1525.114134\n",
      "3345   bitch_tc  1525.114134\n",
      "3022    bitc_tc  1525.003752\n",
      "3604   itch _tc  1524.726531\n",
      "3603    itch_tc  1514.257239\n",
      "3602     itc_tc  1513.053572\n",
      "3021     bit_tc  1505.815578\n",
      "3343     bit_tc  1504.408861\n",
      "1365     ch _nc  1483.234231\n",
      "3888    tch _tc  1476.095008\n",
      "3887     tch_tc  1465.436196\n",
      "3886      tc_tc  1458.686086\n",
      "4000  sentiment  1374.994295\n",
      "3365     ch _tc  1359.247731\n",
      "3600      it_tc  1190.661817\n",
      "1018      bi_nc  1140.308383\n",
      "3018      bi_tc  1083.670486\n",
      "1600      it_nc  1058.805136\n",
      "...         ...          ...\n",
      "3705   nigga_tc   162.475228\n",
      "1033      ch_nc   162.101199\n",
      "1935      uc_nc   161.767759\n",
      "1646   llow _nc   160.985916\n",
      "3537      ho_tc   160.607252\n",
      "3605     ite_tc   159.983345\n",
      "3644     llo_tc   158.973994\n",
      "3167      pu_tc   156.692436\n",
      "3861      ss_tc   156.488132\n",
      "3561      ig_tc   156.119213\n",
      "1645    llow_nc   154.621510\n",
      "595    nigga_nw   154.195081\n",
      "1490     gga_nc   154.195081\n",
      "1491    gga _nc   154.195081\n",
      "1565    igga_nc   154.195081\n",
      "1566   igga _nc   154.195081\n",
      "1705   nigga_nc   154.195081\n",
      "3935      uc_tc   153.490056\n",
      "3442     er _tc   153.073262\n",
      "1644     llo_nc   152.988501\n",
      "2595   nigga_tw   152.965957\n",
      "1606    ite _nc   146.994181\n",
      "1561      ig_nc   146.312041\n",
      "1548      ia_nc   145.128361\n",
      "1167      pu_nc   144.993749\n",
      "1483     ga _nc   141.815616\n",
      "1442     er _nc   141.313396\n",
      "3061       f_tc   140.613220\n",
      "2144  browni_tw   140.271328\n",
      "3483     ga _tc   140.162242\n",
      "\n",
      "[300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Univariate Selection -- apply SelectKBest class to extract top n best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=300)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print('Univariate Selection features found, use getUnivariateData() to get the features')\n",
    "# Extract the top n features\n",
    "uni_selected_feat = featureScores.nlargest(300,'Score')\n",
    "print(uni_selected_feat) # print out the top n features selected\n",
    "\n",
    "# Saving the top n features to a data frame\n",
    "#print(a.iloc[0].name) # how to get the column # for the ith feature\n",
    "#print(a.iloc[0][0]) # how to get the header column\n",
    "top_univariate_features = pd.DataFrame()\n",
    "for i in range(0, 300):\n",
    "    curr_column_vals = X.iloc[:, uni_selected_feat.iloc[i].name]\n",
    "    curr_column_name = uni_selected_feat.iloc[i][0]\n",
    "    top_univariate_features[curr_column_name] = curr_column_vals\n",
    "#top_univariate_features.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\UnivariateFeatures_300.csv', index=None, header=True, encoding='utf-8')\n",
    "y.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TrainLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "#top_univariate_features.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/UnivariateFeatures_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/TrainLabels.csv', index=None, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance results saved, use getFeatureImpt() to get the features\n",
      "itch _tc               0.009137\n",
      "bitc_tc                0.008378\n",
      "bitch_nc               0.006746\n",
      "oe _tc                 0.005973\n",
      " hoe _tc               0.005926\n",
      "bitch_tc               0.005658\n",
      " hoe_nc                0.005619\n",
      "bitc_nc                0.005596\n",
      "tch _tc                0.005498\n",
      "hoe_nc                 0.005421\n",
      " hoe_tc                0.005317\n",
      "hoe _tc                0.005255\n",
      " hoe _nc               0.005201\n",
      " bit_tc                0.005155\n",
      "bit_tc                 0.004916\n",
      "tch _nc                0.004874\n",
      "itc_nc                 0.004753\n",
      "hoe_tw                 0.004744\n",
      "sentiment              0.004716\n",
      "hoe_nw                 0.004713\n",
      " bit_nc                0.004703\n",
      "ch _nc                 0.004680\n",
      "itc_tc                 0.004633\n",
      "tch_nc                 0.004538\n",
      "tch_tc                 0.004512\n",
      "oe_tc                  0.004494\n",
      "itch_tc                0.004461\n",
      "bit_nc                 0.004309\n",
      " bi_tc                 0.004260\n",
      "hoe_tc                 0.004129\n",
      "                         ...   \n",
      "er_nc                  0.000743\n",
      " pu_tc                 0.000742\n",
      "i _nc                  0.000739\n",
      "ggot_tc                0.000729\n",
      "eta_tc                 0.000727\n",
      "faggot_nw              0.000722\n",
      "ass_tw                 0.000715\n",
      " p_tc                  0.000715\n",
      "ash _nc                0.000714\n",
      "eta_nc                 0.000713\n",
      "llow _tc               0.000712\n",
      "ank_tc                 0.000712\n",
      "ar_nc                  0.000709\n",
      "ck_tc                  0.000709\n",
      " pu_nc                 0.000709\n",
      "faggo_tc               0.000700\n",
      "unt_nc                 0.000697\n",
      "a _tc                  0.000696\n",
      "ra_nc                  0.000692\n",
      "aggot_nc               0.000689\n",
      "nigga_tc               0.000689\n",
      "number of emoticons    0.000688\n",
      "cha_nc                 0.000686\n",
      "ar_tc                  0.000685\n",
      "ss_nc                  0.000682\n",
      "nic_nc                 0.000679\n",
      "er _tc                 0.000677\n",
      "ck _tc                 0.000677\n",
      "rd_nc                  0.000676\n",
      "shi_nc                 0.000674\n",
      "Length: 300, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance \n",
    "model = ExtraTreesClassifier(n_estimators=300)\n",
    "model.fit(X,y)\n",
    "print('Feature Importance results saved, use getFeatureImpt() to get the features')\n",
    "#print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "top_feat_impt = feat_importances.nlargest(300) \n",
    "print(top_feat_impt) # prints out the n best features\n",
    "\n",
    "# The top n most important features in bar graph\n",
    "#top_feat_impt.plot(figsize=(75, 25),fontsize=40,kind='bar')\n",
    "#plt.show()\n",
    "\n",
    "# Saving the top n features to a dataframe\n",
    "list_names = top_feat_impt.axes \n",
    "best_impt_features = pd.DataFrame()\n",
    "#print(X.columns.get_loc(list[0][0])) # how to get the index of the column/name from the feature selected names\n",
    "for i in range(0, 300):\n",
    "    curr_column_name = list_names[0][i]\n",
    "    curr_column_index = X.columns.get_loc(curr_column_name)\n",
    "    curr_column_vals = X.iloc[:, curr_column_index]\n",
    "    best_impt_features[curr_column_name] = curr_column_vals\n",
    "#best_impt_features.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\ImportanceFeatures_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TrainLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "#best_impt_features.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/ImportanceFeatures_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/TrainLabels.csv', index=None, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Feature extraction for test data\n",
    "data_test = getTestData()\n",
    "X_test = data_test.iloc[:,0:4030]\n",
    "y_test = data_test.iloc[:,-1]\n",
    "\n",
    "# univariate\n",
    "top_univariate_features_test = pd.DataFrame()\n",
    "for i in range(0, 300):\n",
    "    curr_column_vals = X_test.iloc[:, uni_selected_feat.iloc[i].name]\n",
    "    curr_column_name = uni_selected_feat.iloc[i][0]\n",
    "    top_univariate_features_test[curr_column_name] = curr_column_vals\n",
    "    \n",
    "#top_univariate_features_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\UnivariateFeaturesTest_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TestLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "#top_univariate_features_test.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/UnivariateFeaturesTest_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_test.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/TestLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "\n",
    "# Saving the top n features to a dataframe\n",
    "list_names = top_feat_impt.axes \n",
    "best_impt_features_test = pd.DataFrame()\n",
    "#print(X.columns.get_loc(list[0][0])) # how to get the index of the column/name from the feature selected names\n",
    "for i in range(0, 300):\n",
    "    curr_column_name = list_names[0][i]\n",
    "    curr_column_index = X_test.columns.get_loc(curr_column_name)\n",
    "    curr_column_vals = X_test.iloc[:, curr_column_index]\n",
    "    best_impt_features_test[curr_column_name] = curr_column_vals\n",
    "\n",
    "#best_impt_features_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\ImportanceFeaturesTest_300.csv', index=None, header=True, encoding='utf-8')\n",
    "y_test.to_csv('C:\\\\Users\\\\mikec\\\\Documents\\\\TestLabels.csv', index=None, header=True, encoding='utf-8')\n",
    "#best_impt_features_test.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/ImportanceFeaturesTest_300.csv', index=None, header=True, encoding='utf-8')\n",
    "#y_test.to_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/dataFeatureSelected/TestLabels.csv', index=None, header=True, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for returning top features of different feature selection algorithms\n",
    "def getUnivariateData():\n",
    "    return top_univariate_features\n",
    "\n",
    "def getFeatureImpt():\n",
    "    return best_impt_features\n",
    "\n",
    "def getLabels():\n",
    "    return y\n",
    "\n",
    "# Test data\n",
    "def getUnivariateTestData():\n",
    "    return top_univariate_features_test\n",
    "\n",
    "def getFeatureImptTest():\n",
    "    return best_impt_features_test\n",
    "\n",
    "def getTestLabels():\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of same features selected is: 229\n"
     ]
    }
   ],
   "source": [
    "# Compare the univariate and featureImpt selected features\n",
    "titles_univariate = getUnivariateData().columns\n",
    "titles_impt = getFeatureImpt().columns\n",
    "count = 0\n",
    "for i in range(0, len(titles_univariate)):\n",
    "    if titles_univariate[i] in titles_impt:\n",
    "        #print(titles_univariate[i]+' in both!')\n",
    "        count+=1\n",
    "print('The number of same features selected is: ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix with Heatmap -- get correlations of each features in dataset\n",
    "#corrmat = data.corr()\n",
    "#top_corr_features = corrmat.index\n",
    "#plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "#g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
