{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/featureExtraction\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.chdir('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/featureExtraction/')\n",
    "%cd ../featureExtraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from featurE_eng.ipynb\n",
      "Completing ngram generation for train\n",
      "Completing ngram generation for test\n",
      "Completing char-ngram generation for train\n",
      "Completing char-ngram generation for test\n",
      "Completing tfidf+ngram generation for train\n",
      "Completing tfidf+ngram generation for test\n",
      "Completing char-tfidf+ngram generation for train\n",
      "Completing char-tfidf+ngram generation for test\n",
      "Completing the sentiment analysis for train\n",
      "Completing the sentiment analysis for test\n",
      "Completing the liguistic feature extraction for train\n",
      "Completing the liguistic feature extraction for test\n",
      "Completing the readability scores extraction for train\n",
      "Completing the readability scores extraction for test\n",
      "Concatenating in process\n",
      "Did it!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import import_ipynb\n",
    "from featurE_eng import getData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19808, 4031)\n"
     ]
    }
   ],
   "source": [
    "# retrieve the features from the featureExtraction file\n",
    "data = getData()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the features and target variable\n",
    "X = data.iloc[:,0:4030]  #independent columns, change column number depending on what we have for shape\n",
    "y = data.iloc[:,-1]    #target column i.e labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if nan values check\n",
    "#print(np.where(np.isnan(X)))\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate Selection results:\n",
      "          Specs        Score\n",
      "76     bitch_nw  1880.111408\n",
      "1342    bitc_nc  1878.096858\n",
      "1343   bitch_nc  1878.096858\n",
      "1022    bitc_nc  1877.593354\n",
      "1602   itch _nc  1864.593042\n",
      "1021     bit_nc  1846.728725\n",
      "1341     bit_nc  1840.749266\n",
      "1601    itch_nc  1837.998935\n",
      "1600     itc_nc  1834.324330\n",
      "1889    tch _nc  1709.313722\n",
      "1888     tch_nc  1675.051534\n",
      "1887      tc_nc  1657.428884\n",
      "3342    bitc_tc  1530.192525\n",
      "3343   bitch_tc  1530.192525\n",
      "3022    bitc_tc  1529.876762\n",
      "3602   itch _tc  1529.871140\n",
      "3601    itch_tc  1518.734150\n",
      "3600     itc_tc  1517.178436\n",
      "3021     bit_tc  1511.387977\n",
      "3341     bit_tc  1509.217853\n",
      "1361     ch _nc  1483.234231\n",
      "3889    tch _tc  1480.486044\n",
      "3888     tch_tc  1470.295649\n",
      "3887      tc_tc  1463.245805\n",
      "4000  sentiment  1374.773723\n",
      "3361     ch _tc  1363.410744\n",
      "3598      it_tc  1193.740148\n",
      "1018      bi_nc  1140.308383\n",
      "3018      bi_tc  1085.071235\n",
      "1598      it_nc  1058.805136\n",
      "...         ...          ...\n",
      "3265   aggot_tc   640.282633\n",
      "3490     ggo_tc   640.282633\n",
      "3491    ggot_tc   640.282633\n",
      "3492   ggot _tc   640.282633\n",
      "1487      gg_nc   634.548911\n",
      "1222     tra_nc   633.329473\n",
      "3222     tra_tc   632.225707\n",
      "3263     agg_tc   630.281415\n",
      "1311    ash _nc   625.644394\n",
      "3310     ash_tc   607.220393\n",
      "74      bird_nw   600.002107\n",
      "1340   bird _nc   599.956588\n",
      "1339    bird_nc   594.072442\n",
      "1020    bird_nc   594.043133\n",
      "2293  faggot_tw   586.167006\n",
      "3340   bird _tc   585.368957\n",
      "3339    bird_tc   583.193751\n",
      "3020    bird_tc   582.356401\n",
      "1310     ash_nc   581.084876\n",
      "1593    ird _nc   565.110878\n",
      "2074    bird_tw   562.116770\n",
      "3593    ird _tc   558.033491\n",
      "3011       b_tc   556.639192\n",
      "1592     ird_nc   555.959648\n",
      "3922     tra_tc   552.550895\n",
      "3592     ird_tc   550.479944\n",
      "1922     tra_nc   535.857188\n",
      "3261      ag_tc   534.038330\n",
      "1800      ra_nc   528.413911\n",
      "1514      h _nc   522.048688\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Univariate Selection -- apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=100)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print('Univariate Selection results:')\n",
    "print(featureScores.nlargest(100,'Score'))  #print 100 best features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(i)? (<ipython-input-7-156ab93646fb>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-156ab93646fb>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    print i\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(i)?\n"
     ]
    }
   ],
   "source": [
    "# Extract the top 100 features\n",
    "a = featureScores.nlargest(100,'Score')\n",
    "print(a.columns)\n",
    "#print(a.iloc[0].name) # how to get the column # for the ith feature\n",
    "#print(a.iloc[0][0]) # how to get the header column\n",
    "top_univariate_features = pd.DataFrame()\n",
    "for i in range(0, 100):\n",
    "    print i\n",
    "    curr_column_vals = X.iloc[:, a.iloc[i].name]\n",
    "    curr_column_name = a.iloc[i][0]\n",
    "    top_univariate_features[curr_column_name] = curr_column_vals\n",
    "    \n",
    "print(top_univariate_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_univariate_features.shape) # TODO: HMM this should be 100 columns so ill look at that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Feature Importance \n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,y)\n",
    "print('Feature Importance results:')\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "print(feat_importances.nlargest(100))\n",
    "\n",
    "#feat_importances.nlargest(100).plot(kind='barh')\n",
    "#plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix with Heatmap -- get correlations of each features in dataset\n",
    "#corrmat = data.corr()\n",
    "#top_corr_features = corrmat.index\n",
    "#plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "#g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
