{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n",
    "from nltk.stem.cistem import Cistem\n",
    "import string\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "from textstat.textstat import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "import warnings\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random \n",
    "import os\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Raw data\n",
    "train_data = pd.read_csv(\"/home/mackenzie/Downloads/GermanTrainingData.txt\", sep='\\t', names=['tweet', 'coarse', 'labels'])\n",
    "test_data = pd.read_csv(\"/home/mackenzie/Downloads/GermanTestingData.txt\", sep='\\t', names=['tweet', 'coarse', 'labels'])\n",
    "df = pd.concat([train_data, test_data], ignore_index=True)\n",
    "del train_data\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tweets=df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"german\")\n",
    "\n",
    "other_exclusions = [\"lbr\", \"|lbr|\", \"»\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = Cistem()\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-ßA-ß]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def tokenize(tweet):\n",
    "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-ßA-ß]+\", tweet.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    \"\"\"Same as tokenize but without the stemming\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-ßA-ß.,!?]+\", tweet.lower())).strip()\n",
    "    return tweet.split()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    preprocessor=preprocess,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=stopwords,\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=3000,\n",
    "    min_df=5,\n",
    "    max_df=0.75\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['all', 'ber', 'dami', 'dasselb', 'demselb', 'denselb', 'derselb', 'dess', 'desselb', 'dieselb', 'dor', 'etwa', 'eur', 'f', 'geg', 'hatt', 'hrend', 'jed', 'jen', 'jetz', 'k', 'mach', 'manch', 'nich', 'nne', 'nnt', 'ohn', 'r', 'rde', 'selb', 'solch', 'son', 'sond', 'w', 'welch', 'werd', 'wes', 'woll', 'zwisch'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'^ml': 0, '`ne': 1, 'a': 2, 'a h': 3, 'ab': 4, 'abartig': 5, 'abend': 6, 'abgefuck': 7, 'abgefuck spd': 8, 'abgeleh': 9, 'abgeord': 10, 'abgeschaff': 11, 'abgeschob': 12, 'abgeschob werd': 13, 'abgeseh': 14, 'abgew': 15, 'abgew hlt': 16, 'abh': 17, 'ableg': 18, 'abschaff': 19, 'abschaffung': 20, 'abschaum': 21, 'abschieb': 22, 'abschiebung': 23, 'absehbar': 24, 'absich': 25, 'absolu': 26, 'abstimmung': 27, 'absurd': 28, 'abu': 29, 'abw': 30, 'abwar': 31, 'abzug': 32, 'accou': 33, 'ach': 34, 'ach ja': 35, 'ach scheiss': 36, 'achtung': 37, 'adolf': 38, 'adv': 39, 'afd': 40, 'afd nich': 41, 'afd w': 42, 'afd w hle': 43, 'afd w hler': 44, 'aff': 45, 'afghanista': 46, 'afri': 47, 'afrika': 48, 'agenda': 49, 'aha': 50, 'ahnung': 51, 'aksynod': 52, 'akt': 53, 'aktio': 54, 'aktuell': 55, 'akzeptier': 56, 'al': 57, 'alkohol': 58, 'all': 59, 'all ber': 60, 'all f': 61, 'all gut': 62, 'all m': 63, 'all mensch': 64, 'all mittel': 65, 'all nich': 66, 'all schon': 67, 'all w': 68, 'allei': 69, 'allerding': 70, 'allgemei': 71, 'alt': 72, 'altena': 73, 'alter': 74, 'alternativ': 75, 'altersarmu': 76, 'altkatholisch': 77, 'altkatholisch|': 78, 'altkatholisch| synod': 79, 'altmaier': 80, 'altpartei': 81, 'amerika': 82, 'amerikanisch': 83, 'ami': 84, 'amp': 85, 'amri': 86, 'amt': 87, 'analphab': 88, 'analy': 89, 'anarchi': 90, 'andersdenk': 91, 'andrea': 92, 'andrea nahl': 93, 'anfang': 94, 'ang': 95, 'angab': 96, 'angeblich': 97, 'angebo': 98, 'angeh': 99, 'angeh rig': 100, 'angela': 101, 'angela merkel': 102, 'angesich': 103, 'angewie': 104, 'angezeig': 105, 'angreif': 106, 'angriff': 107, 'anh': 108, 'anh nger': 109, 'anlass': 110, 'ann': 111, 'annewill': 112, 'ans': 113, 'ans ndig': 114, 'anschau': 115, 'anschei': 116, 'anschl': 117, 'anschl ge': 118, 'anschlag': 119, 'anschliess': 120, 'anso': 121, 'ansprech': 122, 'anspruch': 123, 'ansta': 124, 'anstatt': 125, 'anti': 126, 'antideutsch': 127, 'antifa': 128, 'antifantenbru': 129, 'antifaschi': 130, 'antisemi': 131, 'antisemitisch': 132, 'antisemitismu': 133, 'antr': 134, 'antr ge': 135, 'antrag': 136, 'antwor': 137, 'anw': 138, 'anw lte': 139, 'anwal': 140, 'anzeig': 141, 'arab': 142, 'arabie': 143, 'arabisch': 144, 'arbei': 145, 'arbeitgeb': 146, 'arbeitslo': 147, 'ard': 148, 'ard zdf': 149, 'argum': 150, 'argumentatio': 151, 'arm': 152, 'armee': 153, 'armu': 154, 'arsch': 155, 'arschl': 156, 'arschl cher': 157, 'arschloch': 158, 'art': 159, 'artikel': 160, 'arz': 161, 'asia': 162, 'asyl': 163, 'asyla': 164, 'asylantenpack': 165, 'asylrech': 166, 'athei': 167, 'auff': 168, 'aufgab': 169, 'aufgebau': 170, 'aufgekl': 171, 'aufgru': 172, 'aufh': 173, 'aufh ren': 174, 'aufkl': 175, 'aufnehm': 176, 'aufreg': 177, 'aufruf': 178, 'aufsteh': 179, 'auftrag': 180, 'auftritt': 181, 'aug': 182, 'auschwitz': 183, 'ausdruck': 184, 'ausgerech': 185, 'ausl': 186, 'ausl nder': 187, 'ausl ndisch': 188, 'ausla': 189, 'ausnahm': 190, 'ausreich': 191, 'auss': 192, 'aussag': 193, 'ausschliesslich': 194, 'ausseh': 195, 'aussenmini': 196, 'ausserd': 197, 'ausw': 198, 'ausw rtig': 199, 'ausw rtig amt': 200, 'auswei': 201, 'auto': 202, 'axel': 203, 'b': 204, 'b hmermann': 205, 'b rger': 206, 'b rgerkrieg': 207, 'b rgerlich': 208, 'b rgermei': 209, 'b se': 210, 'b sen': 211, 'bad': 212, 'bah': 213, 'bald': 214, 'band': 215, 'bank': 216, 'bann': 217, 'barcelona': 218, 'basi': 219, 'bastard': 220, 'bau': 221, 'bayer': 222, 'bayerisch': 223, 'be': 224, 'beach': 225, 'beam': 226, 'beantrag': 227, 'beantwor': 228, 'beck': 229, 'bedenk': 230, 'bedeu': 231, 'bedford': 232, 'bedford strohm': 233, 'bedie': 234, 'beeindruck': 235, 'beend': 236, 'bef': 237, 'bef rch': 238, 'bef rwor': 239, 'befrei': 240, 'begeh': 241, 'beginn': 242, 'begr': 243, 'begreif': 244, 'begriff': 245, 'beh': 246, 'beh rde': 247, 'behal': 248, 'behandel': 249, 'behaup': 250, 'behauptung': 251, 'behi': 252, 'beid': 253, 'beim': 254, 'bein': 255, 'beispiel': 256, 'bek': 257, 'bek mpf': 258, 'bekann': 259, 'bekenn': 260, 'bekenntni': 261, 'beklopp': 262, 'bekomm': 263, 'bel': 264, 'bel stig': 265, 'bel stigung': 266, 'beleg': 267, 'beleidig': 268, 'beleidigung': 269, 'belog': 270, 'beloh': 271, 'bem': 272, 'ben': 273, 'benachteilig': 274, 'benenn': 275, 'benutz': 276, 'beobach': 277, 'ber': 278, 'ber all': 279, 'ber merkel': 280, 'ber red': 281, 'berall': 282, 'berechtig': 283, 'berei': 284, 'berei jetz': 285, 'bereich': 286, 'bereicherung': 287, 'berf': 288, 'berfl': 289, 'berfl ssig': 290, 'berg': 291, 'bergab': 292, 'berhaup': 293, 'berhaup nich': 294, 'berich': 295, 'berich ber': 296, 'berichterstattung': 297, 'berlass': 298, 'berleb': 299, 'berleg': 300, 'berli': 301, 'bernd': 302, 'bernehm': 303, 'beruf': 304, 'beruhig': 305, 'berzeug': 306, 'bes': 307, 'bes tig': 308, 'besch': 309, 'besch ftig': 310, 'bescheid': 311, 'bescheu': 312, 'beschimpf': 313, 'beschiss': 314, 'beschloss': 315, 'beschw': 316, 'besetz': 317, 'beso': 318, 'besorg': 319, 'bess': 320, 'bess nich': 321, 'besta': 322, 'besteh': 323, 'bestell': 324, 'bestimm': 325, 'bestraf': 326, 'besuch': 327, 'bet': 328, 'beteilig': 329, 'beto': 330, 'betr': 331, 'betrach': 332, 'betreib': 333, 'betroff': 334, 'betrug': 335, 'bett': 336, 'bev': 337, 'bev lkerung': 338, 'bevor': 339, 'bew': 340, 'bew hrung': 341, 'bewegung': 342, 'bewei': 343, 'bewoh': 344, 'bewuss': 345, 'bezahl': 346, 'bezeich': 347, 'bezieh': 348, 'beziehung': 349, 'bezug': 350, 'bibel': 351, 'biet': 352, 'big': 353, 'bild': 354, 'bildung': 355, 'billig': 356, 'bio': 357, 'bir': 358, 'bischof': 359, 'bish': 360, 'bislang': 361, 'bissch': 362, 'bitt': 363, 'bka': 364, 'bka gutach': 365, 'bl': 366, 'bl d': 367, 'bl de': 368, 'bl dsinn': 369, 'bla': 370, 'blau': 371, 'bleib': 372, 'blich': 373, 'blick': 374, 'blieb': 375, 'blind': 376, 'block': 377, 'blockier': 378, 'bloss': 379, 'blu': 380, 'bonhoeff': 381, 'bonn': 382, 'bor': 383, 'bot': 384, 'botschaf': 385, 'botschaf manila': 386, 'boykottier': 387, 'br': 388, 'br ssel': 389, 'br uch': 390, 'brach': 391, 'brand': 392, 'brandenburg': 393, 'brandenburg tor': 394, 'brau': 395, 'brauch': 396, 'brauch nich': 397, 'brd': 398, 'brech': 399, 'brei': 400, 'breitscheidplatz': 401, 'brem': 402, 'brenn': 403, 'brig': 404, 'bring': 405, 'bro': 406, 'bru': 407, 'brud': 408, 'bstu': 409, 'bt': 410, 'btw': 411, 'buch': 412, 'buchstab': 413, 'bullshi': 414, 'bun': 415, 'bund': 416, 'bundeskanzl': 417, 'bundesparteitag': 418, 'bundesregierung': 419, 'bundestag': 420, 'bundestagswahl': 421, 'bundeswehr': 422, 'bundeswei': 423, 'burka': 424, 'bverfg': 425, 'bw': 426, 'bzgl': 427, 'bzw': 428, 'c': 429, 'ca': 430, 'cdu': 431, 'cdu csu': 432, 'cdu spd': 433, 'cel': 434, 'ch': 435, 'chanc': 436, 'chanukka': 437, 'chao': 438, 'charak': 439, 'che': 440, 'chebli': 441, 'chef': 442, 'cher': 443, 'cherlich': 444, 'china': 445, 'chlich': 446, 'chri': 447, 'christentum': 448, 'christlich': 449, 'chs': 450, 'cht': 451, 'cht nich': 452, 'chter': 453, 'chtig': 454, 'chtling': 455, 'chtlingspolitik': 456, 'ck': 457, 'cke': 458, 'ckf': 459, 'ckf hrung': 460, 'ckgra': 461, 'cksich': 462, 'ckt': 463, 'ckung': 464, 'ckwunsch': 465, 'cl': 466, 'claudia': 467, 'claudia roth': 468, 'co': 469, 'csd': 470, 'csu': 471, 'd': 472, 'd mlich': 473, 'd mmer': 474, 'd rfe': 475, 'd rft': 476, 'd sseldorf': 477, 'dabei': 478, 'dach': 479, 'dadurch': 480, 'daf': 481, 'daf r': 482, 'daf r sorg': 483, 'dageg': 484, 'daher': 485, 'dahi': 486, 'damal': 487, 'dami': 488, 'dami nich': 489, 'danach': 490, 'dank': 491, 'dank all': 492, 'dank f': 493, 'dank f r': 494, 'dar': 495, 'dar ber': 496, 'dara': 497, 'darauf': 498, 'darf': 499, 'darf nich': 500, 'dargestell': 501, 'dari': 502, 'darum': 503, 'dat': 504, 'dauer': 505, 'davo': 506, 'davongejag': 507, 'davonjag': 508, 'davor': 509, 'dch': 510, 'ddr': 511, 'de': 512, 'debatt': 513, 'definier': 514, 'definitio': 515, 'definitiv': 516, 'del': 517, 'demo': 518, 'demokra': 519, 'demokratie': 520, 'demokratisch': 521, 'demonstra': 522, 'demonstratio': 523, 'demonstrier': 524, 'deniz': 525, 'denk': 526, 'dennoch': 527, 'denunzia': 528, 'deo': 529, 'depp': 530, 'derar': 531, 'derjenig': 532, 'dermass': 533, 'deshalb': 534, 'dess': 535, 'desweg': 536, 'det': 537, 'deutlich': 538, 'deutsch': 539, 'deutsch b': 540, 'deutsch b rger': 541, 'deutsch botschaf': 542, 'deutsch botschaf manila': 543, 'deutsch m': 544, 'deutsch national': 545, 'deutsch nich': 546, 'deutsch politik': 547, 'deutsch schich': 548, 'deutsch staatsb': 549, 'deutsch t': 550, 'deutsch volk': 551, 'deutsch w': 552, 'deutschfeindlich': 553, 'deutschla': 554, 'deutschla brauch': 555, 'deutschla deutsch': 556, 'deutschla geh': 557, 'deutschla mach': 558, 'deutschla nich': 559, 'dezemb': 560, 'di': 561, 'dialog': 562, 'dick': 563, 'diejenig': 564, 'dien': 565, 'dienstag': 566, 'diesel': 567, 'diesmal': 568, 'dietrich': 569, 'dietrich bonhoeff': 570, 'differenzier': 571, 'dig': 572, 'digitalisierung': 573, 'diktator': 574, 'diktatur': 575, 'dilk': 576, 'ding': 577, 'direk': 578, 'disch': 579, 'diskriminierung': 580, 'diskussio': 581, 'diskutier': 582, 'dobri': 583, 'dolmetsch': 584, 'donald': 585, 'doof': 586, 'dophil': 587, 'dophil denunzia': 588, 'dor': 589, 'dorthi': 590, 'dortmu': 591, 'dr': 592, 'dra': 593, 'drauf': 594, 'dreck': 595, 'dreckig': 596, 'dreh': 597, 'drei': 598, 'dresd': 599, 'dri': 600, 'dring': 601, 'dritt': 602, 'dritteoptio': 603, 'drittesgeschlech': 604, 'drittklassig': 605, 'drog': 606, 'droh': 607, 'druck': 608, 'drum': 609, 'dsinn': 610, 'dt': 611, 'dte': 612, 'duld': 613, 'dumm': 614, 'dumm deutsch': 615, 'dummhei': 616, 'dummk': 617, 'dummk pfe': 618, 'dummschw': 619, 'durchau': 620, 'durchsetz': 621, 'durf': 622, 'e': 623, 'ebe': 624, 'ebe nich': 625, 'ebenfall': 626, 'ebenso': 627, 'ech': 628, 'eck': 629, 'egal': 630, 'egal welch': 631, 'eh': 632, 'ehe': 633, 'ehemalig': 634, 'eher': 635, 'ehr': 636, 'ehrenamtlich': 637, 'ehrlich': 638, 'eier': 639, 'eige': 640, 'eige volk': 641, 'eigentlich': 642, 'eigentlich nich': 643, 'eign': 644, 'eindeutig': 645, 'einf': 646, 'einfach': 647, 'einfach l': 648, 'einfach nich': 649, 'eingef': 650, 'eingef hrt': 651, 'eingeh': 652, 'eingestell': 653, 'einhei': 654, 'einkauf': 655, 'einrei': 656, 'eins': 657, 'einsatz': 658, 'einsch': 659, 'einseitig': 660, 'einsetz': 661, 'einstell': 662, 'einwa': 663, 'einwanderung': 664, 'einzel': 665, 'einzig': 666, 'ekd': 667, 'ekd rv': 668, 'ekdsynod': 669, 'ekelhaf': 670, 'elend': 671, 'eli': 672, 'elter': 673, 'emp': 674, 'empf': 675, 'empfehl': 676, 'empfi': 677, 'end': 678, 'endlich': 679, 'endlich mal': 680, 'engagier': 681, 'engla': 682, 'enorm': 683, 'entdeck': 684, 'entf': 685, 'entgeg': 686, 'entla': 687, 'entscheid': 688, 'entscheidung': 689, 'entschied': 690, 'entschuldig': 691, 'entschuldigung': 692, 'entsetz': 693, 'entsorg': 694, 'entsprich': 695, 'entsteh': 696, 'entt': 697, 'entwed': 698, 'entwickel': 699, 'entwicklung': 700, 'erb': 701, 'erb rmlich': 702, 'erd': 703, 'erdoga': 704, 'erf': 705, 'erfahr': 706, 'erfahrung': 707, 'erfolg': 708, 'erfolgreich': 709, 'erfu': 710, 'ergebni': 711, 'ergebniss': 712, 'ergib': 713, 'erh': 714, 'erhal': 715, 'erheb': 716, 'erika': 717, 'erinn': 718, 'erkann': 719, 'erkenn': 720, 'erkl': 721, 'erkl ren': 722, 'erkl rt': 723, 'erkl rung': 724, 'erl': 725, 'erlaub': 726, 'erleb': 727, 'ermittel': 728, 'ermord': 729, 'ern': 730, 'ern nehm': 731, 'erneu': 732, 'ernsthaf': 733, 'erreich': 734, 'ers': 735, 'ers mal': 736, 'ers rech': 737, 'ers rech nich': 738, 'ersch': 739, 'erschei': 740, 'ersetz': 741, 'erstaunlich': 742, 'erstmal': 743, 'ertrag': 744, 'erw': 745, 'erw hnt': 746, 'erwach': 747, 'erwar': 748, 'erz': 749, 'erz hle': 750, 'ess': 751, 'etablier': 752, 'etc': 753, 'etwa': 754, 'eu': 755, 'eur': 756, 'euro': 757, 'europ': 758, 'europ ische': 759, 'europa': 760, 'ewig': 761, 'existenz': 762, 'existier': 763, 'exper': 764, 'extr': 765, 'f': 766, 'f hle': 767, 'f hre': 768, 'f hrt': 769, 'f hrung': 770, 'f lle': 771, 'f llt': 772, 'f r': 773, 'f r all': 774, 'f r d': 775, 'f r deutsch': 776, 'f r deutschla': 777, 'f r dumm': 778, 'f r europa': 779, 'f r frau': 780, 'f r freihei': 781, 'f r hinwei': 782, 'f r immer': 783, 'f r jed': 784, 'f r land': 785, 'f r m': 786, 'f r merkel': 787, 'f r s': 788, 'f r spd': 789, 'f r t': 790, 'f rch': 791, 'f rder': 792, 'f rs': 793, 'facebook': 794, 'fah': 795, 'fahr': 796, 'fair': 797, 'fak': 798, 'fak new': 799, 'fakenew': 800, 'fall': 801, 'falsch': 802, 'familie': 803, 'familiennachzug': 804, 'fan': 805, 'fang': 806, 'fas': 807, 'fas all': 808, 'faschi': 809, 'faschismu': 810, 'fass': 811, 'faul': 812, 'fb': 813, 'fdp': 814, 'fehl': 815, 'feier': 816, 'feiertag': 817, 'feig': 818, 'feigling': 819, 'fein': 820, 'feind': 821, 'femini': 822, 'feminismu': 823, 'feministisch': 824, 'fen': 825, 'fer': 826, 'fernseh': 827, 'fertig': 828, 'fes': 829, 'fett': 830, 'fettig': 831, 'fettig haar': 832, 'fettig haar wdr': 833, 'ffentlich': 834, 'ffentlich rechtlich': 835, 'ffentlichkei': 836, 'ffn': 837, 'ffnung': 838, 'fick': 839, 'film': 840, 'finanziell': 841, 'finanzier': 842, 'find': 843, 'fing': 844, 'fl': 845, 'fl chtling': 846, 'fl chtlingspolitik': 847, 'flagg': 848, 'flasch': 849, 'flasch sammel': 850, 'fleisch': 851, 'flieg': 852, 'flieh': 853, 'fliess': 854, 'fluch': 855, 'folg': 856, 'follow': 857, 'ford': 858, 'forderung': 859, 'form': 860, 'formulier': 861, 'fortschritt': 862, 'foto': 863, 'fr': 864, 'fr h': 865, 'fr her': 866, 'fr hlich': 867, 'fr hlich gruss': 868, 'frag': 869, 'frag mal': 870, 'frag stell': 871, 'frag warum': 872, 'fraktio': 873, 'frank': 874, 'frankfur': 875, 'frankreich': 876, 'franz': 877, 'franz sisch': 878, 'franzisku': 879, 'frau': 880, 'frau f': 881, 'frau kind': 882, 'frau merkel': 883, 'frech': 884, 'frei': 885, 'freiburg': 886, 'freier': 887, 'freihei': 888, 'freihei f': 889, 'freihei f r': 890, 'freitag': 891, 'freiwillig': 892, 'fremd': 893, 'fress': 894, 'freu': 895, 'freu ber': 896, 'freud': 897, 'fried': 898, 'friedlich': 899, 'friedma': 900, 'froh': 901, 'ft': 902, 'fte': 903, 'fter': 904, 'ftig': 905, 'fund': 906, 'funktio': 907, 'funktio re': 908, 'funktionier': 909, 'furchtbar': 910, 'fuss': 911, 'fussball': 912, 'fxn': 913, 'g': 914, 'g be': 915, 'g ring': 916, 'g te': 917, 'g tter': 918, 'gab': 919, 'gabriel': 920, 'gang': 921, 'ganz': 922, 'ganz einfach': 923, 'ganz europa': 924, 'gar': 925, 'gar nich': 926, 'garantier': 927, 'garnich': 928, 'gas': 929, 'gauck': 930, 'gaula': 931, 'ge': 932, 'geb': 933, 'geb rech': 934, 'gef': 935, 'gef hl': 936, 'gef hrlich': 937, 'gef hrt': 938, 'gef llt': 939, 'gefl': 940, 'gefl cht': 941, 'geg': 942, 'geg afd': 943, 'geg antisemitismu': 944, 'geg ber': 945, 'geg deutsch': 946, 'geg jud': 947, 'geg trump': 948, 'geh': 949, 'geh gar': 950, 'geh gar nich': 951, 'geh gut': 952, 'geh ja': 953, 'geh nich': 954, 'geh ren': 955, 'geh rt': 956, 'geh rt nich': 957, 'geh s': 958, 'geil': 959, 'geis': 960, 'gek': 961, 'gek mpf': 962, 'gekl': 963, 'gekl rt': 964, 'gel': 965, 'gel scht': 966, 'geld': 967, 'geld f': 968, 'geld f r': 969, 'gem': 970, 'gen': 971, 'genau': 972, 'gend': 973, 'genseitig': 974, 'genteil': 975, 'genug': 976, 'ger': 977, 'ger t': 978, 'ges': 979, 'gesch': 980, 'gesch tzt': 981, 'gespr': 982, 'gespr ch': 983, 'gespr che': 984, 'get': 985, 'get tet': 986, 'geta': 987, 'gew': 988, 'gew hlt': 989, 'gew hlt werd': 990, 'gez': 991, 'gg': 992, 'gib': 993, 'gib deutschla': 994, 'gib ja': 995, 'gib nich': 996, 'gib s': 997, 'gib schon': 998, 'gil': 999, 'gil f': 1000, 'gil f r': 1001, 'ging': 1002, 'gl': 1003, 'gl ck': 1004, 'gl ckwunsch': 1005, 'glaub': 1006, 'glaub nich': 1007, 'glaub wirklich': 1008, 'gleich': 1009, 'gleichzeitig': 1010, 'glich': 1011, 'glich mach': 1012, 'glichkei': 1013, 'glyphosa': 1014, 'gnad': 1015, 'gner': 1016, 'gold': 1017, 'googl': 1018, 'gott': 1019, 'gr': 1020, 'gr n': 1021, 'gr n versiff': 1022, 'gr nde': 1023, 'gr ne': 1024, 'gr ne link': 1025, 'gr nen': 1026, 'gr nen nich': 1027, 'gr nen w': 1028, 'gr ner': 1029, 'gr sse': 1030, 'gr sser': 1031, 'gr sst': 1032, 'grab': 1033, 'grad': 1034, 'grandio': 1035, 'gratulier': 1036, 'grau': 1037, 'greif': 1038, 'grenz': 1039, 'grenzenlo': 1040, 'griech': 1041, 'groko': 1042, 'gross': 1043, 'gross koalitio': 1044, 'grossartig': 1045, 'grossteil': 1046, 'grund': 1047, 'grund tzlich': 1048, 'grundgesetz': 1049, 'grundlag': 1050, 'grupp': 1051, 'gruselig': 1052, 'gruss': 1053, 'gruss hauptstad': 1054, 'gst': 1055, 'gt': 1056, 'gt gt': 1057, 'guck': 1058, 'gummigeschoss': 1059, 'gung': 1060, 'gut': 1061, 'gut f': 1062, 'gut f r': 1063, 'gut mach': 1064, 'gut morg': 1065, 'gut nich': 1066, 'gutach': 1067, 'guter': 1068, 'gutmensch': 1069, 'h': 1070, 'h chs': 1071, 'h cke': 1072, 'h her': 1073, 'h lft': 1074, 'h lle': 1075, 'h lt': 1076, 'h maa': 1077, 'h nde': 1078, 'h nge': 1079, 'h ngt': 1080, 'h rde': 1081, 'h re': 1082, 'h ren': 1083, 'h rt': 1084, 'h sslich': 1085, 'h tte': 1086, 'h ufig': 1087, 'haar': 1088, 'haar wdr': 1089, 'hadith': 1090, 'haf': 1091, 'hahaha': 1092, 'hal': 1093, 'hal nich': 1094, 'halb': 1095, 'hallo': 1096, 'hallo freu': 1097, 'haltung': 1098, 'hama': 1099, 'hamburg': 1100, 'hamburg prid': 1101, 'hamburgprid': 1102, 'hand': 1103, 'handel': 1104, 'happy': 1105, 'har': 1106, 'hartaberfair': 1107, 'hartz': 1108, 'hartz iv': 1109, 'has': 1110, 'hass': 1111, 'hatt': 1112, 'hau': 1113, 'hauf': 1114, 'haup': 1115, 'haup chlich': 1116, 'hauptsach': 1117, 'hauptstad': 1118, 'hauptstad israel': 1119, 'hautfarb': 1120, 'he': 1121, 'hebr': 1122, 'hebr isch': 1123, 'hebr ische': 1124, 'heiko': 1125, 'heiko maa': 1126, 'heil': 1127, 'heilig': 1128, 'heima': 1129, 'heimatla': 1130, 'heira': 1131, 'heiss': 1132, 'heiss nich': 1133, 'held': 1134, 'helf': 1135, 'helmu': 1136, 'hen': 1137, 'her': 1138, 'herau': 1139, 'herkomm': 1140, 'herkunf': 1141, 'herr': 1142, 'herrsch': 1143, 'herum': 1144, 'herz': 1145, 'herzlich': 1146, 'herzlich gl': 1147, 'herzlich gl ckwunsch': 1148, 'herzlich willkomm': 1149, 'hess': 1150, 'hetero': 1151, 'hetz': 1152, 'hetz geg': 1153, 'heu': 1154, 'heu abend': 1155, 'heu nich': 1156, 'heu uhr': 1157, 'heuchl': 1158, 'heul': 1159, 'heutig': 1160, 'hi': 1161, 'hiess': 1162, 'hig': 1163, 'higkei': 1164, 'hilf': 1165, 'hillary': 1166, 'himmel': 1167, 'hinterh': 1168, 'hinwei': 1169, 'hinzuf': 1170, 'hir': 1171, 'hir proth': 1172, 'hirnw': 1173, 'hirnw sche': 1174, 'historisch': 1175, 'hitl': 1176, 'hl': 1177, 'hlbar': 1178, 'hle': 1179, 'hle afd': 1180, 'hler': 1181, 'hlich': 1182, 'hlich gruss': 1183, 'hlich gruss hauptstad': 1184, 'hlt': 1185, 'hlt werd': 1186, 'hmermann': 1187, 'hne': 1188, 'hnlich': 1189, 'hnt': 1190, 'hoch': 1191, 'hoff': 1192, 'hoffentlich': 1193, 'hoffnung': 1194, 'hoh': 1195, 'hohl': 1196, 'hol': 1197, 'holocau': 1198, 'homo': 1199, 'honeck': 1200, 'hord': 1201, 'hos': 1202, 'hos fettig': 1203, 'hos fettig haar': 1204, 'hr': 1205, 'hre': 1206, 'hrend': 1207, 'hrer': 1208, 'hrig': 1209, 'hrlich': 1210, 'hrt': 1211, 'hrung': 1212, 'hst': 1213, 'ht': 1214, 'humani': 1215, 'hund': 1216, 'hung': 1217, 'hur': 1218, 'hurensoh': 1219, 'i': 1220, 'ichwar': 1221, 'ick': 1222, 'idee': 1223, 'identi': 1224, 'identi t': 1225, 'ideologie': 1226, 'ideologisch': 1227, 'idio': 1228, 'ignorier': 1229, 'ill': 1230, 'illegal': 1231, 'imam': 1232, 'immer': 1233, 'immer gleich': 1234, 'immer mehr': 1235, 'immer nich': 1236, 'immerhi': 1237, 'importier': 1238, 'impul': 1239, 'incirlik': 1240, 'industriell': 1241, 'info': 1242, 'informatio': 1243, 'informier': 1244, 'inhal': 1245, 'inhaltlich': 1246, 'inn': 1247, 'innenmini': 1248, 'inner': 1249, 'innerhalb': 1250, 'insbeso': 1251, 'insul': 1252, 'integratio': 1253, 'integrier': 1254, 'intelligenz': 1255, 'inter': 1256, 'interess': 1257, 'interessa': 1258, 'interessier': 1259, 'international': 1260, 'interpretatio': 1261, 'interview': 1262, 'invasor': 1263, 'iq': 1264, 'ira': 1265, 'irgendei': 1266, 'irgendetwa': 1267, 'irgendwa': 1268, 'irgendwann': 1269, 'irgendwie': 1270, 'irgendwo': 1271, 'irr': 1272, 'irrsinn': 1273, 'is': 1274, 'isch': 1275, 'ische': 1276, 'isi': 1277, 'islam': 1278, 'islam nich': 1279, 'islami': 1280, 'islamisch': 1281, 'islamisierung': 1282, 'islamismu': 1283, 'islamistisch': 1284, 'israel': 1285, 'israelisch': 1286, 'israelpedia': 1287, 'iss': 1288, 'istig': 1289, 'istlich': 1290, 'italie': 1291, 'iv': 1292, 'j': 1293, 'j disch': 1294, 'j hrig': 1295, 'j mmerlich': 1296, 'ja': 1297, 'ja immer': 1298, 'ja ja': 1299, 'ja mal': 1300, 'ja nich': 1301, 'ja nich mal': 1302, 'ja schon': 1303, 'ja stimm': 1304, 'ja wohl': 1305, 'jag': 1306, 'jahr': 1307, 'jahr f': 1308, 'jahr f r': 1309, 'jahr nich': 1310, 'jahrhu': 1311, 'jahrzeh': 1312, 'jamaika': 1313, 'jamm': 1314, 'japa': 1315, 'je': 1316, 'jed': 1317, 'jed prei': 1318, 'jed tag': 1319, 'jedenfall': 1320, 'jedoch': 1321, 'jem': 1322, 'jema': 1323, 'jemal': 1324, 'jen': 1325, 'jerusal': 1326, 'jetz': 1327, 'jetz afd': 1328, 'jetz mal': 1329, 'jetz nich': 1330, 'jetz schon': 1331, 'jetzig': 1332, 'jo': 1333, 'job': 1334, 'journali': 1335, 'journalismu': 1336, 'jud': 1337, 'judenhass': 1338, 'judentum': 1339, 'jug': 1340, 'jugendlich': 1341, 'jung': 1342, 'jung m': 1343, 'juni': 1344, 'juristisch': 1345, 'juso': 1346, 'justiz': 1347, 'k': 1348, 'k ln': 1349, 'k lner': 1350, 'k me': 1351, 'k mmer': 1352, 'k mpf': 1353, 'k mpf f': 1354, 'k mpf geg': 1355, 'k nne': 1356, 'k nne nich': 1357, 'k nnt': 1358, 'k pfe': 1359, 'k rper': 1360, 'k rperlich': 1361, 'kaha': 1362, 'kal': 1363, 'kam': 1364, 'kamerad': 1365, 'kampag': 1366, 'kampf': 1367, 'kampf geg': 1368, 'kan': 1369, 'kandida': 1370, 'kanzl': 1371, 'kanzleri': 1372, 'kanzlerkandida': 1373, 'kapitalismu': 1374, 'kapitel': 1375, 'kardinal': 1376, 'karlsruh': 1377, 'katalonie': 1378, 'katholisch': 1379, 'katz': 1380, 'kauf': 1381, 'kaum': 1382, 'keinerlei': 1383, 'kenn': 1384, 'ker': 1385, 'kerz': 1386, 'kett': 1387, 'kika': 1388, 'kind': 1389, 'kinderg': 1390, 'kinderg rte': 1391, 'kirch': 1392, 'kirchentag': 1393, 'kita': 1394, 'kl': 1395, 'klag': 1396, 'klapp': 1397, 'klar': 1398, 'klass': 1399, 'klatsch': 1400, 'klau': 1401, 'kleb': 1402, 'klei': 1403, 'kleidung': 1404, 'klick': 1405, 'klima': 1406, 'kling': 1407, 'klo': 1408, 'klug': 1409, 'kn': 1410, 'kna': 1411, 'knall': 1412, 'knech': 1413, 'koalitio': 1414, 'koalitionsverhandlung': 1415, 'koch': 1416, 'kohl': 1417, 'kolleg': 1418, 'komisch': 1419, 'komm': 1420, 'komm nich': 1421, 'komm w': 1422, 'komm w rde': 1423, 'kommentar': 1424, 'kommentier': 1425, 'kommuni': 1426, 'komp': 1427, 'komplett': 1428, 'kompromiss': 1429, 'kon': 1430, 'konflik': 1431, 'konkr': 1432, 'konn': 1433, 'konsequ': 1434, 'konsequenz': 1435, 'konservativ': 1436, 'konsor': 1437, 'kontex': 1438, 'kontroll': 1439, 'kontrollier': 1440, 'konz': 1441, 'kopf': 1442, 'kopftuch': 1443, 'kora': 1444, 'kora hadith': 1445, 'korrek': 1446, 'korrigier': 1447, 'korrup': 1448, 'kos': 1449, 'kostenlo': 1450, 'kotz': 1451, 'kr': 1452, 'kraf': 1453, 'krank': 1454, 'krankenversicherung': 1455, 'kratz': 1456, 'krei': 1457, 'kreuz': 1458, 'kriech': 1459, 'krieg': 1460, 'krim': 1461, 'kriminali': 1462, 'kriminali t': 1463, 'kriminell': 1464, 'kriminell ausl': 1465, 'kriminell ausl nder': 1466, 'kritik': 1467, 'kritisch': 1468, 'kritisier': 1469, 'kuh': 1470, 'kular': 1471, 'kultur': 1472, 'kulturell': 1473, 'kun': 1474, 'kundgebung': 1475, 'kur': 1476, 'kurd': 1477, 'kurz': 1478, 'l': 1479, 'l cherlich': 1480, 'l ge': 1481, 'l gen': 1482, 'l gt': 1483, 'l nder': 1484, 'l nger': 1485, 'l nger leb': 1486, 'l ngs': 1487, 'l npress': 1488, 'l schen': 1489, 'l sst': 1490, 'l sung': 1491, 'l uft': 1492, 'laber': 1493, 'lach': 1494, 'lad': 1495, 'laferlichterluth': 1496, 'lag': 1497, 'lager': 1498, 'land': 1499, 'land nich': 1500, 'landsleu': 1501, 'lang': 1502, 'lang nich': 1503, 'langj': 1504, 'langj hrig': 1505, 'langsam': 1506, 'langweilig': 1507, 'lanz': 1508, 'lass': 1509, 'lass nich': 1510, 'lau': 1511, 'lauf': 1512, 'lder': 1513, 'le': 1514, 'leb': 1515, 'leb deutschla': 1516, 'leck': 1517, 'lediglich': 1518, 'leg': 1519, 'legal': 1520, 'legenhei': 1521, 'legitim': 1522, 'leh': 1523, 'lehr': 1524, 'leich': 1525, 'leid': 1526, 'leider': 1527, 'leider nich': 1528, 'leipzig': 1529, 'leis': 1530, 'leistung': 1531, 'leit': 1532, 'leitkultur': 1533, 'ler': 1534, 'les': 1535, 'letz': 1536, 'letz jahr': 1537, 'leu': 1538, 'ley': 1539, 'lft': 1540, 'liberal': 1541, 'lich': 1542, 'lieb': 1543, 'lieb freu': 1544, 'lieber': 1545, 'liefer': 1546, 'lieg': 1547, 'lies': 1548, 'lind': 1549, 'linie': 1550, 'link': 1551, 'link anarchi': 1552, 'link gr': 1553, 'link gr ne': 1554, 'linksgr': 1555, 'linksgr n': 1556, 'linksgr ne': 1557, 'lis': 1558, 'liv': 1559, 'lker': 1560, 'lkerung': 1561, 'll': 1562, 'lle': 1563, 'ller': 1564, 'llig': 1565, 'llt': 1566, 'ln': 1567, 'lner': 1568, 'lob': 1569, 'lobby': 1570, 'log': 1571, 'loh': 1572, 'los': 1573, 'lsvd': 1574, 'lt': 1575, 'lte': 1576, 'lter': 1577, 'ltig': 1578, 'ltwnd': 1579, 'lump': 1580, 'lustig': 1581, 'luth': 1582, 'm': 1583, 'm cht': 1584, 'm cht nich': 1585, 'm dch': 1586, 'm del': 1587, 'm ge': 1588, 'm gen': 1589, 'm glich': 1590, 'm glichkei': 1591, 'm ll': 1592, 'm nch': 1593, 'm nner': 1594, 'm nnlich': 1595, 'm rder': 1596, 'm rtyr': 1597, 'm sse': 1598, 'm sse nich': 1599, 'm sst': 1600, 'maa': 1601, 'mach': 1602, 'mach nich': 1603, 'mafia': 1604, 'mag': 1605, 'mai': 1606, 'maischberg': 1607, 'mal': 1608, 'mal ehrlich': 1609, 'mal f': 1610, 'mal f r': 1611, 'mal nich': 1612, 'mal seh': 1613, 'manch': 1614, 'manch mensch': 1615, 'manchmal': 1616, 'manda': 1617, 'manila': 1618, 'manipulier': 1619, 'mann': 1620, 'maria': 1621, 'mark': 1622, 'marti': 1623, 'marti schulz': 1624, 'marx': 1625, 'mass': 1626, 'massiv': 1627, 'massnahm': 1628, 'mauer': 1629, 'maul': 1630, 'me': 1631, 'meck': 1632, 'mecklenburg': 1633, 'medie': 1634, 'mehr': 1635, 'mehr f': 1636, 'mehr m': 1637, 'mehr mehr': 1638, 'mehr mensch': 1639, 'mehr nich': 1640, 'mehrhei': 1641, 'meind': 1642, 'meinsam': 1643, 'meinung': 1644, 'meinungsfreihei': 1645, 'meis': 1646, 'meld': 1647, 'meldung': 1648, 'men': 1649, 'meng': 1650, 'mensch': 1651, 'mensch nich': 1652, 'menschenrech': 1653, 'menschenverachtung': 1654, 'menschhei': 1655, 'menschlich': 1656, 'mer': 1657, 'merk': 1658, 'merkel': 1659, 'merkel f': 1660, 'merkel f r': 1661, 'merkel nich': 1662, 'merkel u': 1663, 'merkel vasall': 1664, 'mess': 1665, 'metoo': 1666, 'migra': 1667, 'migratio': 1668, 'mili': 1669, 'milliard': 1670, 'millio': 1671, 'min': 1672, 'mind': 1673, 'minderhei': 1674, 'minderheitsregierung': 1675, 'mini': 1676, 'minu': 1677, 'mio': 1678, 'mis': 1679, 'misch': 1680, 'missbrauch': 1681, 'mitarbei': 1682, 'mitbekomm': 1683, 'mitglied': 1684, 'mitgliederentscheid': 1685, 'mitt': 1686, 'mittel': 1687, 'mittlerweil': 1688, 'mlich': 1689, 'mmer': 1690, 'mmerlich': 1691, 'moder': 1692, 'moderator': 1693, 'moderatori': 1694, 'mohammed': 1695, 'moi': 1696, 'moi moi': 1697, 'mon': 1698, 'mona': 1699, 'moralisch': 1700, 'mord': 1701, 'morg': 1702, 'moschee': 1703, 'mosl': 1704, 'motto': 1705, 'mp': 1706, 'mpf': 1707, 'mpf f': 1708, 'mpf f r': 1709, 'mpf geg': 1710, 'msm': 1711, 'mt': 1712, 'mter': 1713, 'mtlich': 1714, 'multikulti': 1715, 'mund': 1716, 'murksel': 1717, 'muslim': 1718, 'muslimisch': 1719, 'mut': 1720, 'mutig': 1721, 'mutt': 1722, 'mutti': 1723, 'n': 1724, 'n chs': 1725, 'n chs jahr': 1726, 'n mlich': 1727, 'n rnberg': 1728, 'n tig': 1729, 'n tzt': 1730, 'n versiff': 1731, 'na': 1732, 'na ja': 1733, 'na klar': 1734, 'nachbar': 1735, 'nachd': 1736, 'nachdenk': 1737, 'nachfrag': 1738, 'nachrich': 1739, 'nachvollziehbar': 1740, 'nafri': 1741, 'nah': 1742, 'nah ost': 1743, 'nahl': 1744, 'naiv': 1745, 'naja': 1746, 'nam': 1747, 'nann': 1748, 'nas': 1749, 'nat': 1750, 'nat rlich': 1751, 'nat rlich nich': 1752, 'natio': 1753, 'national': 1754, 'nationali': 1755, 'nationalismu': 1756, 'nationalmannschaf': 1757, 'nato': 1758, 'natur': 1759, 'nauso': 1760, 'nazi': 1761, 'nch': 1762, 'nde': 1763, 'nder': 1764, 'nder nich': 1765, 'nder studie': 1766, 'nderung': 1767, 'ndig': 1768, 'ndisch': 1769, 'ndlich': 1770, 'ndni': 1771, 'ndung': 1772, 'ne': 1773, 'ne link': 1774, 'neb': 1775, 'neba': 1776, 'nee': 1777, 'negativ': 1778, 'neger': 1779, 'nehm': 1780, 'nein': 1781, 'nem': 1782, 'nen': 1783, 'nen nich': 1784, 'nen w': 1785, 'nenn': 1786, 'neonazi': 1787, 'ner': 1788, 'neratio': 1789, 'nerell': 1790, 'nerv': 1791, 'nes': 1792, 'nett': 1793, 'netz': 1794, 'netzdg': 1795, 'neu': 1796, 'neu jahr': 1797, 'neubrandenburg': 1798, 'neuer': 1799, 'neujahrsempfang': 1800, 'neutral': 1801, 'neuwahl': 1802, 'new': 1803, 'nft': 1804, 'nftig': 1805, 'nge': 1806, 'nger': 1807, 'nger leb': 1808, 'ngig': 1809, 'nglich': 1810, 'ngni': 1811, 'ngs': 1812, 'ngt': 1813, 'nich': 1814, 'nich all': 1815, 'nich ber': 1816, 'nich bess': 1817, 'nich d': 1818, 'nich deutsch': 1819, 'nich deutschla': 1820, 'nich einfach': 1821, 'nich ern': 1822, 'nich ers': 1823, 'nich f': 1824, 'nich f r': 1825, 'nich ganz': 1826, 'nich geb': 1827, 'nich geg': 1828, 'nich geh': 1829, 'nich gott': 1830, 'nich gr': 1831, 'nich gut': 1832, 'nich h': 1833, 'nich kenn': 1834, 'nich l': 1835, 'nich lag': 1836, 'nich leb': 1837, 'nich m': 1838, 'nich m glich': 1839, 'nich mach': 1840, 'nich mal': 1841, 'nich mehr': 1842, 'nich merkel': 1843, 'nich nder': 1844, 'nich nich': 1845, 'nich probl': 1846, 'nich rad': 1847, 'nich rech': 1848, 'nich regier': 1849, 'nich sag': 1850, 'nich sch': 1851, 'nich schlimm': 1852, 'nich seh': 1853, 'nich sond': 1854, 'nich st': 1855, 'nich t': 1856, 'nich tun': 1857, 'nich vergess': 1858, 'nich versta': 1859, 'nich versteh': 1860, 'nich w': 1861, 'nich wahr': 1862, 'nich wichtig': 1863, 'nich wiss': 1864, 'nich wund': 1865, 'nie': 1866, 'niederla': 1867, 'niedrig': 1868, 'niema': 1869, 'niemal': 1870, 'niess': 1871, 'nig': 1872, 'nimm': 1873, 'nirg': 1874, 'niveau': 1875, 'nix': 1876, 'nke': 1877, 'nkung': 1878, 'nlich': 1879, 'nne': 1880, 'nne nich': 1881, 'nner': 1882, 'nnlich': 1883, 'nnt': 1884, 'no': 1885, 'noafd': 1886, 'noafd afd': 1887, 'nochmal': 1888, 'nogroko': 1889, 'nomm': 1890, 'nord': 1891, 'nordkorea': 1892, 'normal': 1893, 'noss': 1894, 'not': 1895, 'notwendig': 1896, 'npd': 1897, 'npress': 1898, 'nrw': 1899, 'ns': 1900, 'nsche': 1901, 'nsche all': 1902, 'nscht': 1903, 'nst': 1904, 'nstl': 1905, 'nsu': 1906, 'nt': 1907, 'ntv': 1908, 'nu': 1909, 'null': 1910, 'nurmalso': 1911, 'nutz': 1912, 'nze': 1913, 'o': 1914, 'obama': 1915, 'obdachlo': 1916, 'obe': 1917, 'ober': 1918, 'obergrenz': 1919, 'objektiv': 1920, 'obwohl': 1921, 'och': 1922, 'od': 1923, 'off': 1924, 'off abu': 1925, 'off insul': 1926, 'offenbar': 1927, 'offensichtlich': 1928, 'offiziell': 1929, 'oft': 1930, 'oh': 1931, 'ohn': 1932, 'ohn r': 1933, 'ohn r ckgra': 1934, 'ohn schulabschluss': 1935, 'ohr': 1936, 'ok': 1937, 'okay': 1938, 'onli': 1939, 'opfer': 1940, 'oppositio': 1941, 'orba': 1942, 'ord': 1943, 'ordentlich': 1944, 'ordnung': 1945, 'orf': 1946, 'organisatio': 1947, 'organisier': 1948, 'ort': 1949, 'ost': 1950, 'ostk': 1951, 'ostk ste': 1952, 'other': 1953, 'other other': 1954, 'p': 1955, 'p dophil': 1956, 'p dophil denunzia': 1957, 'p sse': 1958, 'paar': 1959, 'pack': 1960, 'pal': 1961, 'pal sti': 1962, 'pal stina': 1963, 'palm': 1964, 'panz': 1965, 'pap': 1966, 'parlam': 1967, 'partei': 1968, 'partei deutschla': 1969, 'parteitag': 1970, 'pass': 1971, 'passier': 1972, 'patrio': 1973, 'patriotismu': 1974, 'peinlich': 1975, 'per': 1976, 'per nlich': 1977, 'perfek': 1978, 'perma': 1979, 'perso': 1980, 'personal': 1981, 'perv': 1982, 'pes': 1983, 'peter': 1984, 'pfaff': 1985, 'pfe': 1986, 'pfeif': 1987, 'pferd': 1988, 'pfleg': 1989, 'pft': 1990, 'pfui': 1991, 'pfui teufel': 1992, 'ph': 1993, 'phoenix': 1994, 'piep': 1995, 'pl': 1996, 'pl tzlich': 1997, 'pla': 1998, 'plattform': 1999, 'platz': 2000, 'plu': 2001, 'pol': 2002, 'poli': 2003, 'politik': 2004, 'politik l': 2005, 'politik nich': 2006, 'politisch': 2007, 'polizei': 2008, 'polizi': 2009, 'polnisch': 2010, 'porno': 2011, 'pos': 2012, 'positio': 2013, 'positiv': 2014, 'pr': 2015, 'pr fen': 2016, 'pr ses': 2017, 'pr sid': 2018, 'predig': 2019, 'prei': 2020, 'press': 2021, 'prid': 2022, 'primitiv': 2023, 'priva': 2024, 'pro': 2025, 'probl': 2026, 'problematisch': 2027, 'produzier': 2028, 'professionell': 2029, 'profil': 2030, 'profilier': 2031, 'programm': 2032, 'projek': 2033, 'propaganda': 2034, 'proph': 2035, 'protestier': 2036, 'proth': 2037, 'provokatio': 2038, 'proz': 2039, 'prozess': 2040, 'ps': 2041, 'psychisch': 2042, 'punk': 2043, 'pur': 2044, 'puti': 2045, 'quali': 2046, 'quatsch': 2047, 'quell': 2048, 'quo': 2049, 'r': 2050, 'r afd': 2051, 'r all': 2052, 'r ckf': 2053, 'r ckgra': 2054, 'r cksich': 2055, 'r d': 2056, 'r deutsch': 2057, 'r deutschla': 2058, 'r dumm': 2059, 'r europa': 2060, 'r f': 2061, 'r frau': 2062, 'r freihei': 2063, 'r gib': 2064, 'r gross': 2065, 'r heu': 2066, 'r hinwei': 2067, 'r immer': 2068, 'r jed': 2069, 'r k': 2070, 'r land': 2071, 'r m': 2072, 'r mal': 2073, 'r medie': 2074, 'r mehr': 2075, 'r merkel': 2076, 'r ne': 2077, 'r nich': 2078, 'r s': 2079, 'r sorg': 2080, 'r spd': 2081, 'r t': 2082, 'rach': 2083, 'rad': 2084, 'radikal': 2085, 'rai': 2086, 'rall': 2087, 'rass': 2088, 'rassi': 2089, 'rassismu': 2090, 'rassistisch': 2091, 'rassistisch ideologie': 2092, 'rational': 2093, 'ratt': 2094, 'rau': 2095, 'rau deutschla': 2096, 'raub': 2097, 'rauch': 2098, 'raum': 2099, 'rausschmeiss': 2100, 'rch': 2101, 'rde': 2102, 'rde all': 2103, 'rde heu': 2104, 'rde nich': 2105, 'rde w': 2106, 'rder': 2107, 'rdig': 2108, 're': 2109, 're gut': 2110, 're nich': 2111, 'reagier': 2112, 'reaktio': 2113, 'real': 2114, 'reali': 2115, 'reali t': 2116, 'rech': 2117, 'rech nich': 2118, 'rechnung': 2119, 'rechtfertig': 2120, 'rechtigkei': 2121, 'rechtlich': 2122, 'rechtsextr': 2123, 'rechtspopuli': 2124, 'rechtsstaa': 2125, 'red': 2126, 'red ber': 2127, 'reformationsjubil': 2128, 'refugee': 2129, 'reg': 2130, 'regel': 2131, 'regier': 2132, 'regierung': 2133, 'regim': 2134, 'regio': 2135, 'reich': 2136, 'reich nich': 2137, 'reichsb': 2138, 'reichsb rger': 2139, 'reih': 2140, 'rein': 2141, 'reis': 2142, 'reiss': 2143, 'religi': 2144, 'religi se': 2145, 'religi sen': 2146, 'religio': 2147, 'ren': 2148, 'ren nich': 2149, 'repr': 2150, 'republik': 2151, 'res': 2152, 'respek': 2153, 'rett': 2154, 'retwee': 2155, 'revolutio': 2156, 'rfe': 2157, 'rfe nich': 2158, 'rfer': 2159, 'rft': 2160, 'rger': 2161, 'rgerkrieg': 2162, 'rgerlich': 2163, 'rgermei': 2164, 'rgerschaf': 2165, 'rgt': 2166, 'rich': 2167, 'richtig': 2168, 'richtung': 2169, 'rig': 2170, 'ring': 2171, 'ritt': 2172, 'rke': 2173, 'rkei': 2174, 'rker': 2175, 'rkisch': 2176, 'rkt': 2177, 'rlich': 2178, 'rlich nich': 2179, 'rmlich': 2180, 'roll': 2181, 'ros': 2182, 'rot': 2183, 'rot gr': 2184, 'rot gr n': 2185, 'roth': 2186, 'rper': 2187, 'rs': 2188, 'rst': 2189, 'rt': 2190, 'rt nich': 2191, 'rte': 2192, 'rter': 2193, 'rtig': 2194, 'rtig amt': 2195, 'rtl': 2196, 'rtyr': 2197, 'ru': 2198, 'ruf': 2199, 'ruh': 2200, 'ruhig': 2201, 'rum': 2202, 'run': 2203, 'rund': 2204, 'rung': 2205, 'russ': 2206, 'russisch': 2207, 'russla': 2208, 'rze': 2209, 'rzt': 2210, 's': 2211, 's kular': 2212, 's mtlich': 2213, 'sach': 2214, 'sag': 2215, 'sag all': 2216, 'sag mal': 2217, 'sah': 2218, 'salafi': 2219, 'sam': 2220, 'sammel': 2221, 'sat': 2222, 'satz': 2223, 'sau': 2224, 'saudi': 2225, 'saudi arabie': 2226, 'sch': 2227, 'sch me': 2228, 'sch men': 2229, 'sch n': 2230, 'sch ne': 2231, 'sch nen': 2232, 'sch ner': 2233, 'sch nst': 2234, 'sch tze': 2235, 'sch tzt': 2236, 'sch ubl': 2237, 'schad': 2238, 'schaff': 2239, 'schal': 2240, 'schand': 2241, 'schand f': 2242, 'schand f r': 2243, 'scharia': 2244, 'schau': 2245, 'schauspiel': 2246, 'sche': 2247, 'scheh': 2248, 'schein': 2249, 'scheinheilg': 2250, 'scheinheilg partei': 2251, 'scheinheilg partei deutschla': 2252, 'scheinheilig': 2253, 'scheiss': 2254, 'scheiter': 2255, 'schen': 2256, 'schenk': 2257, 'scherg': 2258, 'schich': 2259, 'schick': 2260, 'schieh': 2261, 'schiess': 2262, 'schl': 2263, 'schlaf': 2264, 'schlag': 2265, 'schlamp': 2266, 'schland': 2267, 'schlech': 2268, 'schleswig': 2269, 'schliess': 2270, 'schliesslich': 2271, 'schlimm': 2272, 'schloss': 2273, 'schluss': 2274, 'schmarotz': 2275, 'schmarotz p': 2276, 'schmarotz p dophil': 2277, 'schmeiss': 2278, 'schmid': 2279, 'schmoddrig': 2280, 'schnell': 2281, 'schon': 2282, 'schon gar': 2283, 'schon immer': 2284, 'schon l': 2285, 'schon l nger': 2286, 'schon lang': 2287, 'schon mal': 2288, 'schon seit': 2289, 'schoss': 2290, 'schr': 2291, 'schrecklich': 2292, 'schrei': 2293, 'schreib': 2294, 'schrieb': 2295, 'schrif': 2296, 'schritt': 2297, 'scht': 2298, 'schul': 2299, 'schulabschluss': 2300, 'schuld': 2301, 'schuldig': 2302, 'schulz': 2303, 'schutz': 2304, 'schw': 2305, 'schwachk': 2306, 'schwachk pfe': 2307, 'schwachsinn': 2308, 'schwaetz': 2309, 'schwarz': 2310, 'schwarz gr': 2311, 'schwei': 2312, 'schweig': 2313, 'schweiz': 2314, 'schwer': 2315, 'schwierig': 2316, 'schwimm': 2317, 'schwuchtel': 2318, 'schwul': 2319, 'se': 2320, 'sed': 2321, 'seehof': 2322, 'seel': 2323, 'seg': 2324, 'seh': 2325, 'seh nich': 2326, 'sei': 2327, 'sei dank': 2328, 'seid': 2329, 'seid all': 2330, 'seit': 2331, 'seit jahr': 2332, 'seit lang': 2333, 'seit wann': 2334, 'seitd': 2335, 'sel': 2336, 'selb': 2337, 'selbstv': 2338, 'selbstv ndlich': 2339, 'sellschaf': 2340, 'sellschaf nich': 2341, 'sellschaftlich': 2342, 'seltsam': 2343, 'sen': 2344, 'send': 2345, 'sendung': 2346, 'sentier': 2347, 'septemb': 2348, 'ser': 2349, 'servicezei': 2350, 'ses': 2351, 'setz': 2352, 'setzgeb': 2353, 'sex': 2354, 'sexismu': 2355, 'sexuell': 2356, 'sexuell bel': 2357, 'sexuell bel stigung': 2358, 'sharia': 2359, 'show': 2360, 'sicherhei': 2361, 'sicherlich': 2362, 'sid': 2363, 'sieg': 2364, 'sieger': 2365, 'sieh': 2366, 'sindel': 2367, 'sing': 2368, 'sinn': 2369, 'sisch': 2370, 'situatio': 2371, 'sitz': 2372, 'sitz blieb': 2373, 'sitzengeblieb': 2374, 'skandal': 2375, 'sklav': 2376, 'sofor': 2377, 'sog': 2378, 'sogar': 2379, 'sogenann': 2380, 'soh': 2381, 'solang': 2382, 'solch': 2383, 'solch leu': 2384, 'solda': 2385, 'soli': 2386, 'solidari': 2387, 'solidari t': 2388, 'somm': 2389, 'son': 2390, 'sond': 2391, 'sondierung': 2392, 'sondierungsergebniss': 2393, 'sondierungsgespr': 2394, 'sondierungsgespr che': 2395, 'sondierungsgespr che unio': 2396, 'sonntag': 2397, 'sorg': 2398, 'soro': 2399, 'sorry': 2400, 'souv': 2401, 'souv n': 2402, 'soviel': 2403, 'sowa': 2404, 'sowa nich': 2405, 'sowei': 2406, 'sowie': 2407, 'sowieso': 2408, 'sozi': 2409, 'sozial': 2410, 'sozialdemokra': 2411, 'sozialschmarotz': 2412, 'sozialsy': 2413, 'sp': 2414, 'sp t': 2415, 'sp ter': 2416, 'sp tes': 2417, 'spal': 2418, 'spanie': 2419, 'spann': 2420, 'spar': 2421, 'spass': 2422, 'spd': 2423, 'spd f': 2424, 'spd gr': 2425, 'spd politik': 2426, 'spd schmarotz': 2427, 'spd schmarotz p': 2428, 'spd verseuch': 2429, 'spd w': 2430, 'spdbp': 2431, 'spderneu': 2432, 'spdl': 2433, 'spend': 2434, 'sperr': 2435, 'speziell': 2436, 'spiegel': 2437, 'spiel': 2438, 'spinn': 2439, 'spitz': 2440, 'spor': 2441, 'sprach': 2442, 'sprech': 2443, 'sprich': 2444, 'sproch': 2445, 'spruch': 2446, 'ss': 2447, 'sse': 2448, 'sse nich': 2449, 'ssel': 2450, 'sseldorf': 2451, 'sser': 2452, 'ssig': 2453, 'sslich': 2454, 'sst': 2455, 'sst nich': 2456, 'st': 2457, 'st ck': 2458, 'st dte': 2459, 'st ndig': 2460, 'st rke': 2461, 'st rker': 2462, 'st rze': 2463, 'sta': 2464, 'staa': 2465, 'staatlich': 2466, 'staatsanwaltschaf': 2467, 'staatsb': 2468, 'staatsb rger': 2469, 'staatsb rgerschaf': 2470, 'staatsfunk': 2471, 'stad': 2472, 'stal': 2473, 'stamm': 2474, 'stand': 2475, 'stapo': 2476, 'star': 2477, 'stark': 2478, 'stasi': 2479, 'stasi unterlag': 2480, 'statistik': 2481, 'statt': 2482, 'stattfi': 2483, 'ste': 2484, 'steck': 2485, 'steg': 2486, 'steh': 2487, 'steh f': 2488, 'steh f r': 2489, 'steig': 2490, 'steinmei': 2491, 'stell': 2492, 'stellung': 2493, 'ster': 2494, 'sterb': 2495, 'sterreich': 2496, 'sterreichisch': 2497, 'steu': 2498, 'steuergeld': 2499, 'steuerzahl': 2500, 'sti': 2501, 'stiftung': 2502, 'stig': 2503, 'stigung': 2504, 'stil': 2505, 'still': 2506, 'stimm': 2507, 'stimm f': 2508, 'stimm f r': 2509, 'stina': 2510, 'stink': 2511, 'stolz': 2512, 'stopp': 2513, 'str': 2514, 'straf': 2515, 'strafbar': 2516, 'strafta': 2517, 'strass': 2518, 'strategie': 2519, 'strei': 2520, 'strich': 2521, 'strohm': 2522, 'strom': 2523, 'strunz': 2524, 'strunzdumm': 2525, 'studie': 2526, 'studier': 2527, 'stund': 2528, 'sturm': 2529, 'subjek': 2530, 'subsidi': 2531, 'such': 2532, 'sund': 2533, 'sung': 2534, 'super': 2535, 'symbol': 2536, 'synod': 2537, 'syrer': 2538, 'syrie': 2539, 'syrisch': 2540, 'sys': 2541, 'szczeci': 2542, 't': 2543, 't glich': 2544, 't r': 2545, 't rke': 2546, 't rkei': 2547, 't rkisch': 2548, 't ten': 2549, 't ter': 2550, 'tag': 2551, 'tagesschau': 2552, 'tasch': 2553, 'tat': 2554, 'tat chlich': 2555, 'tator': 2556, 'tatsach': 2557, 'tau': 2558, 'taub': 2559, 'taug': 2560, 'taug nich': 2561, 'tbb': 2562, 'te': 2563, 'team': 2564, 'teil': 2565, 'teilnehm': 2566, 'teilwei': 2567, 'ten': 2568, 'ter': 2569, 'teri': 2570, 'termi': 2571, 'terror': 2572, 'terroranschlag': 2573, 'terrori': 2574, 'tes': 2575, 'tet': 2576, 'teufel': 2577, 'tex': 2578, 'the': 2579, 'them': 2580, 'thema': 2581, 'tief': 2582, 'tier': 2583, 'tierqu': 2584, 'tig': 2585, 'tipp': 2586, 'tisch': 2587, 'titel': 2588, 'tja': 2589, 'tl': 2590, 'tn': 2591, 'toch': 2592, 'tod': 2593, 'todesstraf': 2594, 'toleranz': 2595, 'toll': 2596, 'tor': 2597, 'tot': 2598, 'total': 2599, 'tr': 2600, 'tr gt': 2601, 'tr ume': 2602, 'tr umt': 2603, 'traditio': 2604, 'trag': 2605, 'trau': 2606, 'traum': 2607, 'traurig': 2608, 'tre': 2609, 'treff': 2610, 'treib': 2611, 'trenn': 2612, 'treu': 2613, 'triff': 2614, 'trink': 2615, 'tritt': 2616, 'troff': 2617, 'troll': 2618, 'trotz': 2619, 'trotzd': 2620, 'trump': 2621, 'trupp': 2622, 'tte': 2623, 'ttel': 2624, 'tter': 2625, 'tun': 2626, 'tut': 2627, 'tv': 2628, 'tvduell': 2629, 'twee': 2630, 'twitt': 2631, 'typ': 2632, 'typisch': 2633, 'typisch deutsch': 2634, 'tze': 2635, 'tzer': 2636, 'tzlich': 2637, 'tzt': 2638, 'tzung': 2639, 'u': 2640, 'u a': 2641, 'u d': 2642, 'ubig': 2643, 'ubl': 2644, 'uch': 2645, 'ufig': 2646, 'uft': 2647, 'uhr': 2648, 'ukrai': 2649, 'ume': 2650, 'umfrag': 2651, 'umgeh': 2652, 'ums': 2653, 'umso': 2654, 'umt': 2655, 'un': 2656, 'unabh': 2657, 'unabh ngig': 2658, 'unbeding': 2659, 'unertr': 2660, 'unertr glich': 2661, 'unf': 2662, 'unf hig': 2663, 'unf higkei': 2664, 'unfassbar': 2665, 'ungar': 2666, 'ungl': 2667, 'ungl ubig': 2668, 'uni': 2669, 'unio': 2670, 'unm': 2671, 'unm glich': 2672, 'unrech': 2673, 'unsich': 2674, 'unsinn': 2675, 'unterar': 2676, 'unterdr': 2677, 'untergang': 2678, 'untergeh': 2679, 'unterlag': 2680, 'unternehm': 2681, 'unterrich': 2682, 'unterscheid': 2683, 'unterschied': 2684, 'unterschied zwisch': 2685, 'unterstell': 2686, 'unw': 2687, 'unw rdig': 2688, 'ur': 2689, 'urlaub': 2690, 'ursach': 2691, 'urteil': 2692, 'us': 2693, 'usa': 2694, 'usche': 2695, 'user': 2696, 'usser': 2697, 'usserung': 2698, 'usw': 2699, 'v': 2700, 'v lker': 2701, 'v llig': 2702, 'vasall': 2703, 'vasall merkel': 2704, 'vater': 2705, 'ver': 2706, 'ver ffentlich': 2707, 'ver ndlich': 2708, 'ver ndni': 2709, 'ver nftig': 2710, 'veranstaltung': 2711, 'verantwortlich': 2712, 'verantwortung': 2713, 'verarsch': 2714, 'verb': 2715, 'verb nde': 2716, 'verbie': 2717, 'verbl': 2718, 'verbl det': 2719, 'verbo': 2720, 'verbrech': 2721, 'verbrei': 2722, 'verbrenn': 2723, 'verdamm': 2724, 'verdie': 2725, 'verei': 2726, 'vereinig': 2727, 'verf': 2728, 'verf gung': 2729, 'verfahr': 2730, 'verfassung': 2731, 'verfluch': 2732, 'verfolg': 2733, 'vergang': 2734, 'vergangenhei': 2735, 'vergess': 2736, 'vergewaltig': 2737, 'vergewaltigung': 2738, 'vergif': 2739, 'vergleich': 2740, 'verh': 2741, 'verhal': 2742, 'verhandel': 2743, 'verhandlung': 2744, 'verhi': 2745, 'verhi werd': 2746, 'verkauf': 2747, 'verkehr': 2748, 'verklag': 2749, 'verkomm': 2750, 'verl': 2751, 'verlang': 2752, 'verlass': 2753, 'verletz': 2754, 'verlier': 2755, 'verlog': 2756, 'verlor': 2757, 'verm': 2758, 'vermiss': 2759, 'vermittel': 2760, 'vermutlich': 2761, 'vernich': 2762, 'vernichtung': 2763, 'verpass': 2764, 'verr': 2765, 'verr ckt': 2766, 'verr t': 2767, 'verr ter': 2768, 'verra': 2769, 'verreck': 2770, 'versag': 2771, 'verschw': 2772, 'verschwi': 2773, 'verseuch': 2774, 'versiff': 2775, 'versta': 2776, 'versteck': 2777, 'versteh': 2778, 'versuch': 2779, 'verteidig': 2780, 'verteil': 2781, 'vertr': 2782, 'vertrau': 2783, 'vertritt': 2784, 'verursach': 2785, 'verurteil': 2786, 'verw': 2787, 'verwechsel': 2788, 'verzich': 2789, 'via': 2790, 'video': 2791, 'vielfal': 2792, 'vielleich': 2793, 'vier': 2794, 'vll': 2795, 'volk': 2796, 'volk beck': 2797, 'volksverr': 2798, 'volksverr ter': 2799, 'volksverr teri': 2800, 'voll': 2801, 'vollkomm': 2802, 'vollpfo': 2803, 'vorbei': 2804, 'vorbild': 2805, 'vorf': 2806, 'vorf lle': 2807, 'vorgeh': 2808, 'vorh': 2809, 'vorha': 2810, 'vorschlag': 2811, 'vorsich': 2812, 'vorsitz': 2813, 'vorstell': 2814, 'vortrag': 2815, 'vorurteil': 2816, 'vorwerf': 2817, 'vs': 2818, 'vt': 2819, 'w': 2820, 'w hlbar': 2821, 'w hle': 2822, 'w hle afd': 2823, 'w hler': 2824, 'w hlt': 2825, 'w hrend': 2826, 'w nsche': 2827, 'w nsche all': 2828, 'w nscht': 2829, 'w rde': 2830, 'w rde all': 2831, 'w rde heu': 2832, 'w rde nich': 2833, 'w rde w': 2834, 'w re': 2835, 'w re gut': 2836, 'w ren': 2837, 'w sst': 2838, 'wach': 2839, 'waff': 2840, 'wag': 2841, 'wagenknech': 2842, 'wahl': 2843, 'wahlkampf': 2844, 'wahnsinn': 2845, 'wahr': 2846, 'wahrhei': 2847, 'wahrscheinlich': 2848, 'wal': 2849, 'wal geg': 2850, 'wand': 2851, 'wann': 2852, 'warum': 2853, 'warum nich': 2854, 'wass': 2855, 'wdr': 2856, 'wechsel': 2857, 'weder': 2858, 'weh': 2859, 'wehr': 2860, 'weiblich': 2861, 'weihnach': 2862, 'wein': 2863, 'weis': 2864, 'weiss': 2865, 'weiss nich': 2866, 'weit': 2867, 'weiterhi': 2868, 'wel': 2869, 'welch': 2870, 'weltwei': 2871, 'wem': 2872, 'wen': 2873, 'wend': 2874, 'wenig': 2875, 'wer': 2876, 'wer f': 2877, 'wer f r': 2878, 'wer nich': 2879, 'werbung': 2880, 'werd': 2881, 'werd jetz': 2882, 'werd k': 2883, 'werd m': 2884, 'werd nich': 2885, 'werd nie': 2886, 'werf': 2887, 'wes': 2888, 'weshalb': 2889, 'westlich': 2890, 'wett': 2891, 'wichtig': 2892, 'widerlich': 2893, 'widersta': 2894, 'wiederhol': 2895, 'wien': 2896, 'wies': 2897, 'wieso': 2898, 'wieviel': 2899, 'willick': 2900, 'willk': 2901, 'willkomm': 2902, 'win': 2903, 'wind': 2904, 'winn': 2905, 'wirk': 2906, 'wirklich': 2907, 'wirklich nich': 2908, 'wirtschaf': 2909, 'wiss': 2910, 'wissenschaf': 2911, 'witz': 2912, 'woand': 2913, 'wobei': 2914, 'woch': 2915, 'wof': 2916, 'wof r': 2917, 'woh': 2918, 'woher': 2919, 'wohi': 2920, 'wohl': 2921, 'wohl eher': 2922, 'wohl nich': 2923, 'wohlsta': 2924, 'wohnung': 2925, 'wolfgang': 2926, 'woll': 2927, 'woll nich': 2928, 'wonn': 2929, 'wor': 2930, 'word': 2931, 'wow': 2932, 'wozu': 2933, 'wund': 2934, 'wunderbar': 2935, 'wunsch': 2936, 'wurd': 2937, 'wuss': 2938, 'wut': 2939, 'x': 2940, 'x sitz': 2941, 'x sitz blieb': 2942, 'x sitzengeblieb': 2943, 'y': 2944, 'y cel': 2945, 'youtub': 2946, 'yvonn': 2947, 'yvonn willick': 2948, 'z': 2949, 'z b': 2950, 'z hle': 2951, 'zahl': 2952, 'zahlreich': 2953, 'zb': 2954, 'zdemir': 2955, 'zdf': 2956, 'zeich': 2957, 'zeig': 2958, 'zeit': 2959, 'zeitung': 2960, 'zensier': 2961, 'zensur': 2962, 'zentrum': 2963, 'zer': 2964, 'zer ren': 2965, 'zer rt': 2966, 'zersetzung': 2967, 'zeug': 2968, 'zieg': 2969, 'zieh': 2970, 'ziel': 2971, 'ziemlich': 2972, 'zita': 2973, 'zitier': 2974, 'zuer': 2975, 'zug': 2976, 'zuh': 2977, 'zuh ren': 2978, 'zukunf': 2979, 'zumi': 2980, 'zurech': 2981, 'zus': 2982, 'zus nde': 2983, 'zus ndig': 2984, 'zus tzlich': 2985, 'zusamm': 2986, 'zusammenhang': 2987, 'zusta': 2988, 'zustimm': 2989, 'zustimmung': 2990, 'zuviel': 2991, 'zuvor': 2992, 'zw': 2993, 'zwang': 2994, 'zweck': 2995, 'zwei': 2996, 'zwing': 2997, 'zwisch': 2998, 'zwung': 2999}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct tfidf matrix and get relevant scores\n",
    "tfidf = vectorizer.fit_transform(tweets).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "print(vocab) # todo: add \n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Now get other features\n",
    "sentiment_analyzer = VS()\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-ßA-ß]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    sentiment = TextBlob(\"tweet\").sentiment\n",
    "    \n",
    "    words = preprocess(tweet) #Get text only\n",
    "    \n",
    "    syllables = textstat.syllable_count(words, lang='de_DE')\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    features = [FKRA, FRE, syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment[0],twitter_objs[2], twitter_objs[1], twitter_objs[0]]\n",
    "    #features = pandas.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)\n",
    "\n",
    "# Changing string labels to numeric labels\n",
    "def string_to_numeric(x):\n",
    "    if x == 'OTHER' or x == 'PROFANITY':\n",
    "        return 0\n",
    "    if x == 'INSULT':\n",
    "        return 1\n",
    "    if x == 'ABUSE':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"sentiment\", \"num_hashtags\", \"num_mentions\", \"num_urls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "feats = get_feature_array(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "M = np.concatenate([tfidf,feats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8407, 3013)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Finally get a list of variable names\n",
    "variables = ['']*len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    variables[v] = k\n",
    "\n",
    "feature_names = variables+other_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(M)\n",
    "y = df['labels'].apply(string_to_numeric)\n",
    "X.columns = feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [3009 3012] are constant.\n",
      "  UserWarning)\n",
      "/home/mackenzie/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate Selection features found, use getUnivariateData() to get the features\n",
      "                   Specs      Score\n",
      "614                 dumm  64.461365\n",
      "2525          strunzdumm  55.880652\n",
      "1704                mosl  55.345552\n",
      "587               dophil  54.787880\n",
      "2275           schmarotz  53.819002\n",
      "1960                pack  52.935005\n",
      "1956            p dophil  52.840050\n",
      "1659              merkel  52.572181\n",
      "1263             invasor  49.851795\n",
      "1278               islam  48.541379\n",
      "164                asyla  47.059928\n",
      "1717             murksel  45.142919\n",
      "1898              npress  45.073805\n",
      "1488            l npress  43.138647\n",
      "2703              vasall  41.965389\n",
      "2254             scheiss  41.374236\n",
      "2300      schulabschluss  38.508092\n",
      "2798           volksverr  35.600844\n",
      "831               fettig  34.680448\n",
      "832          fettig haar  34.563703\n",
      "2276         schmarotz p  34.354193\n",
      "2277  schmarotz p dophil  34.354193\n",
      "2303              schulz  33.965406\n",
      "21              abschaum  33.503491\n",
      "1955                   p  33.437801\n",
      "2856                 wdr  33.264589\n",
      "1020                  gr  30.828795\n",
      "588      dophil denunzia  30.502020\n",
      "1957   p dophil denunzia  30.502020\n",
      "2427       spd schmarotz  30.502020\n",
      "...                  ...        ...\n",
      "521         demokratisch   1.895437\n",
      "1882                nner   1.889967\n",
      "848                flagg   1.889838\n",
      "2720               verbo   1.889721\n",
      "35                ach ja   1.887196\n",
      "1897                 npd   1.884823\n",
      "321            bess nich   1.883258\n",
      "924          ganz europa   1.883258\n",
      "950              geh gar   1.883258\n",
      "951         geh gar nich   1.883258\n",
      "1425          kommentier   1.883258\n",
      "1431             konflik   1.883258\n",
      "1692               moder   1.883258\n",
      "1734             na klar   1.883258\n",
      "2073               r mal   1.883258\n",
      "2436            speziell   1.883258\n",
      "2603              tr umt   1.883258\n",
      "937           gef hrlich   1.879583\n",
      "589                  dor   1.877908\n",
      "2201               ruhig   1.877193\n",
      "2273             schloss   1.877193\n",
      "2298                scht   1.877193\n",
      "2692              urteil   1.877193\n",
      "2008             polizei   1.873556\n",
      "2453                ssig   1.867778\n",
      "1502                lang   1.860830\n",
      "1100             hamburg   1.859928\n",
      "454                chtig   1.859751\n",
      "1643             meinsam   1.857940\n",
      "363                 bitt   1.856425\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Univariate feature selection from sklearn\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=1000)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print('Univariate Selection features found, use getUnivariateData() to get the features')\n",
    "# Extract the top n features\n",
    "uni_selected_feat = featureScores.nlargest(1000,'Score')\n",
    "print(uni_selected_feat) # print out the top n features selected\n",
    "\n",
    "# Saving the top n features to a data frame\n",
    "#print(a.iloc[0].name) # how to get the column # for the ith feature\n",
    "#print(a.iloc[0][0]) # how to get the header column\n",
    "top_univariate_features = pd.DataFrame()\n",
    "for i in range(0, 1000):\n",
    "    curr_column_vals = X.iloc[:, uni_selected_feat.iloc[i].name]\n",
    "    curr_column_name = uni_selected_feat.iloc[i][0]\n",
    "    top_univariate_features[curr_column_name] = curr_column_vals\n",
    "\n",
    "X = pd.DataFrame(top_univariate_features)\n",
    "X.columns = top_univariate_features.columns\n",
    "print(X.columns)\n",
    "feature_names = top_univariate_features.columns\n",
    "featuresSelected_pd = pd.DataFrame(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame(name='labels')\n",
    "y_test = y_test.to_frame(name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling from imblearn\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "X_train = pd.DataFrame(X_res)\n",
    "X_train.columns = feature_names\n",
    "y_train = pd.DataFrame(y_res)\n",
    "y_train.columns = ['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# BUG: when we convert to h2o dataframe an extra row is added\n",
    "X_train = h2o.H2OFrame(X_train)\n",
    "y_train = h2o.H2OFrame(y_train)\n",
    "X_test = h2o.H2OFrame(X_test)\n",
    "y_test = h2o.H2OFrame(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.na_omit() # pandas-->h2o results in an error where a nan row is added to X data, so this deals with that\n",
    "X_test = X_test.na_omit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check X and y have same number of rows\n",
    "print(len(y_train))\n",
    "print(len(X_train))\n",
    "print(len(y_test))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the train and test data sets\n",
    "# now convert tweet vecs and labels to a pandas dataframe and back to h2o dataframe\n",
    "train = X_train.cbind(y_train)\n",
    "test = X_test.cbind(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more on data prep\n",
    "x = train.columns         # x: A list/vector of predictor column names or indexes. \n",
    "                          # This argument only needs to be specified if the user wants to exclude columns from the \n",
    "                          # set of predictors. If all columns (other than the response) should be used in prediction, \n",
    "                          # then this does not need to be set.\n",
    "\n",
    "y = \"labels\"              # This argument is the name (or index) of the response column\n",
    "x.remove(y)\n",
    "\n",
    "# need to set train and test\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the AUTO-ML piece comes in\n",
    "aml = H2OAutoML(max_runtime_secs=1800) #sort_metric=auc, max_runtime_secs=10800, class_sampling_factors = sample_factors, max_models=?, balance_classes=True\n",
    "aml.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)\n",
    "lb_pd = lb.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The leader model is stored here\n",
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions!\n",
    "preds = aml.predict(test)\n",
    "print(preds)\n",
    "var = preds[\"predict\"].cbind(test[y])\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new folder to hold statistics for a run\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "# create a random folder number to reference the directory\n",
    "rand = random.randint(0, 1000)*random.randint(0,10)\n",
    "directory = '/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/TestResults_replicated/Test_' + str(rand)\n",
    "print('The results for this run will be stored in ' + directory)\n",
    "createFolder(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metrics and results!\n",
    "y_test = h2o.as_list(test[y], use_pandas=True)\n",
    "y_pred = h2o.as_list(preds[\"predict\"])\n",
    "print(\"Confusion Matrix: \")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score: \")\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"Recall: \")\n",
    "confusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "matrix_proportions = np.zeros((3,3))\n",
    "for i in range(0,3):\n",
    "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
    "names=['Other','Insult','Abuse']\n",
    "confusion_df = pd.DataFrame(matrix_proportions, index=names,columns=names)\n",
    "plt.figure(figsize=(5,5))\n",
    "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
    "plt.ylabel(r'True categories',fontsize=14)\n",
    "plt.xlabel(r'Predicted categories',fontsize=14)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.savefig(directory + '/recall.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the classification report info\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "f= open(directory+'/classification_report.txt',\"w+\")\n",
    "f.write(metrics.classification_report(y_test, y_pred))\n",
    "f.write(str(metrics.confusion_matrix(y_test,y_pred)))\n",
    "f.write('\\n')\n",
    "f.write('accuracy: '+ str(metrics.accuracy_score(y_test, y_pred)))\n",
    "f.write('\\n')\n",
    "f.write('f1-score' + str(metrics.f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = lb_pd.to_csv(path_or_buf=directory+'/modelinfo.csv')\n",
    "featuresSelected = featuresSelected_pd.to_csv(path_or_buf=directory+'/feature_selection.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
