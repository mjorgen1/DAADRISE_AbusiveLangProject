{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "from textstat.textstat import *\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/mikec/Documents/davidson/data/labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tweets=df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def tokenize(tweet):\n",
    "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]+\", tweet.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    \"\"\"Same as tokenize but without the stemming\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]+\", tweet.lower())).strip()\n",
    "    return tweet.split()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    preprocessor=preprocess,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=stopwords,\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.75\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\mikec\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', 'onc', 'onli', 'ourselv', 'themselv', 'thi', 'veri', 'wa', 'whi', 'yourselv'] not in stop_words.\n  'stop_words.' % sorted(inconsistent))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#Construct tfidf matrix and get relevant scores\n",
    "tfidf = vectorizer.fit_transform(tweets).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Get POS tags for tweets and save as a string\n",
    "tweet_tags = []\n",
    "for t in tweets:\n",
    "    tokens = basic_tokenize(preprocess(t))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tag_list = [x[1] for x in tags]\n",
    "    tag_str = \" \".join(tag_list)\n",
    "    tweet_tags.append(tag_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#We can use the TFIDF vectorizer to get a token matrix for the POS tags\n",
    "pos_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=None,\n",
    "    lowercase=False,\n",
    "    preprocessor=None,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=None,\n",
    "    use_idf=False,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=5000,\n",
    "    min_df=5,\n",
    "    max_df=0.75,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Construct POS TF matrix and get vocab dict\n",
    "pos = pos_vectorizer.fit_transform(pd.Series(tweet_tags)).toarray()\n",
    "pos_vocab = {v:i for i, v in enumerate(pos_vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Now get other features\n",
    "sentiment_analyzer = VS()\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    sentiment = sentiment_analyzer.polarity_scores(tweet)\n",
    "    \n",
    "    words = preprocess(tweet) #Get text only\n",
    "    \n",
    "    syllables = textstat.syllable_count(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    retweet = 0\n",
    "    if \"rt\" in words:\n",
    "        retweet = 1\n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet]\n",
    "    #features = pandas.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\"vader neu\", \\\n",
    "                        \"vader compound\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"is_retweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "feats = get_feature_array(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "M = np.concatenate([tfidf,pos,feats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(24783, 11172)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Finally get a list of variable names\n",
    "variables = ['']*len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    variables[v] = k\n",
    "\n",
    "pos_variables = ['']*len(pos_vocab)\n",
    "for k,v in pos_vocab.items():\n",
    "    pos_variables[v] = k\n",
    "\n",
    "feature_names = variables+pos_variables+other_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = pd.DataFrame(M)\n",
    "y = df['class'].astype(int)\n",
    "X.columns = feature_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Univariate Selection features found, use getUnivariateData() to get the features",
      "\n",
      "                  Specs        Score\n535               bitch  2384.592874\n11164         vader neg  1772.135115\n11166         vader neu  1384.101505\n11167    vader compound  1350.379776\n2002             faggot   903.795790\n6305              trash   852.094597\n512                bird   824.433547\n6998              yanke   648.175049\n4394             nigger   643.049468\n11156               FRE   600.180045\n1209             charli   589.646341\n11158  avg_syl_per_word   515.689760\n11155              FKRA   497.458888\n2916                hoe   483.474357\n7029             yellow   432.872647\n2000                fag   301.480469\n11170          num_urls   294.387789\n4901              pussi   266.527970\n6828        white trash   254.230504\n6818              white   253.601431\n2246               fuck   226.482701\n4573               oreo   213.074922\n1047             browni   206.540573\n3323             jihadi   201.869783\n4307              nigga   197.535373\n4095               mock   172.935700\n250                 ass   147.876857\n11157     num_syllables   146.967301\n4115             monkey   139.171421\n1332              color   138.253435\n...                 ...          ...\n9282           RB RB IN     2.369546\n7817         IN WRB PRP     2.369041\n2199                 fr     2.362485\n2466             get yo     2.362485\n5982             taught     2.362485\n9924          VBD IN IN     2.362305\n10941        WDT VBP IN     2.361343\n7074                 yr     2.360650\n7515          DT VBZ RB     2.360197\n9877           VB WP VB     2.359370\n10574         VBP RP JJ     2.359370\n2166                foh     2.359370\n6377             trynna     2.359370\n8044          JJ VBP RB     2.357203\n9665           VB IN DT     2.355574\n10026        VBD RB VBG     2.354735\n7381           DT NN JJ     2.351967\n5495               sick     2.348711\n2136               flaw     2.346508\n2433            get new     2.346508\n5298         say nigger     2.346508\n3488         lame bitch     2.346508\n3607           like dat     2.346508\n9123        PRP VBP VBP     2.344167\n5311              sayin     2.344093\n3917               mama     2.343510\n167           ani bitch     2.340007\n751          bitch next     2.340007\n5286          say bitch     2.340007\n8951          PRP NN CC     2.336282\n\n[3000 rows x 2 columns]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#Feature selection \n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# Univariate Selection -- apply SelectKBest class to extract top n best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=3000)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "# concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print('Univariate Selection features found, use getUnivariateData() to get the features')\n",
    "# Extract the top n features\n",
    "uni_selected_feat = featureScores.nlargest(3000,'Score')\n",
    "print(uni_selected_feat) # print out the top n features selected\n",
    "# Saving the top n features to a data frame\n",
    "top_univariate_features = pd.DataFrame()\n",
    "for i in range(0, 3000):\n",
    "    curr_column_vals = X.iloc[:, uni_selected_feat.iloc[i].name]\n",
    "    curr_column_name = uni_selected_feat.iloc[i][0]\n",
    "    top_univariate_features[curr_column_name] = curr_column_vals\n",
    "X = top_univariate_features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-1994ff0854c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature Importance results saved, use getFeatureImpt() to get the features'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 146\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array('labels', dtype='<U6') cannot be considered a valid collection."
     ],
     "ename": "TypeError",
     "evalue": "Singleton array array('labels', dtype='<U6') cannot be considered a valid collection.",
     "output_type": "error"
    }
   ],
   "source": [
    "# Feature Importance \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print('Feature Importance results saved, use getFeatureImpt() to get the features')\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "top_feat_impt = feat_importances.nlargest(1000) \n",
    "print(top_feat_impt) # prints out the n best features\n",
    "\n",
    "# Saving the top n features to a dataframe\n",
    "list_names = top_feat_impt.axes \n",
    "best_impt_features = pd.DataFrame()\n",
    "for i in range(0, 1000):\n",
    "    curr_column_name = list_names[0][i]\n",
    "    curr_column_index = X.columns.get_loc(curr_column_name)\n",
    "    curr_column_vals = X.iloc[:, curr_column_index]\n",
    "    best_impt_features[curr_column_name] = curr_column_vals\n",
    "X = best_impt_features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Near Miss!!",
      "\n",
      "Done!",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\mikec\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:192: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n  warnings.warn('The number of the samples to be selected is larger'\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "print(\"Near Miss!!\")\n",
    "nm = NearMiss(version=3)\n",
    "X_res, y_res = nm.fit_resample(X_train, y_train)\n",
    "X_train = pd.DataFrame(X_res)\n",
    "X_train.columns = uni_selected_feat['Specs']\n",
    "y_train = pd.DataFrame()\n",
    "y_train['labels'] = y_res\n",
    "print(\"Done!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "#y_train = y_train.to_frame(name='labels')\n",
    "y_test = y_test.to_frame(name='labels')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "X_train.to_csv('C:/Users/mikec/Documents/X_train.csv', index=None, header=True, encoding='utf-8')\n",
    "X_test.to_csv('C:/Users/mikec/Documents/X_test.csv', index=None, header=True, encoding='utf-8')\n",
    "y_train.to_csv('C:/Users/mikec/Documents/y_train.csv', index=None, header=True, encoding='utf-8')\n",
    "y_test.to_csv('C:/Users/mikec/Documents/y_test.csv', index=None, header=True, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ",
      ".",
      " connected.",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "--------------------------  ------------------------------------------\nH2O cluster uptime:         2 hours 9 mins\nH2O cluster timezone:       Europe/Berlin\nH2O data parsing timezone:  UTC\nH2O cluster version:        3.24.0.5\nH2O cluster version age:    1 month and 18 days\nH2O cluster name:           H2O_from_python_mikec_wnsfhp\nH2O cluster total nodes:    1\nH2O cluster free memory:    1.505 Gb\nH2O cluster total cores:    8\nH2O cluster allowed cores:  8\nH2O cluster status:         locked, healthy\nH2O connection url:         http://localhost:54321\nH2O connection proxy:\nH2O internal security:      False\nH2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, Core V4\nPython version:             3.7.3 final\n--------------------------  ------------------------------------------",
      "text/html": "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n<td>2 hours 9 mins</td></tr>\n<tr><td>H2O cluster timezone:</td>\n<td>Europe/Berlin</td></tr>\n<tr><td>H2O data parsing timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O cluster version:</td>\n<td>3.24.0.5</td></tr>\n<tr><td>H2O cluster version age:</td>\n<td>1 month and 18 days </td></tr>\n<tr><td>H2O cluster name:</td>\n<td>H2O_from_python_mikec_wnsfhp</td></tr>\n<tr><td>H2O cluster total nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O cluster free memory:</td>\n<td>1.505 Gb</td></tr>\n<tr><td>H2O cluster total cores:</td>\n<td>8</td></tr>\n<tr><td>H2O cluster allowed cores:</td>\n<td>8</td></tr>\n<tr><td>H2O cluster status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O connection url:</td>\n<td>http://localhost:54321</td></tr>\n<tr><td>H2O connection proxy:</td>\n<td>None</td></tr>\n<tr><td>H2O internal security:</td>\n<td>False</td></tr>\n<tr><td>H2O API Extensions:</td>\n<td>Amazon S3, Algos, AutoML, Core V3, Core V4</td></tr>\n<tr><td>Python version:</td>\n<td>3.7.3 final</td></tr></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()\n",
    "from h2o.automl import H2OAutoML"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Parse progress: |",
      "█████████████████████████████████████████████████████████| 100%",
      "\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%",
      "\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%",
      "\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "X_train = h2o.import_file('C:/Users/mikec/Documents/X_train.csv')\n",
    "y_train = h2o.import_file('C:/Users/mikec/Documents/y_train.csv')\n",
    "X_test = h2o.import_file('C:/Users/mikec/Documents/X_test.csv')\n",
    "y_test = h2o.import_file('C:/Users/mikec/Documents/y_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# preparing the train and test data sets\n",
    "# now convert tweet vecs and labels to a pandas dataframe and back to h2o dataframe\n",
    "train = X_train.cbind(y_train)\n",
    "test = X_test.cbind(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# more on data prep\n",
    "x = train.columns         # x: A list/vector of predictor column names or indexes. \n",
    "                          # This argument only needs to be specified if the user wants to exclude columns from the \n",
    "                          # set of predictors. If all columns (other than the response) should be used in prediction, \n",
    "                          # then this does not need to be set.\n",
    "\n",
    "y = \"labels\"              # This argument is the name (or index) of the response column\n",
    "x.remove(y)\n",
    "\n",
    "# need to set train and test\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "AutoML progress: |",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█",
      "█| 100%",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# now the AUTO-ML piece comes in\n",
    "aml = H2OAutoML(max_runtime_secs=1800) #max_models=10 or 20?, max_runtime_secs=3600\n",
    "aml.train(x=x, y=y, training_frame=train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/html": "<table>\n<thead>\n<tr><th>model_id                                           </th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n</thead>\n<tbody>\n<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190806_161201</td><td style=\"text-align: right;\">              0.186418</td><td style=\"text-align: right;\"> 0.507273</td><td style=\"text-align: right;\">0.398146</td><td style=\"text-align: right;\">0.15852 </td></tr>\n<tr><td>StackedEnsemble_AllModels_AutoML_20190806_161201   </td><td style=\"text-align: right;\">              0.187631</td><td style=\"text-align: right;\"> 0.503684</td><td style=\"text-align: right;\">0.396481</td><td style=\"text-align: right;\">0.157197</td></tr>\n<tr><td>GBM_1_AutoML_20190806_161201                       </td><td style=\"text-align: right;\">              0.21592 </td><td style=\"text-align: right;\"> 0.574815</td><td style=\"text-align: right;\">0.433342</td><td style=\"text-align: right;\">0.187785</td></tr>\n<tr><td>GBM_4_AutoML_20190806_161201                       </td><td style=\"text-align: right;\">              0.215954</td><td style=\"text-align: right;\"> 0.574079</td><td style=\"text-align: right;\">0.433133</td><td style=\"text-align: right;\">0.187604</td></tr>\n<tr><td>GBM_2_AutoML_20190806_161201                       </td><td style=\"text-align: right;\">              0.216663</td><td style=\"text-align: right;\"> 0.571801</td><td style=\"text-align: right;\">0.433361</td><td style=\"text-align: right;\">0.187801</td></tr>\n<tr><td>GBM_3_AutoML_20190806_161201                       </td><td style=\"text-align: right;\">              0.21711 </td><td style=\"text-align: right;\"> 0.5777  </td><td style=\"text-align: right;\">0.435682</td><td style=\"text-align: right;\">0.189819</td></tr>\n<tr><td>GLM_grid_1_AutoML_20190806_161201_model_1          </td><td style=\"text-align: right;\">              0.239854</td><td style=\"text-align: right;\"> 0.630669</td><td style=\"text-align: right;\">0.450155</td><td style=\"text-align: right;\">0.202639</td></tr>\n<tr><td>GBM_5_AutoML_20190806_161201                       </td><td style=\"text-align: right;\">              0.256508</td><td style=\"text-align: right;\"> 0.669574</td><td style=\"text-align: right;\">0.478353</td><td style=\"text-align: right;\">0.228822</td></tr>\n<tr><td>DRF_1_AutoML_20190806_161201                       </td><td style=\"text-align: right;\">              0.271029</td><td style=\"text-align: right;\"> 0.753306</td><td style=\"text-align: right;\">0.524278</td><td style=\"text-align: right;\">0.274868</td></tr>\n<tr><td>DeepLearning_1_AutoML_20190806_161201              </td><td style=\"text-align: right;\">              0.354772</td><td style=\"text-align: right;\"> 1.05483 </td><td style=\"text-align: right;\">0.523704</td><td style=\"text-align: right;\">0.274266</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 87
    }
   ],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "lb_pd = lb.as_data_frame()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model Details",
      "\n",
      "=============",
      "\n",
      "H2OStackedEnsembleEstimator",
      " ",
      ": ",
      " ",
      "Stacked Ensemble",
      "\n",
      "Model Key: ",
      " ",
      "StackedEnsemble_BestOfFamily_AutoML_20190806_161201",
      "\n",
      "No model summary for this model",
      "\n",
      "\n",
      "\n",
      "ModelMetricsMultinomialGLM: stackedensemble",
      "\n",
      "** Reported on train data. **",
      "\n",
      "\n",
      "MSE: 0.04790968297694829",
      "\n",
      "RMSE: 0.2188828064900217",
      "\n",
      "\n",
      "ModelMetricsMultinomialGLM: stackedensemble",
      "\n",
      "** Reported on cross-validation data. **",
      "\n",
      "\n",
      "MSE: 0.1585203089547665",
      "\n",
      "RMSE: 0.3981460899654378",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": ""
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 89
    }
   ],
   "source": [
    "# The leader model is stored here\n",
    "aml.leader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%",
      "\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">       p0</th><th style=\"text-align: right;\">      p1</th><th style=\"text-align: right;\">       p2</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.276313 </td><td style=\"text-align: right;\">0.683028</td><td style=\"text-align: right;\">0.0406593</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.334609 </td><td style=\"text-align: right;\">0.64234 </td><td style=\"text-align: right;\">0.0230513</td></tr>\n<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0554214</td><td style=\"text-align: right;\">0.143165</td><td style=\"text-align: right;\">0.801413 </td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.678146 </td><td style=\"text-align: right;\">0.275618</td><td style=\"text-align: right;\">0.0462366</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.221343 </td><td style=\"text-align: right;\">0.736538</td><td style=\"text-align: right;\">0.0421184</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0814909</td><td style=\"text-align: right;\">0.858353</td><td style=\"text-align: right;\">0.0601557</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0479793</td><td style=\"text-align: right;\">0.936881</td><td style=\"text-align: right;\">0.0151401</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.101828 </td><td style=\"text-align: right;\">0.878701</td><td style=\"text-align: right;\">0.0194709</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0594774</td><td style=\"text-align: right;\">0.923771</td><td style=\"text-align: right;\">0.0167514</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.143388 </td><td style=\"text-align: right;\">0.832406</td><td style=\"text-align: right;\">0.0242064</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = aml.predict(test)\n",
    "print(preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">  labels</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">       2</td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       1</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "var = preds[\"predict\"].cbind(test[y])\n",
    "print(var)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.17      0.86      0.28       164\n           1       0.97      0.62      0.75      1905\n           2       0.81      0.84      0.82       410\n\n    accuracy                           0.67      2479\n   macro avg       0.65      0.77      0.62      2479\nweighted avg       0.89      0.67      0.73      2479\n",
      "\n",
      "[[ 141   16    7]\n [ 658 1174   73]\n [  48   18  344]]",
      "\n",
      "0.6692214602662364",
      "\n",
      "0.7345012354966559",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert to pandas dataframe\n",
    "y_test = h2o.as_list(test[y], use_pandas=True)\n",
    "y_pred = h2o.as_list(preds[\"predict\"])\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "matrix_proportions = np.zeros((3,3))\n",
    "for i in range(0,3):\n",
    "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
    "names=['Hate','Offensive','Neither']\n",
    "confusion_df = pd.DataFrame(matrix_proportions, index=names,columns=names)\n",
    "plt.figure(figsize=(5,5))\n",
    "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
    "plt.ylabel(r'True categories',fontsize=14)\n",
    "plt.xlabel(r'Predicted categories',fontsize=14)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.savefig('C:/Users/mikec/Documents/Results/Univariate3000Near3Max05.png')\n",
    "\n",
    "f = open(\"C:/Users/mikec/Documents/Results/Univariate3000Near3Max05.txt\", \"a\")\n",
    "print(\"Univariate feature selection with 3000 features with Near Miss version 3, max run time 30 mins\", file=f)\n",
    "print(report, file=f)\n",
    "print(metrics.confusion_matrix(y_test, y_pred), file=f)\n",
    "print(metrics.accuracy_score(y_test, y_pred), file=f)\n",
    "print(metrics.f1_score(y_test, y_pred, average='weighted'), file=f)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "file = lb_pd.to_csv('C:/Users/mikec/Documents/Results/Univariate3000Near3Max05.csv')\n",
    "#featuresSelected = uni_selected_feat.to_csv('C:/Users/mikec/Documents/Results/feature_selection.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f7050d0a",
   "language": "python",
   "display_name": "PyCharm (DAADRISE_AbusiveLangProject)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}