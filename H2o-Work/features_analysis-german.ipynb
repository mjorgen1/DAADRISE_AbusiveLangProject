{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load two csv files of the features selected from a univariate run\n",
    "# the first is for 1000\n",
    "data_fs1 = pd.read_csv(\"/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/Results_Aug7/Test_featimp1000_ONLY822/feature_selection.csv\", engine='python')\n",
    "data_fs2 = pd.read_csv('/home/mackenzie/workspace/PycharmProjects/DAADRISE_AbusiveLangProject/Results_Aug7/Test_featimp1000_ONLY34/feature_selection.csv', engine='python')\n",
    "data_fs1.columns = ['feature', 'Score']\n",
    "data_fs2.columns = ['feature', 'Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feature', 'Score'], dtype='object')\n",
      "Index(['feature', 'Score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# clean data\n",
    "print(data_fs1.columns)\n",
    "\n",
    "\n",
    "print(data_fs2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that data is equal should be\n",
    "data_fs1.equals(data_fs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      num_chars_total  0.016552412852394623\n",
      "0           num_chars              0.015472\n",
      "1                 FRE              0.014541\n",
      "2                FKRA              0.014460\n",
      "3    avg_syl_per_word              0.014239\n",
      "4           num_terms              0.013962\n",
      "5       num_syllables              0.013847\n",
      "6    num_unique_words              0.013551\n",
      "7           num_words              0.012724\n",
      "8        num_mentions              0.012150\n",
      "9                dumm              0.007085\n",
      "10               mosl              0.006634\n",
      "11               pack              0.006392\n",
      "12              asyla              0.006353\n",
      "13            invasor              0.006143\n",
      "14               nich              0.005249\n",
      "15              islam              0.005172\n",
      "16            scheiss              0.004916\n",
      "17       num_hashtags              0.004735\n",
      "18        luegenpress              0.004711\n",
      "19         strunzdumm              0.004676\n",
      "20             merkel              0.004398\n",
      "21            murksel              0.004245\n",
      "22               fuer              0.004239\n",
      "23                gru              0.003997\n",
      "24           abschaum              0.003878\n",
      "25               frau              0.003498\n",
      "26          schmarotz              0.003471\n",
      "27            entsorg              0.003329\n",
      "28                all              0.003247\n",
      "29              tuerk              0.003167\n",
      "..                ...                   ...\n",
      "969   bundesregierung              0.000236\n",
      "970           deshalb              0.000234\n",
      "971             metoo              0.000234\n",
      "972          legenhei              0.000234\n",
      "973              axel              0.000234\n",
      "974            einzel              0.000233\n",
      "975              durf              0.000233\n",
      "976              beso              0.000233\n",
      "977               sys              0.000233\n",
      "978             kuess              0.000233\n",
      "979              hael              0.000232\n",
      "980    vergewaltigung              0.000232\n",
      "981              ossi              0.000232\n",
      "982             woand              0.000232\n",
      "983         nordkorea              0.000232\n",
      "984            voegel              0.000231\n",
      "985         nich find              0.000231\n",
      "986               pla              0.000231\n",
      "987          ja immer              0.000231\n",
      "988               hol              0.000231\n",
      "989                ao              0.000231\n",
      "990             argum              0.000231\n",
      "991            schaem              0.000230\n",
      "992               nee              0.000230\n",
      "993        provokatio              0.000229\n",
      "994              tief              0.000229\n",
      "995     deutsch waehl              0.000228\n",
      "996          antisemi              0.000228\n",
      "997          unbeding              0.000227\n",
      "998    sellschaftlich              0.000227\n",
      "\n",
      "[999 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_fs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             feature     Score\n",
      "0          num_chars  0.015472\n",
      "1                FRE  0.014541\n",
      "2               FKRA  0.014460\n",
      "3   avg_syl_per_word  0.014239\n",
      "4          num_terms  0.013962\n",
      "5      num_syllables  0.013847\n",
      "6   num_unique_words  0.013551\n",
      "7          num_words  0.012724\n",
      "8       num_mentions  0.012150\n",
      "9               dumm  0.007085\n",
      "10              mosl  0.006634\n",
      "11              pack  0.006392\n",
      "12             asyla  0.006353\n",
      "13           invasor  0.006143\n",
      "14              nich  0.005249\n",
      "15             islam  0.005172\n",
      "16           scheiss  0.004916\n",
      "17      num_hashtags  0.004735\n",
      "18       luegenpress  0.004711\n",
      "19        strunzdumm  0.004676\n",
      "             feature     Score\n",
      "0    num_chars_total  0.015586\n",
      "1                FRE  0.015078\n",
      "2               FKRA  0.014939\n",
      "3   avg_syl_per_word  0.014689\n",
      "4      num_syllables  0.013544\n",
      "5          num_terms  0.012977\n",
      "6   num_unique_words  0.012847\n",
      "7          num_words  0.012645\n",
      "8       num_mentions  0.011729\n",
      "9               dumm  0.007921\n",
      "10              pack  0.006489\n",
      "11              mosl  0.006383\n",
      "12           invasor  0.005922\n",
      "13              nich  0.005840\n",
      "14             asyla  0.005555\n",
      "15      num_hashtags  0.005489\n",
      "16             islam  0.005039\n",
      "17        strunzdumm  0.004933\n",
      "18            merkel  0.004671\n",
      "19           scheiss  0.004572\n"
     ]
    }
   ],
   "source": [
    "# Step 1: visualize the data\n",
    "# print out the top 20 features\n",
    "\n",
    "top_20 = data_fs1.nlargest(20,'Score')\n",
    "print(top_20)\n",
    "\n",
    "top_20_2 = data_fs2.nlargest(20,'Score')\n",
    "print(top_20_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FKRA is in the selected features\n",
      "FRE is in the selected features\n",
      "num_syllables is in the selected features\n",
      "avg_syl_per_word is in the selected features\n",
      "num_chars is in the selected features\n",
      "num_terms is in the selected features\n",
      "num_words is in the selected features\n",
      "num_unique_words is in the selected features\n",
      "num_hashtags is in the selected features\n",
      "num_mentions is in the selected features\n",
      "\n",
      "\n",
      "num_chars_total is NOT in the selected features\n",
      "sentiment is NOT in the selected features\n",
      "num_urls is NOT in the selected features\n"
     ]
    }
   ],
   "source": [
    "# Step 2: figure out how many of the 1000 features are for which category\n",
    "#run checks to see if any of the \"other features\" are in the list\n",
    "# count how many non-other features aka tfidf features are in the list \n",
    "other_features_names = pd.Series([\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"sentiment\", \"num_hashtags\", \"num_mentions\", \"num_urls\"])\n",
    "arr = other_features_names.isin(data_fs1.iloc[:, 0])\n",
    "\n",
    "for i in range(0, len(arr)):\n",
    "    if(arr[i]):\n",
    "        print(other_features_names[i] + ' is in the selected features')\n",
    "\n",
    "print('\\n')\n",
    "        \n",
    "for i in range(0, len(arr)):\n",
    "    if(not arr[i]):\n",
    "        print(other_features_names[i] + ' is NOT in the selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FKRA is in the selected features\n",
      "FRE is in the selected features\n",
      "num_syllables is in the selected features\n",
      "avg_syl_per_word is in the selected features\n",
      "num_chars_total is in the selected features\n",
      "num_terms is in the selected features\n",
      "num_words is in the selected features\n",
      "num_unique_words is in the selected features\n",
      "num_hashtags is in the selected features\n",
      "num_mentions is in the selected features\n",
      "\n",
      "\n",
      "num_chars is NOT in the selected features\n",
      "sentiment is NOT in the selected features\n",
      "num_urls is NOT in the selected features\n"
     ]
    }
   ],
   "source": [
    "other_features_names = pd.Series([\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"sentiment\", \"num_hashtags\", \"num_mentions\", \"num_urls\"])\n",
    "arr = other_features_names.isin(data_fs2.iloc[:, 0])\n",
    "\n",
    "for i in range(0, len(arr)):\n",
    "    if(arr[i]):\n",
    "        print(other_features_names[i] + ' is in the selected features')\n",
    "\n",
    "print('\\n')\n",
    "        \n",
    "for i in range(0, len(arr)):\n",
    "    if(not arr[i]):\n",
    "        print(other_features_names[i] + ' is NOT in the selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
